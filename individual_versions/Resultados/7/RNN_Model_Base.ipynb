{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4dLP23xZmpC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "# Importar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import zipfile\n",
    "from datetime import date\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 999 µs\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exists\n",
      "time: 189 ms\n"
     ]
    }
   ],
   "source": [
    "exp_name = '7'\n",
    "folder = 'Resultados/' + exp_name\n",
    "my_file = Path(folder)\n",
    "if os.path.exists(my_file):\n",
    "    print('already exists')\n",
    "else:\n",
    "    os.makedirs(folder)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exists\n",
      "time: 176 ms\n"
     ]
    }
   ],
   "source": [
    "ch_folder = folder + '/Checkpoints'\n",
    "my_file = Path(ch_folder)\n",
    "if os.path.exists(my_file):\n",
    "    print('already exists')\n",
    "else:\n",
    "    os.makedirs(ch_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nzv66BqFbl92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>Label</th>\n",
       "      <th>Date</th>\n",
       "      <th>Top</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49716</th>\n",
       "      <td>-0.082072</td>\n",
       "      <td>0.099915</td>\n",
       "      <td>-0.015503</td>\n",
       "      <td>0.115560</td>\n",
       "      <td>-0.072611</td>\n",
       "      <td>0.070435</td>\n",
       "      <td>0.042613</td>\n",
       "      <td>-0.041026</td>\n",
       "      <td>0.012126</td>\n",
       "      <td>-0.020508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062215</td>\n",
       "      <td>-0.078471</td>\n",
       "      <td>0.046008</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>-0.071452</td>\n",
       "      <td>0.122559</td>\n",
       "      <td>0.07622</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49717</th>\n",
       "      <td>-0.064514</td>\n",
       "      <td>0.013916</td>\n",
       "      <td>-0.028976</td>\n",
       "      <td>0.058716</td>\n",
       "      <td>-0.078369</td>\n",
       "      <td>-0.057312</td>\n",
       "      <td>-0.077515</td>\n",
       "      <td>-0.234467</td>\n",
       "      <td>0.050751</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010498</td>\n",
       "      <td>0.081284</td>\n",
       "      <td>0.040283</td>\n",
       "      <td>-0.108978</td>\n",
       "      <td>0.033783</td>\n",
       "      <td>0.028870</td>\n",
       "      <td>0.03418</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "49716 -0.082072  0.099915 -0.015503  0.115560 -0.072611  0.070435  0.042613   \n",
       "49717 -0.064514  0.013916 -0.028976  0.058716 -0.078369 -0.057312 -0.077515   \n",
       "\n",
       "              7         8         9  ...       293       294       295  \\\n",
       "49716 -0.041026  0.012126 -0.020508  ... -0.062215 -0.078471  0.046008   \n",
       "49717 -0.234467  0.050751  0.020508  ... -0.010498  0.081284  0.040283   \n",
       "\n",
       "            296       297       298      299  Label       Date  Top  \n",
       "49716  0.005717 -0.071452  0.122559  0.07622      0 2008-08-08   24  \n",
       "49717 -0.108978  0.033783  0.028870  0.03418      0 2008-08-08   25  \n",
       "\n",
       "[2 rows x 303 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.39 s\n"
     ]
    }
   ],
   "source": [
    "#Importar los datasets\n",
    "url_embeddings_average_individual = zipfile.ZipFile('../Data/embeddings_average_individual.zip')\n",
    "url_embeddings_sum_individual = zipfile.ZipFile('../Data/embeddings_sum_individual.zip')\n",
    "\n",
    "embeddings_average_individual = pd.read_csv(url_embeddings_average_individual.open('embeddings_average_individual.csv'), index_col = 0)\n",
    "embeddings_sum_individual =pd.read_csv(url_embeddings_sum_individual.open('embeddings_sum_individual.csv'), index_col = 0)\n",
    "\n",
    "embeddings_average_individual['Date'] =  pd.to_datetime(embeddings_average_individual['Date'], format='%Y-%m-%d')\n",
    "# embeddings_average_individual.sort_values('Date', inplace=True)\n",
    "# embeddings_average_individual.reset_index(drop = True , inplace=True)\n",
    "\n",
    "embeddings_average_individual.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAXOJcEcbmed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 69 ms\n"
     ]
    }
   ],
   "source": [
    "# Selecciono la fecha para la cual hago el corte de train y test\n",
    "training_end = pd.to_datetime(\"2013-12-31\")\n",
    "num_training = len(embeddings_average_individual[(embeddings_average_individual[\"Date\"]) <= training_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 928 ms\n"
     ]
    }
   ],
   "source": [
    "# Selecciono el archivo con el que se corre el modelo\n",
    "data = embeddings_average_individual[embeddings_average_individual['Date']<='2014-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6300, 1, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 764 ms\n"
     ]
    }
   ],
   "source": [
    "# Se separa en train y test\n",
    "x_train = data.drop([\"Top\",\"Label\", \"Date\"], axis=1)[:num_training]\n",
    "x_test = data.drop([\"Top\",'Label', 'Date'], axis=1)[num_training:]\n",
    "y_train = data[\"Label\"].values[:num_training]\n",
    "y_test = data[\"Label\"].values[num_training:]\n",
    "\n",
    "\n",
    "x_train_array = x_train.to_numpy()\n",
    "reshape_x_train = x_train_array.reshape(len(x_train), 1, 300)\n",
    "reshape_x_train.shape\n",
    "\n",
    "x_test_array = x_test.to_numpy()\n",
    "reshape_x_test = x_test_array.reshape(len(x_test), 1, 300)\n",
    "reshape_x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir espacio de busqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 535 ms\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'units1': hp.choice('units1', [10, 64, 128, 256, 512]),\n",
    "    'units2': hp.choice('units2', [10, 64, 128, 256, 512]),\n",
    "                 \n",
    "    'dropout1': hp.choice('dropout1', [0.2,0.3,0.1]),\n",
    "    \n",
    "    'batch_size' : hp.choice('batch_size', [128,256,512]),\n",
    "    'nb_epochs' : hp.choice('nb_epochs', [50]),\n",
    "\n",
    "    'optimizer':  hp.choice('optimizer', [ 'adam','adadelta']),   \n",
    "    'activation': 'relu'    \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir busqueda bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 524 ms\n"
     ]
    }
   ],
   "source": [
    "#Objective function that hyperopt will minimize\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def objective(params):\n",
    "    \n",
    "#     import ml_metrics\n",
    "\n",
    "    \n",
    "    start = timer()\n",
    "    print ('Params testing: ', params)\n",
    "    print ('\\n ')\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(params['units1'], input_shape=(1,300), return_sequences=True))\n",
    "    model.add(Dropout(params['dropout1']))\n",
    "    model.add(LSTM(params['units2'], return_sequences=False))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    # compile the model\n",
    "    model.compile(optimizer=params['optimizer'], loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    logdir = \"Resultados\\\\\" + exp_name +\"\\\\logs\\\\model\"\n",
    "\n",
    "    tensor_board = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1, profile_batch = 100000000)\n",
    "\n",
    "    \n",
    "    #includes the call back object\n",
    "    model.fit(reshape_x_train, y_train, epochs=params['nb_epochs'], batch_size=params['batch_size'],\n",
    "              verbose = 0, validation_data=(reshape_x_test, y_test),callbacks=[tensor_board])\n",
    "     \n",
    "    #predict the test set \n",
    "    score, acc = model.evaluate(reshape_x_test, y_test, verbose=0)\n",
    "    \n",
    "    run_time = timer() - start\n",
    "    \n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([-acc, params, score, run_time])\n",
    "    of_connection.close()\n",
    "    \n",
    "    \n",
    "    print('Test accuracy:', acc)\n",
    " \n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'train_time': run_time,}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almacenar resultados de cada iteración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 600 ms\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import tpe\n",
    "\n",
    "tpe_algorithm = tpe.suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 598 ms\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "from hyperopt import Trials\n",
    "\n",
    "bayes_trials = Trials()\n",
    "\n",
    "# File to save first results\n",
    "out_file = folder + '/gbm_results.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write the headers to the file\n",
    "writer.writerow(['loss', 'params', 'score','time'])\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lanzar optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 128, 'units2': 128}                                     \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49222222                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 64, 'units2': 10}                                           \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49666667                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 512, 'units2': 10}                                      \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.4931746                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 10, 'units2': 512}                                          \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49555555                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 128, 'units2': 128}                                     \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49222222                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 256, 'units2': 128}                                         \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.4895238                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 128, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 256, 'units2': 256}                                     \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49222222                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 128, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 64, 'units2': 256}                                      \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49222222                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 512, 'units2': 10}                                          \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.5012698                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 512, 'units2': 64}                                          \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.50158733                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 128, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 128, 'units2': 512}                                         \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49793652                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.1, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 10, 'units2': 128}                                      \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49222222                                                                                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 64, 'units2': 512}                                          \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.4952381                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 512, 'units2': 64}                                          \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.5001587                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 128, 'dropout1': 0.1, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 10, 'units2': 256}                                          \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.5038095                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 128, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 64, 'units2': 256}                                      \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49222222                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 128, 'units2': 10}                                      \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.4911111                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 256, 'units2': 64}                                      \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.4920635                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 256, 'units2': 10}                                          \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.5088889                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 256, 'units2': 64}                                          \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.50174606                                                                                                                                                             \n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [1:03:31<00:00, 190.59s/trial, best loss: -0.5088889002799988]\n",
      "time: 1h 3min 34s\n"
     ]
    }
   ],
   "source": [
    "# Run optimization\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = 20, trials = bayes_trials,\n",
    "            verbose = 1, rstate= np.random.RandomState(50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportar bayesiana, por si quisiera retomar donde queda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 64 ms\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dump(bayes_trials, open(folder + '/trials.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer mejores parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': -0.5088889002799988,\n",
       "  'status': 'ok',\n",
       "  'train_time': 109.71917329999997},\n",
       " {'loss': -0.5038095116615295,\n",
       "  'status': 'ok',\n",
       "  'train_time': 257.71171749999985}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 228 ms\n"
     ]
    }
   ],
   "source": [
    "# Sort the trials with lowest loss (highest AUC) first\n",
    "bayes_trials_results  = sorted(bayes_trials.results, key = lambda x: x['loss'])\n",
    "bayes_trials_results [:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.508889</td>\n",
       "      <td>{'activation': 'relu', 'batch_size': 512, 'dro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.719173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.503810</td>\n",
       "      <td>{'activation': 'relu', 'batch_size': 128, 'dro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257.711717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.501746</td>\n",
       "      <td>{'activation': 'relu', 'batch_size': 512, 'dro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.215043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.501587</td>\n",
       "      <td>{'activation': 'relu', 'batch_size': 256, 'dro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>247.814475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.501270</td>\n",
       "      <td>{'activation': 'relu', 'batch_size': 256, 'dro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>241.674166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss                                             params  score  \\\n",
       "0 -0.508889  {'activation': 'relu', 'batch_size': 512, 'dro...    NaN   \n",
       "1 -0.503810  {'activation': 'relu', 'batch_size': 128, 'dro...    NaN   \n",
       "2 -0.501746  {'activation': 'relu', 'batch_size': 512, 'dro...    NaN   \n",
       "3 -0.501587  {'activation': 'relu', 'batch_size': 256, 'dro...    NaN   \n",
       "4 -0.501270  {'activation': 'relu', 'batch_size': 256, 'dro...    NaN   \n",
       "\n",
       "         time  \n",
       "0  109.719173  \n",
       "1  257.711717  \n",
       "2  118.215043  \n",
       "3  247.814475  \n",
       "4  241.674166  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 103 ms\n"
     ]
    }
   ],
   "source": [
    "results = pd.read_csv(folder + '/gbm_results.csv')\n",
    "\n",
    "# Sort with best scores on top and reset index for slicing\n",
    "results.sort_values('loss', ascending = True, inplace = True)\n",
    "results.reset_index(inplace = True, drop = True)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 512,\n",
       " 'dropout1': 0.3,\n",
       " 'nb_epochs': 50,\n",
       " 'optimizer': 'adam',\n",
       " 'units1': 256,\n",
       " 'units2': 10}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 200 ms\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Convert from a string to a dictionary\n",
    "ast.literal_eval(results.loc[0, 'params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 512,\n",
       " 'dropout1': 0.3,\n",
       " 'nb_epochs': 50,\n",
       " 'optimizer': 'adam',\n",
       " 'units1': 256,\n",
       " 'units2': 10}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 104 ms\n"
     ]
    }
   ],
   "source": [
    "# Extract the ideal number of estimators and hyperparameters\n",
    "best_bayes_params = ast.literal_eval(results.loc[0, 'params']).copy()\n",
    "best_bayes_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir datasets de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 355 ms\n"
     ]
    }
   ],
   "source": [
    "# Selecciono la fecha para la cual hago el corte de train y test\n",
    "training_end = pd.to_datetime(\"2014-12-31\")\n",
    "num_training = len(embeddings_average_individual[(embeddings_average_individual[\"Date\"]) <= training_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5 ms\n"
     ]
    }
   ],
   "source": [
    "# Selecciono el archivo con el que se corre el modelo\n",
    "data = embeddings_average_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9450, 1, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 933 ms\n"
     ]
    }
   ],
   "source": [
    "# Se separa en train y test\n",
    "x_train = data.drop([\"Top\",\"Label\", \"Date\"], axis=1)[:num_training]\n",
    "x_test = data.drop([\"Top\",'Label', 'Date'], axis=1)[num_training:]\n",
    "y_train = data[\"Label\"].values[:num_training]\n",
    "y_test = data[\"Label\"].values[num_training:]\n",
    "\n",
    "\n",
    "x_train_array = x_train.to_numpy()\n",
    "reshape_x_train = x_train_array.reshape(len(x_train), 1, 300)\n",
    "reshape_x_train.shape\n",
    "\n",
    "x_test_array = x_test.to_numpy()\n",
    "reshape_x_test = x_test_array.reshape(len(x_test), 1, 300)\n",
    "reshape_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIKq7z8tnIWl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(best_bayes_params['units1'], input_shape=(1,300), return_sequences=True))\n",
    "model.add(Dropout(best_bayes_params['dropout1']))\n",
    "model.add(LSTM(best_bayes_params['units2'], return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# define the checkpoint\n",
    "filepath= ch_folder + \"/word2vec-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logdir = \"Resultados\\\\\" + exp_name +\"\\\\logs\\\\model\"\n",
    "\n",
    "\n",
    "tensor_board = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1, profile_batch = 100000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3944,
     "status": "ok",
     "timestamp": 1589755592715,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "JsHgNLFnnTLN",
    "outputId": "4c22910d-c7b2-4dff-eb32-15c2574174ff",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40268 samples\n",
      "Epoch 1/50\n",
      "40268/40268 [==============================] - 7s 171us/sample - loss: 0.6903 - accuracy: 0.5390\n",
      "Epoch 2/50\n",
      "40268/40268 [==============================] - 2s 50us/sample - loss: 0.6897 - accuracy: 0.5393\n",
      "Epoch 3/50\n",
      "40268/40268 [==============================] - 2s 48us/sample - loss: 0.6892 - accuracy: 0.5398\n",
      "Epoch 4/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6888 - accuracy: 0.5410\n",
      "Epoch 5/50\n",
      "40268/40268 [==============================] - 2s 56us/sample - loss: 0.6883 - accuracy: 0.5427\n",
      "Epoch 6/50\n",
      "40268/40268 [==============================] - 2s 52us/sample - loss: 0.6876 - accuracy: 0.5445s - loss: 0.6876 - accu\n",
      "Epoch 7/50\n",
      "40268/40268 [==============================] - 2s 53us/sample - loss: 0.6874 - accuracy: 0.5449\n",
      "Epoch 8/50\n",
      "40268/40268 [==============================] - 2s 50us/sample - loss: 0.6871 - accuracy: 0.5450\n",
      "Epoch 9/50\n",
      "40268/40268 [==============================] - 2s 51us/sample - loss: 0.6866 - accuracy: 0.5449\n",
      "Epoch 10/50\n",
      "40268/40268 [==============================] - 2s 46us/sample - loss: 0.6866 - accuracy: 0.5471\n",
      "Epoch 11/50\n",
      "40268/40268 [==============================] - 2s 48us/sample - loss: 0.6860 - accuracy: 0.5456\n",
      "Epoch 12/50\n",
      "40268/40268 [==============================] - 2s 57us/sample - loss: 0.6860 - accuracy: 0.5484\n",
      "Epoch 13/50\n",
      "40268/40268 [==============================] - 2s 51us/sample - loss: 0.6852 - accuracy: 0.5481\n",
      "Epoch 14/50\n",
      "40268/40268 [==============================] - 2s 52us/sample - loss: 0.6846 - accuracy: 0.5489\n",
      "Epoch 15/50\n",
      "40268/40268 [==============================] - 2s 47us/sample - loss: 0.6845 - accuracy: 0.5490s - loss: 0.6847 - accuracy: 0.\n",
      "Epoch 16/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6833 - accuracy: 0.5508\n",
      "Epoch 17/50\n",
      "40268/40268 [==============================] - 2s 47us/sample - loss: 0.6832 - accuracy: 0.5517\n",
      "Epoch 18/50\n",
      "40268/40268 [==============================] - 2s 53us/sample - loss: 0.6823 - accuracy: 0.5533\n",
      "Epoch 19/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6823 - accuracy: 0.5528\n",
      "Epoch 20/50\n",
      "40268/40268 [==============================] - 2s 57us/sample - loss: 0.6816 - accuracy: 0.5553\n",
      "Epoch 21/50\n",
      "40268/40268 [==============================] - 2s 48us/sample - loss: 0.6808 - accuracy: 0.5569\n",
      "Epoch 22/50\n",
      "40268/40268 [==============================] - 2s 46us/sample - loss: 0.6802 - accuracy: 0.5554\n",
      "Epoch 23/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6793 - accuracy: 0.5572\n",
      "Epoch 24/50\n",
      "40268/40268 [==============================] - 2s 55us/sample - loss: 0.6789 - accuracy: 0.5572s - l\n",
      "Epoch 25/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6782 - accuracy: 0.5590\n",
      "Epoch 26/50\n",
      "40268/40268 [==============================] - 2s 43us/sample - loss: 0.6770 - accuracy: 0.5619\n",
      "Epoch 27/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6759 - accuracy: 0.5614\n",
      "Epoch 28/50\n",
      "40268/40268 [==============================] - 2s 48us/sample - loss: 0.6755 - accuracy: 0.5624s - loss: 0.6757 - accuracy\n",
      "Epoch 29/50\n",
      "40268/40268 [==============================] - 2s 43us/sample - loss: 0.6748 - accuracy: 0.5619\n",
      "Epoch 30/50\n",
      "40268/40268 [==============================] - 2s 43us/sample - loss: 0.6729 - accuracy: 0.5658\n",
      "Epoch 31/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6716 - accuracy: 0.5686\n",
      "Epoch 32/50\n",
      "40268/40268 [==============================] - 2s 43us/sample - loss: 0.6707 - accuracy: 0.5683\n",
      "Epoch 33/50\n",
      "40268/40268 [==============================] - 2s 48us/sample - loss: 0.6693 - accuracy: 0.5713\n",
      "Epoch 34/50\n",
      "40268/40268 [==============================] - 2s 46us/sample - loss: 0.6673 - accuracy: 0.5752\n",
      "Epoch 35/50\n",
      "40268/40268 [==============================] - 2s 47us/sample - loss: 0.6655 - accuracy: 0.5769\n",
      "Epoch 36/50\n",
      "40268/40268 [==============================] - 2s 42us/sample - loss: 0.6640 - accuracy: 0.5776\n",
      "Epoch 37/50\n",
      "40268/40268 [==============================] - 2s 42us/sample - loss: 0.6633 - accuracy: 0.5777s - loss: 0.659 - ETA: 0s - loss: 0.6620 - ac\n",
      "Epoch 38/50\n",
      "40268/40268 [==============================] - 2s 43us/sample - loss: 0.6613 - accuracy: 0.5816\n",
      "Epoch 39/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6587 - accuracy: 0.5846\n",
      "Epoch 40/50\n",
      "40268/40268 [==============================] - 2s 42us/sample - loss: 0.6567 - accuracy: 0.5885s - loss: 0.6571 - accuracy\n",
      "Epoch 41/50\n",
      "40268/40268 [==============================] - 2s 53us/sample - loss: 0.6557 - accuracy: 0.5912s - loss: 0.6559 - accura\n",
      "Epoch 42/50\n",
      "40268/40268 [==============================] - 2s 44us/sample - loss: 0.6529 - accuracy: 0.5918\n",
      "Epoch 43/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6513 - accuracy: 0.5920s - los\n",
      "Epoch 44/50\n",
      "40268/40268 [==============================] - 2s 47us/sample - loss: 0.6480 - accuracy: 0.5991\n",
      "Epoch 45/50\n",
      "40268/40268 [==============================] - 2s 43us/sample - loss: 0.6461 - accuracy: 0.5996\n",
      "Epoch 46/50\n",
      "40268/40268 [==============================] - 2s 43us/sample - loss: 0.6417 - accuracy: 0.6052\n",
      "Epoch 47/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6398 - accuracy: 0.6103\n",
      "Epoch 48/50\n",
      "40268/40268 [==============================] - 2s 42us/sample - loss: 0.6383 - accuracy: 0.6088s - loss: 0.6375 - accura - ETA: 0s - loss: 0.6384 - accuracy: \n",
      "Epoch 49/50\n",
      "40268/40268 [==============================] - 2s 46us/sample - loss: 0.6356 - accuracy: 0.6138\n",
      "Epoch 50/50\n",
      "40268/40268 [==============================] - 2s 46us/sample - loss: 0.6322 - accuracy: 0.6169\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_40 (LSTM)               (None, 1, 256)            570368    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, 10)                10680     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 581,059\n",
      "Trainable params: 581,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(reshape_x_train, y_train,\n",
    "          epochs=best_bayes_params['nb_epochs'], \n",
    "          batch_size=best_bayes_params['batch_size'], callbacks=[tensor_board])\n",
    "\n",
    "\n",
    "model.save(folder + '/keras_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1589755595730,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "mdsR4Qngv5Q1",
    "outputId": "433bbcf6-d6eb-44c1-a1bb-afee72ac0ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.513968\n",
      "time: 3.4 s\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(reshape_x_test, y_test, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.save_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Resultados/7/RNN_Model_Base.ipynb'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 167 ms\n"
     ]
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "copyfile('RNN_Model_Base.ipynb', folder + '/RNN_Model_Base.ipynb' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodo b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1989"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1989"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "# Importing modules\n",
    "%load_ext autotime\n",
    "\n",
    "# Importar librerias\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.expand_frame_repr', True)\n",
    "import os\n",
    "\n",
    "#Importar los datasets\n",
    "url_reddit = 'https://raw.githubusercontent.com/jjiguaran/text_mining/master/Data/RedditNews.csv'\n",
    "url_combined = 'https://raw.githubusercontent.com/jjiguaran/text_mining/master/Data/Combined_News_DJIA.csv'\n",
    "RedditNews = pd.read_csv(url_reddit)\n",
    "CombinedNews = pd.read_csv(url_combined)\n",
    "\n",
    "\n",
    "RedditNews['Date'] =  pd.to_datetime(RedditNews['Date'], format='%Y-%m-%d')\n",
    "RedditNews.sort_values('Date', inplace=True)\n",
    "CombinedNews['Date'] =  pd.to_datetime(CombinedNews['Date'], format='%Y-%m-%d')\n",
    "RedditNews.head()\n",
    "\n",
    "\n",
    "## Nos quedamos con las fechas del dataset que está etiquetado\n",
    "RedditNews = RedditNews[RedditNews['Date'].isin(CombinedNews['Date'])]\n",
    "\n",
    "display(\n",
    "    CombinedNews['Date'].nunique(),\n",
    "    RedditNews['Date'].nunique() )\n",
    "\n",
    "## Añadir columna del top correspondiente\n",
    "RedditNews['Top'] = RedditNews.groupby(['Date']).cumcount()+1\n",
    "\n",
    "## Añadir columna de la clase a este df\n",
    "RedditNews = pd.merge(RedditNews, CombinedNews[['Date']], on=['Date'])\n",
    "\n",
    "# RedditNews[RedditNews['Date']=='2014-12-31']\n",
    "\n",
    "del CombinedNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>News</th>\n",
       "      <th>Top</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>b\"So---Russia and Georgia are at war and the N...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                               News  Top\n",
       "1  2008-08-08  b\"The 'enemy combatent' trials are nothing but...    2\n",
       "2  2008-08-08  b\"Breaking: Georgia invades South Ossetia, Rus...    3\n",
       "8  2008-08-08  b\"Georgia 'downs two Russian warplanes' as cou...    9\n",
       "9  2008-08-08  b\"Afghan children raped with 'impunity,' U.N. ...   10\n",
       "12 2008-08-08  b\"So---Russia and Georgia are at war and the N...   13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>News</th>\n",
       "      <th>Top</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>b'Georgian troops retreat from S. Osettain cap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>b'Did the U.S. Prep Georgia for War with Russia?'</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>b'Russian tanks are moving towards the capital...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                               News  Top\n",
       "0 2008-08-08  b'Georgian troops retreat from S. Osettain cap...    1\n",
       "3 2008-08-08  b'150 Russian tanks have entered South Ossetia...    4\n",
       "4 2008-08-08  b'Did the U.S. Prep Georgia for War with Russia?'    5\n",
       "5 2008-08-08  b'Russian tanks are moving towards the capital...    6\n",
       "6 2008-08-08  b'Russia Today: Columns of troops roll into So...    7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "## Hay error en la codificación de caracteres especiales, encontré ese, pero hay que ver que otros surgen\n",
    "RedditNews['News'] = RedditNews['News'].str.replace(\"year.old\", \" year old \", regex=True)\n",
    "RedditNews['News'] = RedditNews['News'].str.replace(\"\\d year\", \" year \", regex=True)\n",
    "RedditNews['News'] = RedditNews['News'].str.replace(\"year old\", \"years old\", regex=True)\n",
    "\n",
    "\n",
    "RedditNews['News'] = RedditNews['News'].str.replace(\"years.old\", \" years old \", regex=True)\n",
    "RedditNews['News'] = RedditNews['News'].str.replace(\"\\d years\", \" years \", regex=True)\n",
    "\n",
    "## Hay error en la codificación de caracteres especiales, encontré ese, pero hay que ver que otros surgen\n",
    "index_review = RedditNews[(RedditNews['News'].str.startswith('b\"')) |\n",
    "                         (RedditNews['News'].str.startswith(\"b'\"))].index\n",
    "\n",
    "display(RedditNews[RedditNews['News'].str.startswith('b\"')].head(),\n",
    "        RedditNews[RedditNews['News'].str.startswith(\"b'\")].head())\n",
    "\n",
    "\n",
    "RedditNews['News'] = RedditNews['News'].str.replace('^b\\\"', \" \", regex=True)\n",
    "RedditNews['News'] = RedditNews['News'].str.replace(\"^b\\'\", \" \", regex=True)\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stoplist = stopwords.words(\"english\")\n",
    "REPLACE_BY_SPACE_RE = re.compile('[(){}\\[\\]\\|@,;-]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z ^#\\+_]')\n",
    "SEP_NUMBER = re.compile('(?<=\\d)\\,|\\.(?=\\d)')\n",
    "USA_ABREV = re.compile('U\\.S|u\\.s\\|u\\.s\\.a\\.|US')\n",
    "DOT_ABREV = re.compile('\\.(?![a-zA-Z]{2})')\n",
    "STARTING_B = re.compile(\"^\\\"b' |^b \")\n",
    "STOPWORDS = stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    \n",
    "    text = USA_ABREV.sub(' usa ', text) # replace U.S U.S. u.s US for usa\n",
    "    text = text.lower() # lowercase text\n",
    "    text = text.replace(\"al-qaeda\", \"alqaeda\")\n",
    "    text = text.replace(\"al-qa'eda\", \"alqaeda\")\n",
    "    text = text.replace('&amp;', '&')\n",
    "    text = text.replace('&', '')    \n",
    "\n",
    "    text = DOT_ABREV.sub('', text) # removes abrevetion dot, ej: L.G.B.T  = LGBT\n",
    "    text = SEP_NUMBER.sub('', text) # removes . and , seprating numbers\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub(' ', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = STARTING_B.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    text = text.strip()\n",
    "    return text\n",
    "    \n",
    "RedditNews['News'] = RedditNews['News'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "40268"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['georgian', 'troops', 'retreat', 'osettain', 'capital', 'presumably', 'leaving', 'several', 'hundred', 'people', 'killed', 'video']\n",
      "time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "RedditNews_copy = RedditNews.copy()\n",
    "\n",
    "Org_RedditNews = RedditNews_copy[RedditNews_copy['Date']>'2014-12-31'].copy()\n",
    "\n",
    "RedditNews = RedditNews_copy[RedditNews_copy['Date']<='2014-12-31'].copy()\n",
    "\n",
    "display(\n",
    "len(Org_RedditNews),\n",
    "len(RedditNews))\n",
    "    \n",
    "# Convert to tokens\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "# NLTK Stop words\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "data = RedditNews.News.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "\n",
    "print(data_words[:1][0][:30])\n",
    "\n",
    "\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'georgian': 12457,\n",
       " 'troops': 29401,\n",
       " 'retreat': 24328,\n",
       " 'osettain': 20660,\n",
       " 'capital': 5529,\n",
       " 'presumably': 22406,\n",
       " 'leaving': 16700,\n",
       " 'several': 25715,\n",
       " 'hundred': 14220,\n",
       " 'people': 21407,\n",
       " 'killed': 16154,\n",
       " 'video': 30545,\n",
       " 'enemy': 10219,\n",
       " 'combatent': 6681,\n",
       " 'trials': 29322,\n",
       " 'nothing': 19971,\n",
       " 'sham': 25801,\n",
       " 'salim': 25000,\n",
       " 'haman': 13243,\n",
       " 'sentenced': 25621,\n",
       " 'year': 31661,\n",
       " 'kept': 16037,\n",
       " 'longer': 17184,\n",
       " 'anyway': 2752,\n",
       " 'feel': 11245,\n",
       " 'like': 16952,\n",
       " 'breaking': 4889,\n",
       " 'georgia': 12456,\n",
       " 'invades': 15259,\n",
       " 'south': 26811,\n",
       " 'ossetia': 20665,\n",
       " 'russia': 24869,\n",
       " 'warned': 30913,\n",
       " 'would': 31490,\n",
       " 'intervene': 15199,\n",
       " 'side': 26138,\n",
       " '150': 247,\n",
       " 'russian': 24870,\n",
       " 'tanks': 28299,\n",
       " 'entered': 10315,\n",
       " 'whilst': 31163,\n",
       " 'shoots': 26009,\n",
       " 'two': 29596,\n",
       " 'jets': 15642,\n",
       " 'usa': 30252,\n",
       " 'prep': 22356,\n",
       " 'war': 30879,\n",
       " 'moving': 18945,\n",
       " 'towards': 29089,\n",
       " 'reportedly': 24059,\n",
       " 'completely': 6848,\n",
       " 'destroyed': 8670,\n",
       " 'artillery': 3049,\n",
       " 'fire': 11455,\n",
       " 'today': 28917,\n",
       " 'columns': 6673,\n",
       " 'roll': 24651,\n",
       " 'footage': 11737,\n",
       " 'fighting': 11363,\n",
       " 'youtube': 31756,\n",
       " 'musharraf': 19091,\n",
       " 'impeached': 14525,\n",
       " 'downs': 9456,\n",
       " 'warplanes': 30921,\n",
       " 'countries': 7484,\n",
       " 'move': 18934,\n",
       " 'brink': 4979,\n",
       " 'afghan': 2028,\n",
       " 'children': 6116,\n",
       " 'raped': 23322,\n",
       " 'impunity': 14617,\n",
       " 'un': 29700,\n",
       " 'official': 20367,\n",
       " 'says': 25182,\n",
       " 'sick': 26131,\n",
       " 'three': 28750,\n",
       " 'years': 31665,\n",
       " 'old': 20420,\n",
       " 'rice': 24459,\n",
       " 'gives': 12572,\n",
       " 'green': 12881,\n",
       " 'light': 16940,\n",
       " 'israel': 15452,\n",
       " 'attack': 3261,\n",
       " 'iran': 15341,\n",
       " 'veto': 30499,\n",
       " 'israeli': 15453,\n",
       " 'military': 18379,\n",
       " 'ops': 20540,\n",
       " 'announcing': 2642,\n",
       " 'class': 6345,\n",
       " 'action': 1813,\n",
       " 'lawsuit': 16627,\n",
       " 'behalf': 4010,\n",
       " 'american': 2460,\n",
       " 'public': 22841,\n",
       " 'fbi': 11196,\n",
       " 'nyt': 20207,\n",
       " 'top': 28992,\n",
       " 'story': 27453,\n",
       " 'opening': 20493,\n",
       " 'ceremonies': 5866,\n",
       " 'olympics': 20443,\n",
       " 'fucking': 12087,\n",
       " 'disgrace': 9050,\n",
       " 'yet': 31693,\n",
       " 'proof': 22661,\n",
       " 'decline': 8215,\n",
       " 'journalism': 15763,\n",
       " 'visitors': 30654,\n",
       " 'suffering': 27752,\n",
       " 'mental': 18135,\n",
       " 'illnesses': 14441,\n",
       " 'banned': 3722,\n",
       " 'indian': 14731,\n",
       " 'shoe': 25997,\n",
       " 'manufactory': 17671,\n",
       " 'series': 25667,\n",
       " 'work': 31438,\n",
       " 'caucasus': 5740,\n",
       " 'crisis': 7668,\n",
       " 'help': 13631,\n",
       " 'mexico': 18257,\n",
       " 'kidnapping': 16143,\n",
       " 'surge': 27939,\n",
       " 'withdraw': 31351,\n",
       " '1000': 39,\n",
       " 'soldiers': 26696,\n",
       " 'iraq': 15347,\n",
       " 'fight': 11359,\n",
       " 'forces': 11762,\n",
       " 'breakaway': 4883,\n",
       " 'region': 23751,\n",
       " 'pentagon': 21403,\n",
       " 'thinks': 28701,\n",
       " 'attacking': 3265,\n",
       " 'bad': 3569,\n",
       " 'idea': 14346,\n",
       " 'news': 19615,\n",
       " 'world': 31455,\n",
       " 'report': 24057,\n",
       " 'condoleezza': 6955,\n",
       " 'act': 1809,\n",
       " 'prevent': 22428,\n",
       " 'strike': 27541,\n",
       " 'defense': 8313,\n",
       " 'minister': 18442,\n",
       " 'ehud': 9912,\n",
       " 'barak': 3738,\n",
       " 'prepared': 22361,\n",
       " 'uncompromising': 29752,\n",
       " 'victory': 30541,\n",
       " 'case': 5662,\n",
       " 'hostilities': 14085,\n",
       " 'alqaeda': 2382,\n",
       " 'faces': 10973,\n",
       " 'islamist': 15426,\n",
       " 'backlash': 3551,\n",
       " 'gets': 12482,\n",
       " 'involved': 15315,\n",
       " 'nato': 19315,\n",
       " 'absorb': 1659,\n",
       " 'unleash': 29985,\n",
       " 'full': 12114,\n",
       " 'scale': 25189,\n",
       " 'iii': 14415,\n",
       " 'start': 27227,\n",
       " 'china': 6140,\n",
       " 'tells': 28483,\n",
       " 'bush': 5248,\n",
       " 'stay': 27280,\n",
       " 'affairs': 2001,\n",
       " 'busy': 5278,\n",
       " 'day': 8081,\n",
       " 'european': 10565,\n",
       " 'union': 29948,\n",
       " 'approved': 2862,\n",
       " 'new': 19603,\n",
       " 'sanctions': 25051,\n",
       " 'protest': 22740,\n",
       " 'nuclear': 20126,\n",
       " 'programme': 22595,\n",
       " 'angered': 2592,\n",
       " 'sale': 24989,\n",
       " 'mistake': 18554,\n",
       " 'monumental': 18784,\n",
       " 'proportions': 22686,\n",
       " 'welcome': 31091,\n",
       " 'iv': 15484,\n",
       " 'high': 13755,\n",
       " 'definition': 8338,\n",
       " 'citizen': 6286,\n",
       " 'living': 17091,\n",
       " 'blames': 4399,\n",
       " 'leaders': 16652,\n",
       " 'genocide': 12425,\n",
       " 'innocent': 14957,\n",
       " 'mossad': 18871,\n",
       " 'fraudulent': 11940,\n",
       " 'zealand': 31821,\n",
       " 'passports': 21183,\n",
       " 'presses': 22397,\n",
       " 'deeper': 8269,\n",
       " 'regime': 23745,\n",
       " 'change': 5932,\n",
       " 'goal': 12654,\n",
       " 'army': 2995,\n",
       " 'flees': 11583,\n",
       " 'disarray': 8964,\n",
       " 'russians': 24871,\n",
       " 'advance': 1947,\n",
       " 'gori': 12743,\n",
       " 'abandoned': 1551,\n",
       " 'without': 31363,\n",
       " 'shot': 26037,\n",
       " 'fired': 11464,\n",
       " 'jewish': 15649,\n",
       " 'thanks': 28628,\n",
       " 'training': 29162,\n",
       " 'fending': 11276,\n",
       " 'puts': 22971,\n",
       " 'foot': 11736,\n",
       " 'conflict': 7004,\n",
       " 'wont': 31414,\n",
       " 'america': 2459,\n",
       " 'us': 30251,\n",
       " 'olympic': 20442,\n",
       " 'ceremony': 5867,\n",
       " 'fireworks': 11478,\n",
       " 'faked': 11038,\n",
       " 'abhinav': 1604,\n",
       " 'bindra': 4277,\n",
       " 'wins': 31313,\n",
       " 'first': 11484,\n",
       " 'ever': 10619,\n",
       " 'individual': 14766,\n",
       " 'gold': 12686,\n",
       " 'medal': 18022,\n",
       " 'india': 14730,\n",
       " 'come': 6692,\n",
       " 'trading': 29135,\n",
       " 'sex': 25731,\n",
       " 'food': 11728,\n",
       " 'drivers': 9565,\n",
       " 'jerusalem': 15638,\n",
       " 'taxi': 28377,\n",
       " 'station': 27256,\n",
       " 'threaten': 28743,\n",
       " 'quit': 23101,\n",
       " 'rather': 23357,\n",
       " 'boss': 4723,\n",
       " 'arab': 2884,\n",
       " 'much': 18979,\n",
       " 'better': 4183,\n",
       " 'perhaps': 21442,\n",
       " 'question': 23080,\n",
       " 'beaten': 3945,\n",
       " 'united': 29959,\n",
       " 'states': 27251,\n",
       " 'head': 13502,\n",
       " 'peak': 21308,\n",
       " 'oil': 20394,\n",
       " 'physicians': 21650,\n",
       " 'group': 12975,\n",
       " 'condemns': 6947,\n",
       " 'state': 27244,\n",
       " 'torture': 29038,\n",
       " 'pics': 21678,\n",
       " 'ship': 25954,\n",
       " 'heads': 13518,\n",
       " 'arctic': 2927,\n",
       " 'define': 8332,\n",
       " 'territory': 28569,\n",
       " 'riots': 24536,\n",
       " 'still': 27364,\n",
       " 'going': 12684,\n",
       " 'montreal': 18780,\n",
       " 'canada': 5448,\n",
       " 'police': 22005,\n",
       " 'murdered': 19065,\n",
       " 'boy': 4786,\n",
       " 'saturday': 25135,\n",
       " 'believe': 4059,\n",
       " 'tv': 29569,\n",
       " 'neither': 19512,\n",
       " 'victims': 30535,\n",
       " 'behind': 4027,\n",
       " 'aggression': 2086,\n",
       " 'french': 11991,\n",
       " 'team': 28401,\n",
       " 'stunned': 27614,\n",
       " 'phelps': 21584,\n",
       " '4x100m': 1084,\n",
       " 'relay': 23868,\n",
       " 'overtake': 20846,\n",
       " 'largest': 16534,\n",
       " 'manufacturer': 17674,\n",
       " 'beats': 3952,\n",
       " 'drum': 9598,\n",
       " 'dumps': 9657,\n",
       " 'dollar': 9333,\n",
       " 'remember': 23932,\n",
       " 'adorable': 1931,\n",
       " 'sang': 25071,\n",
       " 'fake': 11037,\n",
       " 'ends': 10212,\n",
       " 'operation': 20507,\n",
       " 'sexual': 25739,\n",
       " 'harassment': 13350,\n",
       " 'losing': 17228,\n",
       " 'support': 27902,\n",
       " 'brutal': 5063,\n",
       " 'crackdown': 7549,\n",
       " 'activities': 1825,\n",
       " 'regards': 23742,\n",
       " 'islamic': 15421,\n",
       " 'including': 14670,\n",
       " 'women': 31402,\n",
       " 'buying': 5295,\n",
       " 'cucumbers': 7812,\n",
       " 'ceasefire': 5786,\n",
       " 'putin': 22968,\n",
       " 'outmaneuvers': 20736,\n",
       " 'west': 31112,\n",
       " 'microsoft': 18309,\n",
       " 'intel': 15093,\n",
       " 'tried': 29345,\n",
       " 'kill': 16153,\n",
       " 'xo': 31595,\n",
       " '100': 38,\n",
       " 'laptop': 16526,\n",
       " 'stratfor': 27494,\n",
       " 'russo': 24873,\n",
       " 'balance': 3637,\n",
       " 'power': 22229,\n",
       " 'trying': 29452,\n",
       " 'get': 12481,\n",
       " 'sense': 25608,\n",
       " 'whole': 31198,\n",
       " 'vote': 30737,\n",
       " 'think': 28696,\n",
       " 'started': 27228,\n",
       " 'surprised': 27958,\n",
       " 'timing': 28862,\n",
       " 'swiftness': 28090,\n",
       " 'sort': 26786,\n",
       " 'happened': 13334,\n",
       " 'said': 24959,\n",
       " 'monday': 18721,\n",
       " 'gorbachev': 12734,\n",
       " 'attacked': 3262,\n",
       " 'ossetian': 20666,\n",
       " 'tskhinvali': 29465,\n",
       " 'multiple': 19028,\n",
       " 'rocket': 24624,\n",
       " 'launchers': 16590,\n",
       " 'designed': 8638,\n",
       " 'devastate': 8735,\n",
       " 'large': 16531,\n",
       " 'areas': 2931,\n",
       " 'cnn': 6496,\n",
       " 'use': 30255,\n",
       " 'ruins': 24817,\n",
       " 'cover': 7522,\n",
       " 'bbc': 3906,\n",
       " 'asia': 3091,\n",
       " 'pacific': 20902,\n",
       " 'extinction': 10897,\n",
       " 'man': 17594,\n",
       " 'climate': 6412,\n",
       " 'beginning': 4003,\n",
       " 'violates': 30612,\n",
       " 'ancient': 2564,\n",
       " 'tradition': 29136,\n",
       " 'truce': 29419,\n",
       " 'games': 12258,\n",
       " 'ioc': 15321,\n",
       " 'could': 7442,\n",
       " 'respond': 24216,\n",
       " 'taking': 28240,\n",
       " '2014': 526,\n",
       " 'away': 3457,\n",
       " 'christopher': 6213,\n",
       " 'king': 16187,\n",
       " 'argues': 2948,\n",
       " 'invasion': 15266,\n",
       " 'misjudged': 18522,\n",
       " 'resolve': 24193,\n",
       " 'signs': 26189,\n",
       " 'point': 21973,\n",
       " 'encouraging': 10178,\n",
       " 'invade': 15255,\n",
       " 'goddamnit': 12664,\n",
       " '62': 1212,\n",
       " 'led': 16711,\n",
       " 'country': 7485,\n",
       " 'based': 3813,\n",
       " 'evidence': 10633,\n",
       " 'connection': 7052,\n",
       " 'accuses': 1761,\n",
       " 'making': 17538,\n",
       " 'serious': 25668,\n",
       " 'blunder': 4528,\n",
       " 'pursuing': 22957,\n",
       " 'interest': 15136,\n",
       " 'russias': 24872,\n",
       " 'response': 24221,\n",
       " 'right': 24500,\n",
       " 'know': 16272,\n",
       " 'place': 21805,\n",
       " '11': 100,\n",
       " 'party': 21155,\n",
       " 'cities': 6283,\n",
       " '55': 1146,\n",
       " 'pyramids': 22990,\n",
       " 'luxor': 17353,\n",
       " 'stacked': 27149,\n",
       " 'mega': 18062,\n",
       " 'city': 6290,\n",
       " 'pyramid': 22988,\n",
       " 'tokyo': 28940,\n",
       " 'bay': 3894,\n",
       " 'cold': 6579,\n",
       " 'announces': 2641,\n",
       " 'grill': 12925,\n",
       " 'yeah': 31660,\n",
       " 'end': 10191,\n",
       " 'well': 31098,\n",
       " '92': 1478,\n",
       " 'readers': 23430,\n",
       " 'actions': 1815,\n",
       " 'justified': 15861,\n",
       " 'commander': 6713,\n",
       " 'navy': 19345,\n",
       " 'air': 2167,\n",
       " 'reconnaissance': 23575,\n",
       " 'squadron': 27095,\n",
       " 'provides': 22772,\n",
       " 'president': 22389,\n",
       " 'secretary': 25472,\n",
       " 'airborne': 2173,\n",
       " 'ability': 1611,\n",
       " 'command': 6708,\n",
       " 'nation': 19292,\n",
       " 'weapons': 31031,\n",
       " 'relieved': 23889,\n",
       " 'duty': 9682,\n",
       " 'sink': 26265,\n",
       " 'ships': 25962,\n",
       " 'moved': 18935,\n",
       " '10': 37,\n",
       " 'million': 18393,\n",
       " 'quake': 23031,\n",
       " 'survivors': 27986,\n",
       " 'prefab': 22326,\n",
       " 'homes': 13952,\n",
       " 'send': 25592,\n",
       " 'fleet': 11584,\n",
       " 'black': 4367,\n",
       " 'sea': 25418,\n",
       " 'humanitarian': 14193,\n",
       " 'aid': 2148,\n",
       " 'exercise': 10741,\n",
       " 'britain': 4985,\n",
       " 'policy': 22012,\n",
       " 'tough': 29068,\n",
       " 'drugs': 9597,\n",
       " 'pointless': 21978,\n",
       " 'former': 11826,\n",
       " 'civil': 6296,\n",
       " 'servant': 25674,\n",
       " 'ran': 23286,\n",
       " 'cabinet': 5328,\n",
       " 'anti': 2689,\n",
       " 'unit': 29957,\n",
       " 'clears': 6391,\n",
       " 'reuters': 24354,\n",
       " 'cameraman': 5418,\n",
       " 'ordered': 20578,\n",
       " 'knew': 16255,\n",
       " 'doomed': 9386,\n",
       " 'realize': 23455,\n",
       " 'refuses': 23727,\n",
       " 'body': 4573,\n",
       " '14': 210,\n",
       " 'found': 11869,\n",
       " 'trunk': 29437,\n",
       " 'latest': 16562,\n",
       " 'ransom': 23313,\n",
       " 'paid': 20939,\n",
       " 'victim': 30531,\n",
       " 'cop': 7326,\n",
       " 'quits': 23104,\n",
       " 'prez': 22442,\n",
       " 'dissolves': 9190,\n",
       " 'suspect': 27990,\n",
       " 'elite': 10000,\n",
       " 'task': 28347,\n",
       " 'force': 11758,\n",
       " 'warns': 30918,\n",
       " 'plan': 21825,\n",
       " 'facilities': 10980,\n",
       " '2006': 508,\n",
       " 'nobel': 19855,\n",
       " 'laureate': 16600,\n",
       " 'aleksander': 2277,\n",
       " 'solzhenitsyn': 26733,\n",
       " 'encircling': 10162,\n",
       " 'effect': 9879,\n",
       " 'schools': 25301,\n",
       " 'information': 14872,\n",
       " 'warfare': 30891,\n",
       " 'intriguing': 15231,\n",
       " 'cyberalliance': 7910,\n",
       " 'estonian': 10509,\n",
       " 'computer': 6886,\n",
       " 'experts': 10818,\n",
       " 'heading': 13512,\n",
       " 'keep': 16014,\n",
       " 'networks': 19576,\n",
       " 'running': 24847,\n",
       " 'amid': 2468,\n",
       " 'intense': 15105,\n",
       " 'confrontation': 7013,\n",
       " 'take': 28231,\n",
       " 'control': 7250,\n",
       " 'seaports': 25435,\n",
       " 'airports': 2202,\n",
       " 'denies': 8489,\n",
       " 'quarter': 23052,\n",
       " 'blame': 4397,\n",
       " 'poll': 22035,\n",
       " 'choice': 6168,\n",
       " 'defence': 8303,\n",
       " 'witness': 31368,\n",
       " 'tbilisi': 28388,\n",
       " 'breach': 4874,\n",
       " 'agreement': 2109,\n",
       " 'ddos': 8097,\n",
       " 'came': 5413,\n",
       " 'sources': 26806,\n",
       " 'missions': 18550,\n",
       " 'soon': 26768,\n",
       " 'hits': 13861,\n",
       " 'wwiii': 31564,\n",
       " 'elephants': 9975,\n",
       " 'extinct': 10896,\n",
       " '2020': 532,\n",
       " 'convoy': 7295,\n",
       " 'violating': 30613,\n",
       " 'poland': 21995,\n",
       " 'agree': 2105,\n",
       " 'missle': 18551,\n",
       " 'deal': 8116,\n",
       " 'interesting': 15138,\n",
       " 'expected': 10789,\n",
       " 'resign': 24173,\n",
       " 'face': 10967,\n",
       " 'impeachment': 14526,\n",
       " 'exaggerating': 10661,\n",
       " 'death': 8131,\n",
       " 'toll': 28950,\n",
       " 'human': 14187,\n",
       " 'rights': 24507,\n",
       " 'conquer': 7060,\n",
       " 'tblisi': 28389,\n",
       " 'bet': 4169,\n",
       " 'seriously': 25669,\n",
       " 'rushdie': 24862,\n",
       " 'random': 23296,\n",
       " 'house': 14116,\n",
       " 'refusal': 23724,\n",
       " 'publish': 22852,\n",
       " 'novel': 19999,\n",
       " 'fear': 11205,\n",
       " 'muslim': 19102,\n",
       " 'retaliation': 24302,\n",
       " 'moscow': 18858,\n",
       " 'made': 17427,\n",
       " 'plans': 21838,\n",
       " 'months': 18777,\n",
       " 'ago': 2099,\n",
       " 'exaggerated': 10660,\n",
       " '44': 1013,\n",
       " 'originally': 20622,\n",
       " 'compared': 6802,\n",
       " '2000': 499,\n",
       " 'swedish': 28073,\n",
       " 'wrestler': 31519,\n",
       " 'ara': 2883,\n",
       " 'abrahamian': 1642,\n",
       " 'throws': 28778,\n",
       " 'hissy': 13841,\n",
       " 'fit': 11508,\n",
       " 'osetia': 20659,\n",
       " '89': 1442,\n",
       " 'pictures': 21681,\n",
       " 'soldier': 26695,\n",
       " 'admit': 1913,\n",
       " 'legalise': 16726,\n",
       " 'missile': 18544,\n",
       " 'inside': 14987,\n",
       " 'pakistan': 20960,\n",
       " 'may': 17926,\n",
       " 'launched': 16588,\n",
       " 'cia': 6240,\n",
       " 'philippines': 21598,\n",
       " 'peace': 21298,\n",
       " 'advocate': 1979,\n",
       " 'say': 25176,\n",
       " 'muslims': 19103,\n",
       " 'need': 19462,\n",
       " 'assurance': 3197,\n",
       " 'christians': 6209,\n",
       " 'convert': 7279,\n",
       " 'agreed': 2107,\n",
       " 'preliminary': 22345,\n",
       " 'controversial': 7257,\n",
       " 'shield': 25932,\n",
       " 'darfur': 8032,\n",
       " 'rebels': 23496,\n",
       " 'accuse': 1757,\n",
       " 'sudan': 27735,\n",
       " 'mounting': 18917,\n",
       " 'major': 17523,\n",
       " 'forget': 11802,\n",
       " 'territorial': 28567,\n",
       " 'integrity': 15092,\n",
       " 'taliban': 28252,\n",
       " 'wages': 30792,\n",
       " 'workers': 31444,\n",
       " 'saudi': 25143,\n",
       " 'arabia': 2885,\n",
       " 'mother': 18875,\n",
       " 'moves': 18939,\n",
       " 'block': 4471,\n",
       " 'child': 6109,\n",
       " 'marriage': 17770,\n",
       " 'reporter': 24060,\n",
       " 'sniper': 26589,\n",
       " 'live': 17076,\n",
       " 'broadcast': 5002,\n",
       " 'nigeria': 19731,\n",
       " 'handed': 13280,\n",
       " 'potentially': 22202,\n",
       " 'rich': 24460,\n",
       " 'bakassi': 3628,\n",
       " 'peninsula': 21388,\n",
       " 'cameroon': 5423,\n",
       " 'product': 22565,\n",
       " 'imperial': 14535,\n",
       " 'drive': 9561,\n",
       " 'local': 17125,\n",
       " 'conflicts': 7007,\n",
       " 'confict': 6979,\n",
       " 'set': 25693,\n",
       " 'back': 3529,\n",
       " 'relations': 23856,\n",
       " 'guardian': 13019,\n",
       " 'co': 6499,\n",
       " 'uk': 29661,\n",
       " 'bank': 3704,\n",
       " 'analyst': 2539,\n",
       " 'forecast': 11769,\n",
       " 'days': 8085,\n",
       " 'early': 9735,\n",
       " 'apparently': 2803,\n",
       " 'sabotaging': 24909,\n",
       " 'infrastructure': 14884,\n",
       " 'cripple': 7663,\n",
       " 'already': 2385,\n",
       " 'battered': 3873,\n",
       " 'non': 19889,\n",
       " 'media': 18031,\n",
       " 'photos': 21635,\n",
       " 'business': 5260,\n",
       " 'week': 31066,\n",
       " 'edge': 9839,\n",
       " 'struggle': 27580,\n",
       " 'access': 1707,\n",
       " 'caspian': 5672,\n",
       " '35': 870,\n",
       " 'billion': 4259,\n",
       " 'barrels': 3791,\n",
       " 'trillions': 29358,\n",
       " 'cubic': 7806,\n",
       " 'feet': 11250,\n",
       " 'gas': 12313,\n",
       " 'go': 12652,\n",
       " 'unpunished': 30051,\n",
       " 'government': 12772,\n",
       " 'accused': 1758,\n",
       " 'creating': 7593,\n",
       " 'laws': 16624,\n",
       " 'chilling': 6128,\n",
       " 'freedom': 11959,\n",
       " 'expression': 10872,\n",
       " 'critical': 7678,\n",
       " 'committee': 6758,\n",
       " 'italian': 15469,\n",
       " 'lashed': 16548,\n",
       " 'influential': 14863,\n",
       " 'catholic': 5731,\n",
       " 'magazine': 17449,\n",
       " 'suggested': 27769,\n",
       " 'fascism': 11131,\n",
       " 'might': 18333,\n",
       " 'resurfacing': 24281,\n",
       " 'within': 31362,\n",
       " 'fakes': 11041,\n",
       " 'girlfriend': 12560,\n",
       " 'ethnic': 10530,\n",
       " 'minority': 18455,\n",
       " 'criticism': 7684,\n",
       " 'valid': 30343,\n",
       " 'general': 12397,\n",
       " 'threatens': 28748,\n",
       " 'demands': 8434,\n",
       " 'withdraws': 31356,\n",
       " 'inspect': 15006,\n",
       " 'polish': 22016,\n",
       " 'site': 26295,\n",
       " 'fueled': 12092,\n",
       " 'rush': 24861,\n",
       " 'energy': 10222,\n",
       " 'resources': 24205,\n",
       " 'mom': 18702,\n",
       " 'missing': 18546,\n",
       " 'gay': 12345,\n",
       " '21': 565,\n",
       " 'cheerleader': 6042,\n",
       " 'looking': 17194,\n",
       " 'soviet': 26825,\n",
       " 'rule': 24819,\n",
       " 'word': 31431,\n",
       " 'propaganda': 22664,\n",
       " 'learnt': 16687,\n",
       " 'powerful': 22232,\n",
       " 'regaining': 23735,\n",
       " 'provinces': 22775,\n",
       " 'ministers': 18444,\n",
       " 'building': 5127,\n",
       " 'national': 19293,\n",
       " 'dna': 9281,\n",
       " 'database': 8055,\n",
       " 'stealth': 27291,\n",
       " 'retaining': 24294,\n",
       " 'profiles': 22579,\n",
       " 'nearly': 19445,\n",
       " '40000': 955,\n",
       " 'never': 19601,\n",
       " 'convicted': 7286,\n",
       " 'crime': 7638,\n",
       " 'rivals': 24565,\n",
       " 'remove': 23956,\n",
       " 'pipelines': 21756,\n",
       " 'stand': 27199,\n",
       " 'chinese': 6143,\n",
       " 'pollution': 22054,\n",
       " 'really': 23460,\n",
       " 'looks': 17195,\n",
       " 'hacker': 13153,\n",
       " 'kidnaps': 16145,\n",
       " 'tortures': 29042,\n",
       " 'informant': 14870,\n",
       " 'posts': 22189,\n",
       " 'picture': 21679,\n",
       " 'warning': 30916,\n",
       " 'others': 20673,\n",
       " 'officials': 20370,\n",
       " 'presence': 22374,\n",
       " 'become': 3962,\n",
       " 'permanent': 21458,\n",
       " 'johann': 15713,\n",
       " 'hari': 13378,\n",
       " 'stop': 27431,\n",
       " 'cowards': 7536,\n",
       " 'islam': 15415,\n",
       " 'redditors': 23629,\n",
       " 'generally': 12400,\n",
       " 'supportive': 27908,\n",
       " 'americas': 2463,\n",
       " 'seize': 25542,\n",
       " 'depot': 8565,\n",
       " 'unenforceable': 29870,\n",
       " 'encourage': 10175,\n",
       " 'cops': 7335,\n",
       " 'escalate': 10462,\n",
       " 'tactics': 28200,\n",
       " 'tragedy': 29148,\n",
       " 'occurs': 20321,\n",
       " 'restricted': 24260,\n",
       " 'maldives': 17557,\n",
       " 'constitution': 7133,\n",
       " '190000': 382,\n",
       " 'contractors': 7226,\n",
       " 'working': 31446,\n",
       " 'great': 12870,\n",
       " 'resource': 24204,\n",
       " 'underway': 29837,\n",
       " 'mainly': 17504,\n",
       " 'middle': 18315,\n",
       " 'east': 9761,\n",
       " 'also': 2387,\n",
       " 'smaller': 26499,\n",
       " 'skirmishes': 26350,\n",
       " 'scattered': 25242,\n",
       " 'around': 3001,\n",
       " 'disguised': 9055,\n",
       " 'many': 17681,\n",
       " 'global': 12612,\n",
       " 'terror': 28570,\n",
       " 'tour': 29074,\n",
       " 'undercuts': 29786,\n",
       " 'version': 30483,\n",
       " 'fires': 11473,\n",
       " 'satellite': 25123,\n",
       " 'space': 26838,\n",
       " 'ss': 27125,\n",
       " 'missiles': 18545,\n",
       " 'tornado': 29022,\n",
       " 'bus': 5244,\n",
       " 'captured': 5556,\n",
       " 'one': 20462,\n",
       " 'passengers': 21173,\n",
       " 'leave': 16698,\n",
       " 'little': 17073,\n",
       " 'girl': 12559,\n",
       " 'ugly': 29653,\n",
       " 'prison': 22492,\n",
       " 'majority': 17525,\n",
       " 'female': 11265,\n",
       " 'prisoners': 22494,\n",
       " 'serving': 25689,\n",
       " '20': 497,\n",
       " 'sentences': 25622,\n",
       " 'rape': 23321,\n",
       " 'left': 16717,\n",
       " 'family': 11074,\n",
       " 'shattered': 25865,\n",
       " 'resigning': 24177,\n",
       " 'avoid': 3434,\n",
       " 'battle': 3879,\n",
       " 'harm': 13383,\n",
       " 'interests': 15140,\n",
       " 'mayor': 17934,\n",
       " 'asks': 3106,\n",
       " 'visit': 30650,\n",
       " 'town': 29097,\n",
       " 'option': 20549,\n",
       " 'parliamentarian': 21113,\n",
       " 'situation': 26302,\n",
       " 'continues': 7212,\n",
       " 'quest': 23078,\n",
       " 'prize': 22515,\n",
       " 'money': 18727,\n",
       " 'mi5': 18266,\n",
       " 'seeks': 25519,\n",
       " 'spies': 26968,\n",
       " 'porn': 22115,\n",
       " 'channel': 5939,\n",
       " 'lets': 16819,\n",
       " 'canadians': 5451,\n",
       " 'strut': 27585,\n",
       " 'stuff': 27603,\n",
       " 'dangerous': 8012,\n",
       " 'neighbor': 19500,\n",
       " 'vladimir': 30680,\n",
       " 'takes': 28239,\n",
       " 'powerless': 22234,\n",
       " 'opinion': 20515,\n",
       " 'page': 20934,\n",
       " 'saner': 25069,\n",
       " 'hour': 14112,\n",
       " 'saakashvili': 24899,\n",
       " 'eats': 9776,\n",
       " 'tie': 28824,\n",
       " 'chicken': 6097,\n",
       " 'animal': 2613,\n",
       " 'rfid': 24435,\n",
       " 'surveillance': 27975,\n",
       " 'arrives': 3022,\n",
       " 'given': 12570,\n",
       " 'order': 20577,\n",
       " 'everyone': 10624,\n",
       " 'must': 19105,\n",
       " 'grows': 12987,\n",
       " 'genes': 12413,\n",
       " 'democratic': 8447,\n",
       " 'shuts': 26111,\n",
       " 'opposition': 20530,\n",
       " 'owned': 20880,\n",
       " 'assaults': 3146,\n",
       " 'kidnappings': 16144,\n",
       " 'killings': 16158,\n",
       " 'doubled': 9416,\n",
       " 'past': 21186,\n",
       " 'five': 11517,\n",
       " 'raid': 23214,\n",
       " 'base': 3810,\n",
       " 'denmark': 8492,\n",
       " '54': 1139,\n",
       " 'make': 17529,\n",
       " 'rapists': 23330,\n",
       " 'practically': 22249,\n",
       " 'seizes': 25544,\n",
       " 'vehicles': 30428,\n",
       " 'kosovo': 16325,\n",
       " 'near': 19440,\n",
       " 'kabul': 15880,\n",
       " 'schrder': 25302,\n",
       " 'lambasted': 16458,\n",
       " 'blaming': 4400,\n",
       " 'system': 28170,\n",
       " 'magic': 17456,\n",
       " 'pudding': 22859,\n",
       " 'run': 24840,\n",
       " 'arrested': 3015,\n",
       " 'locked': 17137,\n",
       " 'hours': 14115,\n",
       " 'photo': 21621,\n",
       " 'van': 30364,\n",
       " 'ignoring': 14407,\n",
       " 'entry': 10354,\n",
       " 'sign': 26172,\n",
       " 'ten': 28509,\n",
       " 'totalitarian': 29054,\n",
       " 'wasteland': 30959,\n",
       " 'finally': 11408,\n",
       " 'image': 14457,\n",
       " 'mind': 18410,\n",
       " 'michael': 18273,\n",
       " 'pic': 21662,\n",
       " 'york': 31726,\n",
       " 'laser': 16544,\n",
       " 'graffiti': 12804,\n",
       " 'artist': 3050,\n",
       " 'detained': 8685,\n",
       " 'indefinitely': 14717,\n",
       " 'beijing': 4032,\n",
       " 'tibet': 28807,\n",
       " 'art': 3036,\n",
       " 'isolated': 15446,\n",
       " 'maintain': 17508,\n",
       " 'everybody': 10622,\n",
       " 'loves': 17260,\n",
       " 'offshore': 20380,\n",
       " 'wind': 31280,\n",
       " 'spain': 26850,\n",
       " 'blaze': 4422,\n",
       " 'engulfs': 10254,\n",
       " 'egyptian': 9906,\n",
       " 'parliament': 21112,\n",
       " 'ken': 16024,\n",
       " 'haywood': 13484,\n",
       " 'whose': 31209,\n",
       " 'threat': 28741,\n",
       " 'emails': 10030,\n",
       " 'serial': 25666,\n",
       " 'bomb': 4620,\n",
       " 'blasts': 4417,\n",
       " '102': 60,\n",
       " 'grandma': 12820,\n",
       " 'oldest': 20422,\n",
       " 'person': 21493,\n",
       " 'facebook': 10968,\n",
       " '16000': 283,\n",
       " 'fine': 11423,\n",
       " 'british': 4991,\n",
       " 'woman': 31398,\n",
       " 'caught': 5742,\n",
       " 'sharing': 25849,\n",
       " 'game': 12254,\n",
       " 'online': 20467,\n",
       " 'brazil': 4869,\n",
       " 'play': 21863,\n",
       " 'defend': 8305,\n",
       " 'recently': 23530,\n",
       " 'discovered': 9014,\n",
       " 'freezes': 11985,\n",
       " 'ties': 28830,\n",
       " 'driven': 9562,\n",
       " 'shai': 25783,\n",
       " 'agassi': 2069,\n",
       " 'audacious': 3308,\n",
       " 'put': 22967,\n",
       " 'electric': 9953,\n",
       " 'cars': 5635,\n",
       " 'road': 24580,\n",
       " 'august': 3325,\n",
       " '19th': 483,\n",
       " '2003': 505,\n",
       " 'bombing': 4629,\n",
       " 'headquarters': 13517,\n",
       " 'elderly': 9942,\n",
       " 'labor': 16403,\n",
       " 'education': 9868,\n",
       " 'applying': 2836,\n",
       " 'permission': 21461,\n",
       " 'sets': 25696,\n",
       " ...}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 866 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer.fit(RedditNews['News'].values)\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-cb6415104b11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_words_bigrams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Number of features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26 ms\n"
     ]
    }
   ],
   "source": [
    "input_dim = data_words_bigrams.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNhtKTbzPEwz7PyaEe0FkIO",
   "collapsed_sections": [],
   "name": "RNN - Meli.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
