{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4dLP23xZmpC"
   },
   "outputs": [],
   "source": [
    "# Importar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import zipfile\n",
    "from datetime import date\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nzv66BqFbl92"
   },
   "outputs": [],
   "source": [
    "#Importar los datasets\n",
    "url_embeddings_average_individual = zipfile.ZipFile('C:/Users/dalessam/Downloads/text_mining/Data/embeddings_average_individual.zip')\n",
    "url_embeddings_sum_individual = zipfile.ZipFile('C:/Users/dalessam/Downloads/text_mining/Data/embeddings_sum_individual.zip')\n",
    "\n",
    "embeddings_average_individual = pd.read_csv(url_embeddings_average_individual.open('embeddings_average_individual.csv'))\n",
    "embeddings_sum_individual =pd.read_csv(url_embeddings_sum_individual.open('embeddings_sum_individual.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAXOJcEcbmed"
   },
   "outputs": [],
   "source": [
    "# Selecciono la fecha para la cual hago el corte de train y test\n",
    "training_end = pd.to_datetime(\"2014-12-31\")\n",
    "num_training = len(embeddings_average_individual[pd.to_datetime(embeddings_average_individual[\"Date\"]) <= training_end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVoOQQrAbpy2"
   },
   "outputs": [],
   "source": [
    "# Selecciono el archivo con el que se corre el modelo\n",
    "data = embeddings_average_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iGzSZUEzbvLs"
   },
   "outputs": [],
   "source": [
    "# Se separa en train y test\n",
    "x_train = data.drop([data.columns[0],\"Top\",\"Label\", \"Date\"], axis=1)[:num_training]\n",
    "x_test = data.drop([data.columns[0],\"Top\",'Label', 'Date'], axis=1)[num_training:]\n",
    "y_train = data[\"Label\"].values[:num_training]\n",
    "y_test = data[\"Label\"].values[num_training:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vlllQBuXsjDh"
   },
   "source": [
    "Se cambia el shape de train y test para el input:\n",
    "https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 915,
     "status": "ok",
     "timestamp": 1589753651752,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "EdyQX-X3mEde",
    "outputId": "3f319356-30f7-414a-8ad8-c5997b17efcd",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40268, 1, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_array = x_train.to_numpy()\n",
    "reshape_x_train = x_train_array.reshape(40268, 1, 300)\n",
    "reshape_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1207,
     "status": "ok",
     "timestamp": 1589753654795,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "TiRmnmDvsagi",
    "outputId": "1fcf3a9b-7bd2-4981-e024-828e7b11aa1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9450, 1, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_array = x_test.to_numpy()\n",
    "reshape_x_test = x_test_array.reshape(9450, 1, 300)\n",
    "reshape_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJZBoIl-nFDg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\dalessam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\dalessam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\dalessam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\dalessam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\dalessam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\dalessam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from numpy.testing import assert_allclose\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIKq7z8tnIWl"
   },
   "outputs": [],
   "source": [
    "n_units = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_units, input_shape=(1,300), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(n_units, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# define the checkpoint\n",
    "filepath=\"word2vec-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3944,
     "status": "ok",
     "timestamp": 1589755592715,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "JsHgNLFnnTLN",
    "outputId": "4c22910d-c7b2-4dff-eb32-15c2574174ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dalessam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "40268/40268 [==============================] - 2s 43us/step - loss: 0.6908 - accuracy: 0.5375\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.69077, saving model to word2vec-01-0.6908.hdf5\n",
      "Epoch 2/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6901 - accuracy: 0.5393\n",
      "\n",
      "Epoch 00002: loss improved from 0.69077 to 0.69008, saving model to word2vec-02-0.6901.hdf5\n",
      "Epoch 3/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6899 - accuracy: 0.5393\n",
      "\n",
      "Epoch 00003: loss improved from 0.69008 to 0.68993, saving model to word2vec-03-0.6899.hdf5\n",
      "Epoch 4/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6898 - accuracy: 0.5393\n",
      "\n",
      "Epoch 00004: loss improved from 0.68993 to 0.68978, saving model to word2vec-04-0.6898.hdf5\n",
      "Epoch 5/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6897 - accuracy: 0.5393\n",
      "\n",
      "Epoch 00005: loss improved from 0.68978 to 0.68971, saving model to word2vec-05-0.6897.hdf5\n",
      "Epoch 6/50\n",
      "40268/40268 [==============================] - 1s 19us/step - loss: 0.6895 - accuracy: 0.5393\n",
      "\n",
      "Epoch 00006: loss improved from 0.68971 to 0.68947, saving model to word2vec-06-0.6895.hdf5\n",
      "Epoch 7/50\n",
      "40268/40268 [==============================] - 1s 21us/step - loss: 0.6891 - accuracy: 0.5396\n",
      "\n",
      "Epoch 00007: loss improved from 0.68947 to 0.68910, saving model to word2vec-07-0.6891.hdf5\n",
      "Epoch 8/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6888 - accuracy: 0.5398\n",
      "\n",
      "Epoch 00008: loss improved from 0.68910 to 0.68878, saving model to word2vec-08-0.6888.hdf5\n",
      "Epoch 9/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6883 - accuracy: 0.5411\n",
      "\n",
      "Epoch 00009: loss improved from 0.68878 to 0.68830, saving model to word2vec-09-0.6883.hdf5\n",
      "Epoch 10/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6880 - accuracy: 0.5426\n",
      "\n",
      "Epoch 00010: loss improved from 0.68830 to 0.68800, saving model to word2vec-10-0.6880.hdf5\n",
      "Epoch 11/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6876 - accuracy: 0.5439\n",
      "\n",
      "Epoch 00011: loss improved from 0.68800 to 0.68760, saving model to word2vec-11-0.6876.hdf5\n",
      "Epoch 12/50\n",
      "40268/40268 [==============================] - 1s 21us/step - loss: 0.6873 - accuracy: 0.5432\n",
      "\n",
      "Epoch 00012: loss improved from 0.68760 to 0.68726, saving model to word2vec-12-0.6873.hdf5\n",
      "Epoch 13/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6869 - accuracy: 0.5458\n",
      "\n",
      "Epoch 00013: loss improved from 0.68726 to 0.68689, saving model to word2vec-13-0.6869.hdf5\n",
      "Epoch 14/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6869 - accuracy: 0.5462\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.68689\n",
      "Epoch 15/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6866 - accuracy: 0.5456\n",
      "\n",
      "Epoch 00015: loss improved from 0.68689 to 0.68661, saving model to word2vec-15-0.6866.hdf5\n",
      "Epoch 16/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6866 - accuracy: 0.5451\n",
      "\n",
      "Epoch 00016: loss improved from 0.68661 to 0.68656, saving model to word2vec-16-0.6866.hdf5\n",
      "Epoch 17/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6863 - accuracy: 0.5474\n",
      "\n",
      "Epoch 00017: loss improved from 0.68656 to 0.68626, saving model to word2vec-17-0.6863.hdf5\n",
      "Epoch 18/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6863 - accuracy: 0.5471\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.68626\n",
      "Epoch 19/50\n",
      "40268/40268 [==============================] - 1s 21us/step - loss: 0.6860 - accuracy: 0.5498\n",
      "\n",
      "Epoch 00019: loss improved from 0.68626 to 0.68598, saving model to word2vec-19-0.6860.hdf5\n",
      "Epoch 20/50\n",
      "40268/40268 [==============================] - 1s 21us/step - loss: 0.6857 - accuracy: 0.5486\n",
      "\n",
      "Epoch 00020: loss improved from 0.68598 to 0.68569, saving model to word2vec-20-0.6857.hdf5\n",
      "Epoch 21/50\n",
      "40268/40268 [==============================] - 1s 21us/step - loss: 0.6854 - accuracy: 0.5489\n",
      "\n",
      "Epoch 00021: loss improved from 0.68569 to 0.68544, saving model to word2vec-21-0.6854.hdf5\n",
      "Epoch 22/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6856 - accuracy: 0.5458\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.68544\n",
      "Epoch 23/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6850 - accuracy: 0.5491\n",
      "\n",
      "Epoch 00023: loss improved from 0.68544 to 0.68501, saving model to word2vec-23-0.6850.hdf5\n",
      "Epoch 24/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6850 - accuracy: 0.5489\n",
      "\n",
      "Epoch 00024: loss improved from 0.68501 to 0.68500, saving model to word2vec-24-0.6850.hdf5\n",
      "Epoch 25/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6846 - accuracy: 0.5517\n",
      "\n",
      "Epoch 00025: loss improved from 0.68500 to 0.68461, saving model to word2vec-25-0.6846.hdf5\n",
      "Epoch 26/50\n",
      "40268/40268 [==============================] - 1s 19us/step - loss: 0.6846 - accuracy: 0.5505\n",
      "\n",
      "Epoch 00026: loss improved from 0.68461 to 0.68458, saving model to word2vec-26-0.6846.hdf5\n",
      "Epoch 27/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6843 - accuracy: 0.5506\n",
      "\n",
      "Epoch 00027: loss improved from 0.68458 to 0.68429, saving model to word2vec-27-0.6843.hdf5\n",
      "Epoch 28/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6841 - accuracy: 0.5512\n",
      "\n",
      "Epoch 00028: loss improved from 0.68429 to 0.68413, saving model to word2vec-28-0.6841.hdf5\n",
      "Epoch 29/50\n",
      "40268/40268 [==============================] - 1s 21us/step - loss: 0.6838 - accuracy: 0.5528\n",
      "\n",
      "Epoch 00029: loss improved from 0.68413 to 0.68379, saving model to word2vec-29-0.6838.hdf5\n",
      "Epoch 30/50\n",
      "40268/40268 [==============================] - 1s 21us/step - loss: 0.6836 - accuracy: 0.5545\n",
      "\n",
      "Epoch 00030: loss improved from 0.68379 to 0.68362, saving model to word2vec-30-0.6836.hdf5\n",
      "Epoch 31/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6834 - accuracy: 0.5540\n",
      "\n",
      "Epoch 00031: loss improved from 0.68362 to 0.68339, saving model to word2vec-31-0.6834.hdf5\n",
      "Epoch 32/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6829 - accuracy: 0.5551\n",
      "\n",
      "Epoch 00032: loss improved from 0.68339 to 0.68293, saving model to word2vec-32-0.6829.hdf5\n",
      "Epoch 33/50\n",
      "40268/40268 [==============================] - 1s 21us/step - loss: 0.6825 - accuracy: 0.5558\n",
      "\n",
      "Epoch 00033: loss improved from 0.68293 to 0.68245, saving model to word2vec-33-0.6825.hdf5\n",
      "Epoch 34/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6825 - accuracy: 0.5567\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.68245\n",
      "Epoch 35/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6818 - accuracy: 0.5576\n",
      "\n",
      "Epoch 00035: loss improved from 0.68245 to 0.68182, saving model to word2vec-35-0.6818.hdf5\n",
      "Epoch 36/50\n",
      "40268/40268 [==============================] - 1s 19us/step - loss: 0.6813 - accuracy: 0.5586\n",
      "\n",
      "Epoch 00036: loss improved from 0.68182 to 0.68131, saving model to word2vec-36-0.6813.hdf5\n",
      "Epoch 37/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6809 - accuracy: 0.5603\n",
      "\n",
      "Epoch 00037: loss improved from 0.68131 to 0.68085, saving model to word2vec-37-0.6809.hdf5\n",
      "Epoch 38/50\n",
      "40268/40268 [==============================] - 1s 21us/step - loss: 0.6804 - accuracy: 0.5606\n",
      "\n",
      "Epoch 00038: loss improved from 0.68085 to 0.68035, saving model to word2vec-38-0.6804.hdf5\n",
      "Epoch 39/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6800 - accuracy: 0.5598\n",
      "\n",
      "Epoch 00039: loss improved from 0.68035 to 0.68004, saving model to word2vec-39-0.6800.hdf5\n",
      "Epoch 40/50\n",
      "40268/40268 [==============================] - 1s 21us/step - loss: 0.6801 - accuracy: 0.5587\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.68004\n",
      "Epoch 41/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6791 - accuracy: 0.5627\n",
      "\n",
      "Epoch 00041: loss improved from 0.68004 to 0.67905, saving model to word2vec-41-0.6791.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "40268/40268 [==============================] - 1s 21us/step - loss: 0.6786 - accuracy: 0.5664\n",
      "\n",
      "Epoch 00042: loss improved from 0.67905 to 0.67858, saving model to word2vec-42-0.6786.hdf5\n",
      "Epoch 43/50\n",
      "40268/40268 [==============================] - 1s 21us/step - loss: 0.6775 - accuracy: 0.5651\n",
      "\n",
      "Epoch 00043: loss improved from 0.67858 to 0.67750, saving model to word2vec-43-0.6775.hdf5\n",
      "Epoch 44/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6776 - accuracy: 0.5669\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.67750\n",
      "Epoch 45/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6767 - accuracy: 0.5691\n",
      "\n",
      "Epoch 00045: loss improved from 0.67750 to 0.67671, saving model to word2vec-45-0.6767.hdf5\n",
      "Epoch 46/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6765 - accuracy: 0.5679\n",
      "\n",
      "Epoch 00046: loss improved from 0.67671 to 0.67654, saving model to word2vec-46-0.6765.hdf5\n",
      "Epoch 47/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6757 - accuracy: 0.5713\n",
      "\n",
      "Epoch 00047: loss improved from 0.67654 to 0.67566, saving model to word2vec-47-0.6757.hdf5\n",
      "Epoch 48/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6752 - accuracy: 0.5700\n",
      "\n",
      "Epoch 00048: loss improved from 0.67566 to 0.67516, saving model to word2vec-48-0.6752.hdf5\n",
      "Epoch 49/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6744 - accuracy: 0.5713\n",
      "\n",
      "Epoch 00049: loss improved from 0.67516 to 0.67440, saving model to word2vec-49-0.6744.hdf5\n",
      "Epoch 50/50\n",
      "40268/40268 [==============================] - 1s 20us/step - loss: 0.6743 - accuracy: 0.5722\n",
      "\n",
      "Epoch 00050: loss improved from 0.67440 to 0.67425, saving model to word2vec-50-0.6743.hdf5\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1, 10)             12440     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 10)                840       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 13,291\n",
      "Trainable params: 13,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(reshape_x_train, y_train, epochs=50, batch_size=500, callbacks=callbacks_list)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1589755595730,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "mdsR4Qngv5Q1",
    "outputId": "433bbcf6-d6eb-44c1-a1bb-afee72ac0ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.513968\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(reshape_x_test, y_test, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVoOQQrAbpy2"
   },
   "outputs": [],
   "source": [
    "# Selecciono el archivo con el que se corre el modelo\n",
    "data = embeddings_sum_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iGzSZUEzbvLs"
   },
   "outputs": [],
   "source": [
    "# Se separa en train y test\n",
    "x_train = data.drop([data.columns[0],\"Top\",\"Label\", \"Date\"], axis=1)[:num_training]\n",
    "x_test = data.drop([data.columns[0],\"Top\",'Label', 'Date'], axis=1)[num_training:]\n",
    "y_train = data[\"Label\"].values[:num_training]\n",
    "y_test = data[\"Label\"].values[num_training:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 915,
     "status": "ok",
     "timestamp": 1589753651752,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "EdyQX-X3mEde",
    "outputId": "3f319356-30f7-414a-8ad8-c5997b17efcd",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40268, 1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_array = x_train.to_numpy()\n",
    "reshape_x_train = x_train_array.reshape(40268, 1, 300)\n",
    "reshape_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1207,
     "status": "ok",
     "timestamp": 1589753654795,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "TiRmnmDvsagi",
    "outputId": "1fcf3a9b-7bd2-4981-e024-828e7b11aa1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9450, 1, 300)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_array = x_test.to_numpy()\n",
    "reshape_x_test = x_test_array.reshape(9450, 1, 300)\n",
    "reshape_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJZBoIl-nFDg",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from numpy.testing import assert_allclose\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIKq7z8tnIWl"
   },
   "outputs": [],
   "source": [
    "n_units = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_units, input_shape=(1,300), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(n_units, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# define the checkpoint\n",
    "filepath=\"word2vec-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3944,
     "status": "ok",
     "timestamp": 1589755592715,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "JsHgNLFnnTLN",
    "outputId": "4c22910d-c7b2-4dff-eb32-15c2574174ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40268/40268 [==============================] - 2s 42us/step - loss: 0.6907 - accuracy: 0.5365\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.69071, saving model to word2vec-01-0.6907.hdf5\n",
      "Epoch 2/50\n",
      "40268/40268 [==============================] - 1s 21us/step - loss: 0.6899 - accuracy: 0.5393\n",
      "\n",
      "Epoch 00002: loss improved from 0.69071 to 0.68992, saving model to word2vec-02-0.6899.hdf5\n",
      "Epoch 3/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6894 - accuracy: 0.5395\n",
      "\n",
      "Epoch 00003: loss improved from 0.68992 to 0.68940, saving model to word2vec-03-0.6894.hdf5\n",
      "Epoch 4/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6887 - accuracy: 0.5400\n",
      "\n",
      "Epoch 00004: loss improved from 0.68940 to 0.68867, saving model to word2vec-04-0.6887.hdf5\n",
      "Epoch 5/50\n",
      "40268/40268 [==============================] - 1s 24us/step - loss: 0.6875 - accuracy: 0.5436\n",
      "\n",
      "Epoch 00005: loss improved from 0.68867 to 0.68749, saving model to word2vec-05-0.6875.hdf5\n",
      "Epoch 6/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6864 - accuracy: 0.5471\n",
      "\n",
      "Epoch 00006: loss improved from 0.68749 to 0.68640, saving model to word2vec-06-0.6864.hdf5\n",
      "Epoch 7/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6843 - accuracy: 0.5540\n",
      "\n",
      "Epoch 00007: loss improved from 0.68640 to 0.68426, saving model to word2vec-07-0.6843.hdf5\n",
      "Epoch 8/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6821 - accuracy: 0.5604\n",
      "\n",
      "Epoch 00008: loss improved from 0.68426 to 0.68215, saving model to word2vec-08-0.6821.hdf5\n",
      "Epoch 9/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6791 - accuracy: 0.5666\n",
      "\n",
      "Epoch 00009: loss improved from 0.68215 to 0.67908, saving model to word2vec-09-0.6791.hdf5\n",
      "Epoch 10/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6761 - accuracy: 0.5744\n",
      "\n",
      "Epoch 00010: loss improved from 0.67908 to 0.67614, saving model to word2vec-10-0.6761.hdf5\n",
      "Epoch 11/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6723 - accuracy: 0.5818\n",
      "\n",
      "Epoch 00011: loss improved from 0.67614 to 0.67227, saving model to word2vec-11-0.6723.hdf5\n",
      "Epoch 12/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6692 - accuracy: 0.5852\n",
      "\n",
      "Epoch 00012: loss improved from 0.67227 to 0.66919, saving model to word2vec-12-0.6692.hdf5\n",
      "Epoch 13/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6671 - accuracy: 0.5898\n",
      "\n",
      "Epoch 00013: loss improved from 0.66919 to 0.66706, saving model to word2vec-13-0.6671.hdf5\n",
      "Epoch 14/50\n",
      "40268/40268 [==============================] - 1s 24us/step - loss: 0.6649 - accuracy: 0.5936\n",
      "\n",
      "Epoch 00014: loss improved from 0.66706 to 0.66490, saving model to word2vec-14-0.6649.hdf5\n",
      "Epoch 15/50\n",
      "40268/40268 [==============================] - 1s 24us/step - loss: 0.6598 - accuracy: 0.5975\n",
      "\n",
      "Epoch 00015: loss improved from 0.66490 to 0.65983, saving model to word2vec-15-0.6598.hdf5\n",
      "Epoch 16/50\n",
      "40268/40268 [==============================] - 1s 24us/step - loss: 0.6570 - accuracy: 0.6021\n",
      "\n",
      "Epoch 00016: loss improved from 0.65983 to 0.65702, saving model to word2vec-16-0.6570.hdf5\n",
      "Epoch 17/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6537 - accuracy: 0.6069\n",
      "\n",
      "Epoch 00017: loss improved from 0.65702 to 0.65373, saving model to word2vec-17-0.6537.hdf5\n",
      "Epoch 18/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6507 - accuracy: 0.6123\n",
      "\n",
      "Epoch 00018: loss improved from 0.65373 to 0.65069, saving model to word2vec-18-0.6507.hdf5\n",
      "Epoch 19/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6489 - accuracy: 0.6152\n",
      "\n",
      "Epoch 00019: loss improved from 0.65069 to 0.64891, saving model to word2vec-19-0.6489.hdf5\n",
      "Epoch 20/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6462 - accuracy: 0.6184\n",
      "\n",
      "Epoch 00020: loss improved from 0.64891 to 0.64624, saving model to word2vec-20-0.6462.hdf5\n",
      "Epoch 21/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6427 - accuracy: 0.6232\n",
      "\n",
      "Epoch 00021: loss improved from 0.64624 to 0.64266, saving model to word2vec-21-0.6427.hdf5\n",
      "Epoch 22/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6407 - accuracy: 0.6250\n",
      "\n",
      "Epoch 00022: loss improved from 0.64266 to 0.64070, saving model to word2vec-22-0.6407.hdf5\n",
      "Epoch 23/50\n",
      "40268/40268 [==============================] - 1s 24us/step - loss: 0.6409 - accuracy: 0.6260\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.64070\n",
      "Epoch 24/50\n",
      "40268/40268 [==============================] - 1s 21us/step - loss: 0.6373 - accuracy: 0.6277\n",
      "\n",
      "Epoch 00024: loss improved from 0.64070 to 0.63728, saving model to word2vec-24-0.6373.hdf5\n",
      "Epoch 25/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6357 - accuracy: 0.6323\n",
      "\n",
      "Epoch 00025: loss improved from 0.63728 to 0.63565, saving model to word2vec-25-0.6357.hdf5\n",
      "Epoch 26/50\n",
      "40268/40268 [==============================] - 1s 24us/step - loss: 0.6346 - accuracy: 0.6317\n",
      "\n",
      "Epoch 00026: loss improved from 0.63565 to 0.63459, saving model to word2vec-26-0.6346.hdf5\n",
      "Epoch 27/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6304 - accuracy: 0.6368\n",
      "\n",
      "Epoch 00027: loss improved from 0.63459 to 0.63041, saving model to word2vec-27-0.6304.hdf5\n",
      "Epoch 28/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6306 - accuracy: 0.6350\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.63041\n",
      "Epoch 29/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6272 - accuracy: 0.6389\n",
      "\n",
      "Epoch 00029: loss improved from 0.63041 to 0.62722, saving model to word2vec-29-0.6272.hdf5\n",
      "Epoch 30/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6250 - accuracy: 0.6438\n",
      "\n",
      "Epoch 00030: loss improved from 0.62722 to 0.62500, saving model to word2vec-30-0.6250.hdf5\n",
      "Epoch 31/50\n",
      "40268/40268 [==============================] - 1s 24us/step - loss: 0.6251 - accuracy: 0.6431\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.62500\n",
      "Epoch 32/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6240 - accuracy: 0.6436\n",
      "\n",
      "Epoch 00032: loss improved from 0.62500 to 0.62404, saving model to word2vec-32-0.6240.hdf5\n",
      "Epoch 33/50\n",
      "40268/40268 [==============================] - 1s 21us/step - loss: 0.6225 - accuracy: 0.6428\n",
      "\n",
      "Epoch 00033: loss improved from 0.62404 to 0.62245, saving model to word2vec-33-0.6225.hdf5\n",
      "Epoch 34/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6195 - accuracy: 0.6485\n",
      "\n",
      "Epoch 00034: loss improved from 0.62245 to 0.61955, saving model to word2vec-34-0.6195.hdf5\n",
      "Epoch 35/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6180 - accuracy: 0.6504\n",
      "\n",
      "Epoch 00035: loss improved from 0.61955 to 0.61802, saving model to word2vec-35-0.6180.hdf5\n",
      "Epoch 36/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6171 - accuracy: 0.6522\n",
      "\n",
      "Epoch 00036: loss improved from 0.61802 to 0.61713, saving model to word2vec-36-0.6171.hdf5\n",
      "Epoch 37/50\n",
      "40268/40268 [==============================] - 1s 24us/step - loss: 0.6151 - accuracy: 0.6526\n",
      "\n",
      "Epoch 00037: loss improved from 0.61713 to 0.61508, saving model to word2vec-37-0.6151.hdf5\n",
      "Epoch 38/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6132 - accuracy: 0.6543\n",
      "\n",
      "Epoch 00038: loss improved from 0.61508 to 0.61320, saving model to word2vec-38-0.6132.hdf5\n",
      "Epoch 39/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6116 - accuracy: 0.6552\n",
      "\n",
      "Epoch 00039: loss improved from 0.61320 to 0.61163, saving model to word2vec-39-0.6116.hdf5\n",
      "Epoch 40/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6088 - accuracy: 0.6592\n",
      "\n",
      "Epoch 00040: loss improved from 0.61163 to 0.60885, saving model to word2vec-40-0.6088.hdf5\n",
      "Epoch 41/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6091 - accuracy: 0.6572\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.60885\n",
      "Epoch 42/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6067 - accuracy: 0.6608\n",
      "\n",
      "Epoch 00042: loss improved from 0.60885 to 0.60667, saving model to word2vec-42-0.6067.hdf5\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6076 - accuracy: 0.6587\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.60667\n",
      "Epoch 44/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6049 - accuracy: 0.6600\n",
      "\n",
      "Epoch 00044: loss improved from 0.60667 to 0.60486, saving model to word2vec-44-0.6049.hdf5\n",
      "Epoch 45/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6063 - accuracy: 0.6597\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.60486\n",
      "Epoch 46/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6038 - accuracy: 0.6630\n",
      "\n",
      "Epoch 00046: loss improved from 0.60486 to 0.60381, saving model to word2vec-46-0.6038.hdf5\n",
      "Epoch 47/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6034 - accuracy: 0.6608\n",
      "\n",
      "Epoch 00047: loss improved from 0.60381 to 0.60338, saving model to word2vec-47-0.6034.hdf5\n",
      "Epoch 48/50\n",
      "40268/40268 [==============================] - 1s 22us/step - loss: 0.6026 - accuracy: 0.6619\n",
      "\n",
      "Epoch 00048: loss improved from 0.60338 to 0.60264, saving model to word2vec-48-0.6026.hdf5\n",
      "Epoch 49/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.6016 - accuracy: 0.6654\n",
      "\n",
      "Epoch 00049: loss improved from 0.60264 to 0.60161, saving model to word2vec-49-0.6016.hdf5\n",
      "Epoch 50/50\n",
      "40268/40268 [==============================] - 1s 23us/step - loss: 0.5986 - accuracy: 0.6644\n",
      "\n",
      "Epoch 00050: loss improved from 0.60161 to 0.59861, saving model to word2vec-50-0.5986.hdf5\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 1, 10)             12440     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 10)                840       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 13,291\n",
      "Trainable params: 13,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(reshape_x_train, y_train, epochs=50, batch_size=500, callbacks=callbacks_list)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1589755595730,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "mdsR4Qngv5Q1",
    "outputId": "433bbcf6-d6eb-44c1-a1bb-afee72ac0ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.506878\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(reshape_x_test, y_test, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNhtKTbzPEwz7PyaEe0FkIO",
   "collapsed_sections": [],
   "name": "RNN - Meli.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
