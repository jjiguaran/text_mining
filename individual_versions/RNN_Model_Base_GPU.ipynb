{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4dLP23xZmpC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "# Importar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import zipfile\n",
    "from datetime import date\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 999 µs\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exists\n",
      "time: 189 ms\n"
     ]
    }
   ],
   "source": [
    "exp_name = '7'\n",
    "folder = 'Resultados/' + exp_name\n",
    "my_file = Path(folder)\n",
    "if os.path.exists(my_file):\n",
    "    print('already exists')\n",
    "else:\n",
    "    os.makedirs(folder)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exists\n",
      "time: 176 ms\n"
     ]
    }
   ],
   "source": [
    "ch_folder = folder + '/Checkpoints'\n",
    "my_file = Path(ch_folder)\n",
    "if os.path.exists(my_file):\n",
    "    print('already exists')\n",
    "else:\n",
    "    os.makedirs(ch_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nzv66BqFbl92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>Label</th>\n",
       "      <th>Date</th>\n",
       "      <th>Top</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49716</th>\n",
       "      <td>-0.082072</td>\n",
       "      <td>0.099915</td>\n",
       "      <td>-0.015503</td>\n",
       "      <td>0.115560</td>\n",
       "      <td>-0.072611</td>\n",
       "      <td>0.070435</td>\n",
       "      <td>0.042613</td>\n",
       "      <td>-0.041026</td>\n",
       "      <td>0.012126</td>\n",
       "      <td>-0.020508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062215</td>\n",
       "      <td>-0.078471</td>\n",
       "      <td>0.046008</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>-0.071452</td>\n",
       "      <td>0.122559</td>\n",
       "      <td>0.07622</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49717</th>\n",
       "      <td>-0.064514</td>\n",
       "      <td>0.013916</td>\n",
       "      <td>-0.028976</td>\n",
       "      <td>0.058716</td>\n",
       "      <td>-0.078369</td>\n",
       "      <td>-0.057312</td>\n",
       "      <td>-0.077515</td>\n",
       "      <td>-0.234467</td>\n",
       "      <td>0.050751</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010498</td>\n",
       "      <td>0.081284</td>\n",
       "      <td>0.040283</td>\n",
       "      <td>-0.108978</td>\n",
       "      <td>0.033783</td>\n",
       "      <td>0.028870</td>\n",
       "      <td>0.03418</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "49716 -0.082072  0.099915 -0.015503  0.115560 -0.072611  0.070435  0.042613   \n",
       "49717 -0.064514  0.013916 -0.028976  0.058716 -0.078369 -0.057312 -0.077515   \n",
       "\n",
       "              7         8         9  ...       293       294       295  \\\n",
       "49716 -0.041026  0.012126 -0.020508  ... -0.062215 -0.078471  0.046008   \n",
       "49717 -0.234467  0.050751  0.020508  ... -0.010498  0.081284  0.040283   \n",
       "\n",
       "            296       297       298      299  Label       Date  Top  \n",
       "49716  0.005717 -0.071452  0.122559  0.07622      0 2008-08-08   24  \n",
       "49717 -0.108978  0.033783  0.028870  0.03418      0 2008-08-08   25  \n",
       "\n",
       "[2 rows x 303 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.39 s\n"
     ]
    }
   ],
   "source": [
    "#Importar los datasets\n",
    "url_embeddings_average_individual = zipfile.ZipFile('../Data/embeddings_average_individual.zip')\n",
    "url_embeddings_sum_individual = zipfile.ZipFile('../Data/embeddings_sum_individual.zip')\n",
    "\n",
    "embeddings_average_individual = pd.read_csv(url_embeddings_average_individual.open('embeddings_average_individual.csv'), index_col = 0)\n",
    "embeddings_sum_individual =pd.read_csv(url_embeddings_sum_individual.open('embeddings_sum_individual.csv'), index_col = 0)\n",
    "\n",
    "embeddings_average_individual['Date'] =  pd.to_datetime(embeddings_average_individual['Date'], format='%Y-%m-%d')\n",
    "# embeddings_average_individual.sort_values('Date', inplace=True)\n",
    "# embeddings_average_individual.reset_index(drop = True , inplace=True)\n",
    "\n",
    "embeddings_average_individual.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAXOJcEcbmed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 69 ms\n"
     ]
    }
   ],
   "source": [
    "# Selecciono la fecha para la cual hago el corte de train y test\n",
    "training_end = pd.to_datetime(\"2013-12-31\")\n",
    "num_training = len(embeddings_average_individual[(embeddings_average_individual[\"Date\"]) <= training_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 928 ms\n"
     ]
    }
   ],
   "source": [
    "# Selecciono el archivo con el que se corre el modelo\n",
    "data = embeddings_average_individual[embeddings_average_individual['Date']<='2014-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6300, 1, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 764 ms\n"
     ]
    }
   ],
   "source": [
    "# Se separa en train y test\n",
    "x_train = data.drop([\"Top\",\"Label\", \"Date\"], axis=1)[:num_training]\n",
    "x_test = data.drop([\"Top\",'Label', 'Date'], axis=1)[num_training:]\n",
    "y_train = data[\"Label\"].values[:num_training]\n",
    "y_test = data[\"Label\"].values[num_training:]\n",
    "\n",
    "\n",
    "x_train_array = x_train.to_numpy()\n",
    "reshape_x_train = x_train_array.reshape(len(x_train), 1, 300)\n",
    "reshape_x_train.shape\n",
    "\n",
    "x_test_array = x_test.to_numpy()\n",
    "reshape_x_test = x_test_array.reshape(len(x_test), 1, 300)\n",
    "reshape_x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir espacio de busqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 535 ms\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'units1': hp.choice('units1', [10, 64, 128, 256, 512]),\n",
    "    'units2': hp.choice('units2', [10, 64, 128, 256, 512]),\n",
    "                 \n",
    "    'dropout1': hp.choice('dropout1', [0.2,0.3,0.1]),\n",
    "    \n",
    "    'batch_size' : hp.choice('batch_size', [128,256,512]),\n",
    "    'nb_epochs' : hp.choice('nb_epochs', [50]),\n",
    "\n",
    "    'optimizer':  hp.choice('optimizer', [ 'adam','adadelta']),   \n",
    "    'activation': 'relu'    \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir busqueda bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 524 ms\n"
     ]
    }
   ],
   "source": [
    "#Objective function that hyperopt will minimize\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def objective(params):\n",
    "    \n",
    "#     import ml_metrics\n",
    "\n",
    "    \n",
    "    start = timer()\n",
    "    print ('Params testing: ', params)\n",
    "    print ('\\n ')\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(params['units1'], input_shape=(1,300), return_sequences=True))\n",
    "    model.add(Dropout(params['dropout1']))\n",
    "    model.add(LSTM(params['units2'], return_sequences=False))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    # compile the model\n",
    "    model.compile(optimizer=params['optimizer'], loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    logdir = \"Resultados\\\\\" + exp_name +\"\\\\logs\\\\model\"\n",
    "\n",
    "    tensor_board = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1, profile_batch = 100000000)\n",
    "\n",
    "    \n",
    "    #includes the call back object\n",
    "    model.fit(reshape_x_train, y_train, epochs=params['nb_epochs'], batch_size=params['batch_size'],\n",
    "              verbose = 0, validation_data=(reshape_x_test, y_test),callbacks=[tensor_board])\n",
    "     \n",
    "    #predict the test set \n",
    "    score, acc = model.evaluate(reshape_x_test, y_test, verbose=0)\n",
    "    \n",
    "    run_time = timer() - start\n",
    "    \n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([-acc, params, score, run_time])\n",
    "    of_connection.close()\n",
    "    \n",
    "    \n",
    "    print('Test accuracy:', acc)\n",
    " \n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'train_time': run_time,}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almacenar resultados de cada iteración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 600 ms\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import tpe\n",
    "\n",
    "tpe_algorithm = tpe.suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 598 ms\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "from hyperopt import Trials\n",
    "\n",
    "bayes_trials = Trials()\n",
    "\n",
    "# File to save first results\n",
    "out_file = folder + '/gbm_results.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write the headers to the file\n",
    "writer.writerow(['loss', 'params', 'score','time'])\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lanzar optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 128, 'units2': 128}                                     \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49222222                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 64, 'units2': 10}                                           \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49666667                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 512, 'units2': 10}                                      \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.4931746                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 10, 'units2': 512}                                          \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49555555                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 128, 'units2': 128}                                     \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49222222                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 256, 'units2': 128}                                         \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.4895238                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 128, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 256, 'units2': 256}                                     \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49222222                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 128, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 64, 'units2': 256}                                      \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49222222                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 512, 'units2': 10}                                          \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.5012698                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 512, 'units2': 64}                                          \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.50158733                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 128, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 128, 'units2': 512}                                         \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49793652                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.1, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 10, 'units2': 128}                                      \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49222222                                                                                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 64, 'units2': 512}                                          \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.4952381                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 512, 'units2': 64}                                          \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.5001587                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 128, 'dropout1': 0.1, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 10, 'units2': 256}                                          \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.5038095                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 128, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 64, 'units2': 256}                                      \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.49222222                                                                                                                                                             \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 128, 'units2': 10}                                      \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.4911111                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 256, 'units2': 64}                                      \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.4920635                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 256, 'units2': 10}                                          \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.5088889                                                                                                                                                              \n",
      "Params testing:                                                                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 256, 'units2': 64}                                          \n",
      "Test accuracy:                                                                                                                                                         \n",
      "0.50174606                                                                                                                                                             \n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [1:03:31<00:00, 190.59s/trial, best loss: -0.5088889002799988]\n",
      "time: 1h 3min 34s\n"
     ]
    }
   ],
   "source": [
    "# Run optimization\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = 20, trials = bayes_trials,\n",
    "            verbose = 1, rstate= np.random.RandomState(50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportar bayesiana, por si quisiera retomar donde queda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 64 ms\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dump(bayes_trials, open(folder + '/trials.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer mejores parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': -0.5088889002799988,\n",
       "  'status': 'ok',\n",
       "  'train_time': 109.71917329999997},\n",
       " {'loss': -0.5038095116615295,\n",
       "  'status': 'ok',\n",
       "  'train_time': 257.71171749999985}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 228 ms\n"
     ]
    }
   ],
   "source": [
    "# Sort the trials with lowest loss (highest AUC) first\n",
    "bayes_trials_results  = sorted(bayes_trials.results, key = lambda x: x['loss'])\n",
    "bayes_trials_results [:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.508889</td>\n",
       "      <td>{'activation': 'relu', 'batch_size': 512, 'dro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.719173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.503810</td>\n",
       "      <td>{'activation': 'relu', 'batch_size': 128, 'dro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257.711717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.501746</td>\n",
       "      <td>{'activation': 'relu', 'batch_size': 512, 'dro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.215043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.501587</td>\n",
       "      <td>{'activation': 'relu', 'batch_size': 256, 'dro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>247.814475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.501270</td>\n",
       "      <td>{'activation': 'relu', 'batch_size': 256, 'dro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>241.674166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss                                             params  score  \\\n",
       "0 -0.508889  {'activation': 'relu', 'batch_size': 512, 'dro...    NaN   \n",
       "1 -0.503810  {'activation': 'relu', 'batch_size': 128, 'dro...    NaN   \n",
       "2 -0.501746  {'activation': 'relu', 'batch_size': 512, 'dro...    NaN   \n",
       "3 -0.501587  {'activation': 'relu', 'batch_size': 256, 'dro...    NaN   \n",
       "4 -0.501270  {'activation': 'relu', 'batch_size': 256, 'dro...    NaN   \n",
       "\n",
       "         time  \n",
       "0  109.719173  \n",
       "1  257.711717  \n",
       "2  118.215043  \n",
       "3  247.814475  \n",
       "4  241.674166  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 103 ms\n"
     ]
    }
   ],
   "source": [
    "results = pd.read_csv(folder + '/gbm_results.csv')\n",
    "\n",
    "# Sort with best scores on top and reset index for slicing\n",
    "results.sort_values('loss', ascending = True, inplace = True)\n",
    "results.reset_index(inplace = True, drop = True)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 512,\n",
       " 'dropout1': 0.3,\n",
       " 'nb_epochs': 50,\n",
       " 'optimizer': 'adam',\n",
       " 'units1': 256,\n",
       " 'units2': 10}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 200 ms\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Convert from a string to a dictionary\n",
    "ast.literal_eval(results.loc[0, 'params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 512,\n",
       " 'dropout1': 0.3,\n",
       " 'nb_epochs': 50,\n",
       " 'optimizer': 'adam',\n",
       " 'units1': 256,\n",
       " 'units2': 10}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 104 ms\n"
     ]
    }
   ],
   "source": [
    "# Extract the ideal number of estimators and hyperparameters\n",
    "best_bayes_params = ast.literal_eval(results.loc[0, 'params']).copy()\n",
    "best_bayes_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir datasets de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 355 ms\n"
     ]
    }
   ],
   "source": [
    "# Selecciono la fecha para la cual hago el corte de train y test\n",
    "training_end = pd.to_datetime(\"2014-12-31\")\n",
    "num_training = len(embeddings_average_individual[(embeddings_average_individual[\"Date\"]) <= training_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5 ms\n"
     ]
    }
   ],
   "source": [
    "# Selecciono el archivo con el que se corre el modelo\n",
    "data = embeddings_average_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9450, 1, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 933 ms\n"
     ]
    }
   ],
   "source": [
    "# Se separa en train y test\n",
    "x_train = data.drop([\"Top\",\"Label\", \"Date\"], axis=1)[:num_training]\n",
    "x_test = data.drop([\"Top\",'Label', 'Date'], axis=1)[num_training:]\n",
    "y_train = data[\"Label\"].values[:num_training]\n",
    "y_test = data[\"Label\"].values[num_training:]\n",
    "\n",
    "\n",
    "x_train_array = x_train.to_numpy()\n",
    "reshape_x_train = x_train_array.reshape(len(x_train), 1, 300)\n",
    "reshape_x_train.shape\n",
    "\n",
    "x_test_array = x_test.to_numpy()\n",
    "reshape_x_test = x_test_array.reshape(len(x_test), 1, 300)\n",
    "reshape_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIKq7z8tnIWl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(best_bayes_params['units1'], input_shape=(1,300), return_sequences=True))\n",
    "model.add(Dropout(best_bayes_params['dropout1']))\n",
    "model.add(LSTM(best_bayes_params['units2'], return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# define the checkpoint\n",
    "filepath= ch_folder + \"/word2vec-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logdir = \"Resultados\\\\\" + exp_name +\"\\\\logs\\\\model\"\n",
    "\n",
    "\n",
    "tensor_board = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1, profile_batch = 100000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3944,
     "status": "ok",
     "timestamp": 1589755592715,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "JsHgNLFnnTLN",
    "outputId": "4c22910d-c7b2-4dff-eb32-15c2574174ff",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40268 samples\n",
      "Epoch 1/50\n",
      "40268/40268 [==============================] - 7s 171us/sample - loss: 0.6903 - accuracy: 0.5390\n",
      "Epoch 2/50\n",
      "40268/40268 [==============================] - 2s 50us/sample - loss: 0.6897 - accuracy: 0.5393\n",
      "Epoch 3/50\n",
      "40268/40268 [==============================] - 2s 48us/sample - loss: 0.6892 - accuracy: 0.5398\n",
      "Epoch 4/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6888 - accuracy: 0.5410\n",
      "Epoch 5/50\n",
      "40268/40268 [==============================] - 2s 56us/sample - loss: 0.6883 - accuracy: 0.5427\n",
      "Epoch 6/50\n",
      "40268/40268 [==============================] - 2s 52us/sample - loss: 0.6876 - accuracy: 0.5445s - loss: 0.6876 - accu\n",
      "Epoch 7/50\n",
      "40268/40268 [==============================] - 2s 53us/sample - loss: 0.6874 - accuracy: 0.5449\n",
      "Epoch 8/50\n",
      "40268/40268 [==============================] - 2s 50us/sample - loss: 0.6871 - accuracy: 0.5450\n",
      "Epoch 9/50\n",
      "40268/40268 [==============================] - 2s 51us/sample - loss: 0.6866 - accuracy: 0.5449\n",
      "Epoch 10/50\n",
      "40268/40268 [==============================] - 2s 46us/sample - loss: 0.6866 - accuracy: 0.5471\n",
      "Epoch 11/50\n",
      "40268/40268 [==============================] - 2s 48us/sample - loss: 0.6860 - accuracy: 0.5456\n",
      "Epoch 12/50\n",
      "40268/40268 [==============================] - 2s 57us/sample - loss: 0.6860 - accuracy: 0.5484\n",
      "Epoch 13/50\n",
      "40268/40268 [==============================] - 2s 51us/sample - loss: 0.6852 - accuracy: 0.5481\n",
      "Epoch 14/50\n",
      "40268/40268 [==============================] - 2s 52us/sample - loss: 0.6846 - accuracy: 0.5489\n",
      "Epoch 15/50\n",
      "40268/40268 [==============================] - 2s 47us/sample - loss: 0.6845 - accuracy: 0.5490s - loss: 0.6847 - accuracy: 0.\n",
      "Epoch 16/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6833 - accuracy: 0.5508\n",
      "Epoch 17/50\n",
      "40268/40268 [==============================] - 2s 47us/sample - loss: 0.6832 - accuracy: 0.5517\n",
      "Epoch 18/50\n",
      "40268/40268 [==============================] - 2s 53us/sample - loss: 0.6823 - accuracy: 0.5533\n",
      "Epoch 19/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6823 - accuracy: 0.5528\n",
      "Epoch 20/50\n",
      "40268/40268 [==============================] - 2s 57us/sample - loss: 0.6816 - accuracy: 0.5553\n",
      "Epoch 21/50\n",
      "40268/40268 [==============================] - 2s 48us/sample - loss: 0.6808 - accuracy: 0.5569\n",
      "Epoch 22/50\n",
      "40268/40268 [==============================] - 2s 46us/sample - loss: 0.6802 - accuracy: 0.5554\n",
      "Epoch 23/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6793 - accuracy: 0.5572\n",
      "Epoch 24/50\n",
      "40268/40268 [==============================] - 2s 55us/sample - loss: 0.6789 - accuracy: 0.5572s - l\n",
      "Epoch 25/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6782 - accuracy: 0.5590\n",
      "Epoch 26/50\n",
      "40268/40268 [==============================] - 2s 43us/sample - loss: 0.6770 - accuracy: 0.5619\n",
      "Epoch 27/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6759 - accuracy: 0.5614\n",
      "Epoch 28/50\n",
      "40268/40268 [==============================] - 2s 48us/sample - loss: 0.6755 - accuracy: 0.5624s - loss: 0.6757 - accuracy\n",
      "Epoch 29/50\n",
      "40268/40268 [==============================] - 2s 43us/sample - loss: 0.6748 - accuracy: 0.5619\n",
      "Epoch 30/50\n",
      "40268/40268 [==============================] - 2s 43us/sample - loss: 0.6729 - accuracy: 0.5658\n",
      "Epoch 31/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6716 - accuracy: 0.5686\n",
      "Epoch 32/50\n",
      "40268/40268 [==============================] - 2s 43us/sample - loss: 0.6707 - accuracy: 0.5683\n",
      "Epoch 33/50\n",
      "40268/40268 [==============================] - 2s 48us/sample - loss: 0.6693 - accuracy: 0.5713\n",
      "Epoch 34/50\n",
      "40268/40268 [==============================] - 2s 46us/sample - loss: 0.6673 - accuracy: 0.5752\n",
      "Epoch 35/50\n",
      "40268/40268 [==============================] - 2s 47us/sample - loss: 0.6655 - accuracy: 0.5769\n",
      "Epoch 36/50\n",
      "40268/40268 [==============================] - 2s 42us/sample - loss: 0.6640 - accuracy: 0.5776\n",
      "Epoch 37/50\n",
      "40268/40268 [==============================] - 2s 42us/sample - loss: 0.6633 - accuracy: 0.5777s - loss: 0.659 - ETA: 0s - loss: 0.6620 - ac\n",
      "Epoch 38/50\n",
      "40268/40268 [==============================] - 2s 43us/sample - loss: 0.6613 - accuracy: 0.5816\n",
      "Epoch 39/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6587 - accuracy: 0.5846\n",
      "Epoch 40/50\n",
      "40268/40268 [==============================] - 2s 42us/sample - loss: 0.6567 - accuracy: 0.5885s - loss: 0.6571 - accuracy\n",
      "Epoch 41/50\n",
      "40268/40268 [==============================] - 2s 53us/sample - loss: 0.6557 - accuracy: 0.5912s - loss: 0.6559 - accura\n",
      "Epoch 42/50\n",
      "40268/40268 [==============================] - 2s 44us/sample - loss: 0.6529 - accuracy: 0.5918\n",
      "Epoch 43/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6513 - accuracy: 0.5920s - los\n",
      "Epoch 44/50\n",
      "40268/40268 [==============================] - 2s 47us/sample - loss: 0.6480 - accuracy: 0.5991\n",
      "Epoch 45/50\n",
      "40268/40268 [==============================] - 2s 43us/sample - loss: 0.6461 - accuracy: 0.5996\n",
      "Epoch 46/50\n",
      "40268/40268 [==============================] - 2s 43us/sample - loss: 0.6417 - accuracy: 0.6052\n",
      "Epoch 47/50\n",
      "40268/40268 [==============================] - 2s 45us/sample - loss: 0.6398 - accuracy: 0.6103\n",
      "Epoch 48/50\n",
      "40268/40268 [==============================] - 2s 42us/sample - loss: 0.6383 - accuracy: 0.6088s - loss: 0.6375 - accura - ETA: 0s - loss: 0.6384 - accuracy: \n",
      "Epoch 49/50\n",
      "40268/40268 [==============================] - 2s 46us/sample - loss: 0.6356 - accuracy: 0.6138\n",
      "Epoch 50/50\n",
      "40268/40268 [==============================] - 2s 46us/sample - loss: 0.6322 - accuracy: 0.6169\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_40 (LSTM)               (None, 1, 256)            570368    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, 10)                10680     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 581,059\n",
      "Trainable params: 581,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(reshape_x_train, y_train,\n",
    "          epochs=best_bayes_params['nb_epochs'], \n",
    "          batch_size=best_bayes_params['batch_size'], callbacks=[tensor_board])\n",
    "\n",
    "\n",
    "model.save(folder + '/keras_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1589755595730,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "mdsR4Qngv5Q1",
    "outputId": "433bbcf6-d6eb-44c1-a1bb-afee72ac0ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.513968\n",
      "time: 3.4 s\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(reshape_x_test, y_test, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.save_checkpoint()\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5 ms\n"
     ]
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.save_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Resultados/7/RNN_Model_Base.ipynb'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 78.6 ms\n"
     ]
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "copyfile('RNN_Model_Base_GPU.ipynb', folder + '/RNN_Model_Base.ipynb' )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNhtKTbzPEwz7PyaEe0FkIO",
   "collapsed_sections": [],
   "name": "RNN - Meli.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
