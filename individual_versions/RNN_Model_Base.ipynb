{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4dLP23xZmpC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.93 s\n"
     ]
    }
   ],
   "source": [
    "# Importar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import zipfile\n",
    "from datetime import date\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from numpy.testing import assert_allclose\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exists\n",
      "time: 136 ms\n"
     ]
    }
   ],
   "source": [
    "exp_name = 'Embed_promedio'\n",
    "folder = 'Resultados/' + exp_name\n",
    "my_file = Path(folder)\n",
    "if os.path.exists(my_file):\n",
    "    print('already exists')\n",
    "else:\n",
    "    os.makedirs(folder)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exists\n",
      "time: 114 ms\n"
     ]
    }
   ],
   "source": [
    "ch_folder = folder + '/Checkpoints'\n",
    "my_file = Path(ch_folder)\n",
    "if os.path.exists(my_file):\n",
    "    print('already exists')\n",
    "else:\n",
    "    os.makedirs(ch_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nzv66BqFbl92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>Label</th>\n",
       "      <th>Date</th>\n",
       "      <th>Top</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49716</th>\n",
       "      <td>-0.082072</td>\n",
       "      <td>0.099915</td>\n",
       "      <td>-0.015503</td>\n",
       "      <td>0.115560</td>\n",
       "      <td>-0.072611</td>\n",
       "      <td>0.070435</td>\n",
       "      <td>0.042613</td>\n",
       "      <td>-0.041026</td>\n",
       "      <td>0.012126</td>\n",
       "      <td>-0.020508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062215</td>\n",
       "      <td>-0.078471</td>\n",
       "      <td>0.046008</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>-0.071452</td>\n",
       "      <td>0.122559</td>\n",
       "      <td>0.07622</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49717</th>\n",
       "      <td>-0.064514</td>\n",
       "      <td>0.013916</td>\n",
       "      <td>-0.028976</td>\n",
       "      <td>0.058716</td>\n",
       "      <td>-0.078369</td>\n",
       "      <td>-0.057312</td>\n",
       "      <td>-0.077515</td>\n",
       "      <td>-0.234467</td>\n",
       "      <td>0.050751</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010498</td>\n",
       "      <td>0.081284</td>\n",
       "      <td>0.040283</td>\n",
       "      <td>-0.108978</td>\n",
       "      <td>0.033783</td>\n",
       "      <td>0.028870</td>\n",
       "      <td>0.03418</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "49716 -0.082072  0.099915 -0.015503  0.115560 -0.072611  0.070435  0.042613   \n",
       "49717 -0.064514  0.013916 -0.028976  0.058716 -0.078369 -0.057312 -0.077515   \n",
       "\n",
       "              7         8         9  ...       293       294       295  \\\n",
       "49716 -0.041026  0.012126 -0.020508  ... -0.062215 -0.078471  0.046008   \n",
       "49717 -0.234467  0.050751  0.020508  ... -0.010498  0.081284  0.040283   \n",
       "\n",
       "            296       297       298      299  Label       Date  Top  \n",
       "49716  0.005717 -0.071452  0.122559  0.07622      0 2008-08-08   24  \n",
       "49717 -0.108978  0.033783  0.028870  0.03418      0 2008-08-08   25  \n",
       "\n",
       "[2 rows x 303 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "#Importar los datasets\n",
    "url_embeddings_average_individual = zipfile.ZipFile('../Data/embeddings_average_individual.zip')\n",
    "url_embeddings_sum_individual = zipfile.ZipFile('../Data/embeddings_sum_individual.zip')\n",
    "\n",
    "embeddings_average_individual = pd.read_csv(url_embeddings_average_individual.open('embeddings_average_individual.csv'), index_col = 0)\n",
    "embeddings_sum_individual =pd.read_csv(url_embeddings_sum_individual.open('embeddings_sum_individual.csv'), index_col = 0)\n",
    "\n",
    "embeddings_average_individual['Date'] =  pd.to_datetime(embeddings_average_individual['Date'], format='%Y-%m-%d')\n",
    "# embeddings_average_individual.sort_values('Date', inplace=True)\n",
    "# embeddings_average_individual.reset_index(drop = True , inplace=True)\n",
    "\n",
    "embeddings_average_individual.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAXOJcEcbmed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 90 ms\n"
     ]
    }
   ],
   "source": [
    "# Selecciono la fecha para la cual hago el corte de train y test\n",
    "training_end = pd.to_datetime(\"2013-12-31\")\n",
    "num_training = len(embeddings_average_individual[(embeddings_average_individual[\"Date\"]) <= training_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 71 ms\n"
     ]
    }
   ],
   "source": [
    "# Selecciono el archivo con el que se corre el modelo\n",
    "data = embeddings_average_individual[embeddings_average_individual['Date']<='2014-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6300, 1, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 268 ms\n"
     ]
    }
   ],
   "source": [
    "# Se separa en train y test\n",
    "x_train = data.drop([\"Top\",\"Label\", \"Date\"], axis=1)[:num_training]\n",
    "x_test = data.drop([\"Top\",'Label', 'Date'], axis=1)[num_training:]\n",
    "y_train = data[\"Label\"].values[:num_training]\n",
    "y_test = data[\"Label\"].values[num_training:]\n",
    "\n",
    "\n",
    "x_train_array = x_train.to_numpy()\n",
    "reshape_x_train = x_train_array.reshape(len(x_train), 1, 300)\n",
    "reshape_x_train.shape\n",
    "\n",
    "x_test_array = x_test.to_numpy()\n",
    "reshape_x_test = x_test_array.reshape(len(x_test), 1, 300)\n",
    "reshape_x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir espacio de busqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 149 ms\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'units1': hp.choice('units1', [10, 64, 128, 256, 512]),\n",
    "    'units2': hp.choice('units2', [10, 64, 128, 256, 512]),\n",
    "                 \n",
    "    'dropout1': hp.choice('dropout1', [0.2,0.3,0.1]),\n",
    "    \n",
    "    'batch_size' : hp.choice('batch_size', [128,256,512]),\n",
    "    'nb_epochs' : hp.choice('nb_epochs', [50]),\n",
    "\n",
    "    'optimizer':  hp.choice('optimizer', [ 'adam','adadelta']),   \n",
    "    'activation': 'relu'    \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir busqueda bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 125 ms\n"
     ]
    }
   ],
   "source": [
    "#Objective function that hyperopt will minimize\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def objective(params):\n",
    "    \n",
    "    import ml_metrics\n",
    "\n",
    "    \n",
    "    start = timer()\n",
    "    print ('Params testing: ', params)\n",
    "    print ('\\n ')\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(params['units1'], input_shape=(1,300), return_sequences=True))\n",
    "    model.add(Dropout(params['dropout1']))\n",
    "    model.add(LSTM(params['units2'], return_sequences=False))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    # compile the model\n",
    "    model.compile(optimizer=params['optimizer'], loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    \n",
    "    #includes the call back object\n",
    "    model.fit(reshape_x_train, y_train, epochs=params['nb_epochs'], batch_size=params['batch_size'],\n",
    "              verbose = 0, validation_data=(reshape_x_test, y_test))\n",
    "     \n",
    "    #predict the test set \n",
    "    score, acc = model.evaluate(reshape_x_test, y_test, verbose=0)\n",
    "    \n",
    "    run_time = timer() - start\n",
    "    \n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([-acc, params, score, run_time])\n",
    "    of_connection.close()\n",
    "    \n",
    "    \n",
    "    print('Test accuracy:', acc)\n",
    " \n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'train_time': run_time,}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almacenar resultados de cada iteración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 73.5 ms\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import tpe\n",
    "\n",
    "tpe_algorithm = tpe.suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 114 ms\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "from hyperopt import Trials\n",
    "\n",
    "bayes_trials = Trials()\n",
    "\n",
    "# File to save first results\n",
    "out_file = folder + '/gbm_results.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write the headers to the file\n",
    "writer.writerow(['loss', 'params', 'score','time'])\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lanzar optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 128, 'units2': 128}\n",
      "Test accuracy:                                                                                                         \n",
      "0.4920634925365448                                                                                                     \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 64, 'units2': 10}\n",
      "Test accuracy:                                                                                                         \n",
      "0.5046031475067139                                                                                                     \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 512, 'units2': 10}\n",
      "Test accuracy:                                                                                                         \n",
      "0.49190476536750793                                                                                                    \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 10, 'units2': 512}\n",
      "Test accuracy:                                                                                                         \n",
      "0.5061904788017273                                                                                                     \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 128, 'units2': 128}\n",
      "Test accuracy:                                                                                                         \n",
      "0.4928571283817291                                                                                                     \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 256, 'units2': 128}\n",
      "Test accuracy:                                                                                                         \n",
      "0.49619048833847046                                                                                                    \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 128, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 256, 'units2': 256}\n",
      "Test accuracy:                                                                                                         \n",
      "0.4952380955219269                                                                                                     \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 128, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 64, 'units2': 256}\n",
      "Test accuracy:                                                                                                         \n",
      "0.49047619104385376                                                                                                    \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 512, 'units2': 10}\n",
      "Test accuracy:                                                                                                         \n",
      "0.49539682269096375                                                                                                    \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 512, 'units2': 64}\n",
      "Test accuracy:                                                                                                         \n",
      "0.5007936358451843                                                                                                     \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 128, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 128, 'units2': 512}\n",
      "Test accuracy:                                                                                                         \n",
      "0.4957142770290375                                                                                                     \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.1, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 10, 'units2': 128}\n",
      "Test accuracy:                                                                                                         \n",
      "0.4920634925365448                                                                                                     \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 64, 'units2': 512}\n",
      "Test accuracy:                                                                                                         \n",
      "0.5073015689849854                                                                                                     \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 512, 'units2': 64}\n",
      "Test accuracy:                                                                                                         \n",
      "0.49444442987442017                                                                                                    \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 128, 'dropout1': 0.1, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 10, 'units2': 256}\n",
      "Test accuracy:                                                                                                         \n",
      "0.506507933139801                                                                                                      \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 128, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 64, 'units2': 256}\n",
      "Test accuracy:                                                                                                         \n",
      "0.49841269850730896                                                                                                    \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 128, 'units2': 10}\n",
      "Test accuracy:                                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4920634925365448                                                                                                     \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adadelta', 'units1': 256, 'units2': 64}\n",
      "Test accuracy:                                                                                                         \n",
      "0.4920634925365448                                                                                                     \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 256, 'units2': 10}\n",
      "Test accuracy:                                                                                                         \n",
      "0.49968254566192627                                                                                                    \n",
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 512, 'dropout1': 0.3, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 256, 'units2': 64}\n",
      "Test accuracy:                                                                                                         \n",
      "0.506507933139801                                                                                                      \n",
      "100%|████████████████████████████████████████████| 20/20 [1:41:44<00:00, 209.97s/trial, best loss: -0.5073015689849854]\n",
      "time: 1h 41min 44s\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "\n",
    "# Run optimization\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = 20, trials = bayes_trials,\n",
    "            verbose = 1, rstate= np.random.RandomState(50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportar bayesiana, por si quisiera retomar donde queda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dump(bayes_trials, open(folder + '/trials.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer mejores parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': -0.5073015689849854,\n",
       "  'status': 'ok',\n",
       "  'train_time': 363.16455289999976},\n",
       " {'loss': -0.506507933139801,\n",
       "  'status': 'ok',\n",
       "  'train_time': 197.95745129999978}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 100 ms\n"
     ]
    }
   ],
   "source": [
    "# Sort the trials with lowest loss (highest AUC) first\n",
    "bayes_trials_results  = sorted(bayes_trials.results, key = lambda x: x['loss'])\n",
    "bayes_trials_results [:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.507302</td>\n",
       "      <td>{'activation': 'relu', 'batch_size': 512, 'dro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>363.164553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.506508</td>\n",
       "      <td>{'activation': 'relu', 'batch_size': 512, 'dro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188.239897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.506508</td>\n",
       "      <td>{'activation': 'relu', 'batch_size': 128, 'dro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197.957451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.506190</td>\n",
       "      <td>{'activation': 'relu', 'batch_size': 256, 'dro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>391.347929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.504603</td>\n",
       "      <td>{'activation': 'relu', 'batch_size': 256, 'dro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.543316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss                                             params  score  \\\n",
       "0 -0.507302  {'activation': 'relu', 'batch_size': 512, 'dro...    NaN   \n",
       "1 -0.506508  {'activation': 'relu', 'batch_size': 512, 'dro...    NaN   \n",
       "2 -0.506508  {'activation': 'relu', 'batch_size': 128, 'dro...    NaN   \n",
       "3 -0.506190  {'activation': 'relu', 'batch_size': 256, 'dro...    NaN   \n",
       "4 -0.504603  {'activation': 'relu', 'batch_size': 256, 'dro...    NaN   \n",
       "\n",
       "         time  \n",
       "0  363.164553  \n",
       "1  188.239897  \n",
       "2  197.957451  \n",
       "3  391.347929  \n",
       "4   62.543316  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 130 ms\n"
     ]
    }
   ],
   "source": [
    "results = pd.read_csv(folder + '/gbm_results.csv')\n",
    "\n",
    "# Sort with best scores on top and reset index for slicing\n",
    "results.sort_values('loss', ascending = True, inplace = True)\n",
    "results.reset_index(inplace = True, drop = True)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 512,\n",
       " 'dropout1': 0.2,\n",
       " 'nb_epochs': 50,\n",
       " 'optimizer': 'adam',\n",
       " 'units1': 64,\n",
       " 'units2': 512}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 77.7 ms\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Convert from a string to a dictionary\n",
    "ast.literal_eval(results.loc[0, 'params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 512,\n",
       " 'dropout1': 0.2,\n",
       " 'nb_epochs': 50,\n",
       " 'optimizer': 'adam',\n",
       " 'units1': 64,\n",
       " 'units2': 512}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 131 ms\n"
     ]
    }
   ],
   "source": [
    "# Extract the ideal number of estimators and hyperparameters\n",
    "best_bayes_params = ast.literal_eval(results.loc[0, 'params']).copy()\n",
    "best_bayes_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir datasets de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 219 ms\n"
     ]
    }
   ],
   "source": [
    "# Selecciono la fecha para la cual hago el corte de train y test\n",
    "training_end = pd.to_datetime(\"2014-12-31\")\n",
    "num_training = len(embeddings_average_individual[(embeddings_average_individual[\"Date\"]) <= training_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 134 ms\n"
     ]
    }
   ],
   "source": [
    "# Selecciono el archivo con el que se corre el modelo\n",
    "data = embeddings_average_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9450, 1, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 278 ms\n"
     ]
    }
   ],
   "source": [
    "# Se separa en train y test\n",
    "x_train = data.drop([\"Top\",\"Label\", \"Date\"], axis=1)[:num_training]\n",
    "x_test = data.drop([\"Top\",'Label', 'Date'], axis=1)[num_training:]\n",
    "y_train = data[\"Label\"].values[:num_training]\n",
    "y_test = data[\"Label\"].values[num_training:]\n",
    "\n",
    "\n",
    "x_train_array = x_train.to_numpy()\n",
    "reshape_x_train = x_train_array.reshape(len(x_train), 1, 300)\n",
    "reshape_x_train.shape\n",
    "\n",
    "x_test_array = x_test.to_numpy()\n",
    "reshape_x_test = x_test_array.reshape(len(x_test), 1, 300)\n",
    "reshape_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIKq7z8tnIWl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(best_bayes_params['units1'], input_shape=(1,300), return_sequences=True))\n",
    "model.add(Dropout(best_bayes_params['dropout1']))\n",
    "model.add(LSTM(best_bayes_params['units2'], return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# define the checkpoint\n",
    "filepath= ch_folder + \"/word2vec-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3944,
     "status": "ok",
     "timestamp": 1589755592715,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "JsHgNLFnnTLN",
    "outputId": "4c22910d-c7b2-4dff-eb32-15c2574174ff",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40268/40268 [==============================] - ETA: 1:06 - loss: 0.6931 - accuracy: 0.51 - ETA: 38s - loss: 0.6928 - accuracy: 0.5410 - ETA: 28s - loss: 0.6928 - accuracy: 0.534 - ETA: 23s - loss: 0.6927 - accuracy: 0.532 - ETA: 20s - loss: 0.6926 - accuracy: 0.531 - ETA: 18s - loss: 0.6923 - accuracy: 0.534 - ETA: 16s - loss: 0.6920 - accuracy: 0.537 - ETA: 15s - loss: 0.6918 - accuracy: 0.537 - ETA: 14s - loss: 0.6915 - accuracy: 0.539 - ETA: 13s - loss: 0.6914 - accuracy: 0.539 - ETA: 12s - loss: 0.6915 - accuracy: 0.537 - ETA: 12s - loss: 0.6913 - accuracy: 0.538 - ETA: 11s - loss: 0.6908 - accuracy: 0.540 - ETA: 11s - loss: 0.6908 - accuracy: 0.540 - ETA: 10s - loss: 0.6905 - accuracy: 0.541 - ETA: 10s - loss: 0.6906 - accuracy: 0.541 - ETA: 10s - loss: 0.6912 - accuracy: 0.538 - ETA: 9s - loss: 0.6910 - accuracy: 0.538 - ETA: 9s - loss: 0.6906 - accuracy: 0.54 - ETA: 9s - loss: 0.6908 - accuracy: 0.53 - ETA: 8s - loss: 0.6909 - accuracy: 0.53 - ETA: 8s - loss: 0.6908 - accuracy: 0.53 - ETA: 8s - loss: 0.6908 - accuracy: 0.53 - ETA: 8s - loss: 0.6908 - accuracy: 0.53 - ETA: 7s - loss: 0.6911 - accuracy: 0.53 - ETA: 7s - loss: 0.6909 - accuracy: 0.53 - ETA: 7s - loss: 0.6909 - accuracy: 0.53 - ETA: 7s - loss: 0.6909 - accuracy: 0.53 - ETA: 6s - loss: 0.6908 - accuracy: 0.53 - ETA: 6s - loss: 0.6907 - accuracy: 0.53 - ETA: 6s - loss: 0.6909 - accuracy: 0.53 - ETA: 6s - loss: 0.6909 - accuracy: 0.53 - ETA: 6s - loss: 0.6909 - accuracy: 0.53 - ETA: 6s - loss: 0.6909 - accuracy: 0.53 - ETA: 5s - loss: 0.6909 - accuracy: 0.53 - ETA: 5s - loss: 0.6908 - accuracy: 0.53 - ETA: 5s - loss: 0.6908 - accuracy: 0.53 - ETA: 5s - loss: 0.6908 - accuracy: 0.53 - ETA: 5s - loss: 0.6907 - accuracy: 0.53 - ETA: 5s - loss: 0.6907 - accuracy: 0.53 - ETA: 4s - loss: 0.6906 - accuracy: 0.53 - ETA: 4s - loss: 0.6906 - accuracy: 0.53 - ETA: 4s - loss: 0.6905 - accuracy: 0.53 - ETA: 4s - loss: 0.6905 - accuracy: 0.53 - ETA: 4s - loss: 0.6906 - accuracy: 0.53 - ETA: 4s - loss: 0.6906 - accuracy: 0.53 - ETA: 4s - loss: 0.6906 - accuracy: 0.53 - ETA: 3s - loss: 0.6905 - accuracy: 0.53 - ETA: 3s - loss: 0.6905 - accuracy: 0.53 - ETA: 3s - loss: 0.6905 - accuracy: 0.53 - ETA: 3s - loss: 0.6905 - accuracy: 0.53 - ETA: 3s - loss: 0.6905 - accuracy: 0.53 - ETA: 3s - loss: 0.6904 - accuracy: 0.53 - ETA: 3s - loss: 0.6903 - accuracy: 0.53 - ETA: 2s - loss: 0.6904 - accuracy: 0.53 - ETA: 2s - loss: 0.6905 - accuracy: 0.53 - ETA: 2s - loss: 0.6904 - accuracy: 0.53 - ETA: 2s - loss: 0.6904 - accuracy: 0.53 - ETA: 2s - loss: 0.6904 - accuracy: 0.53 - ETA: 2s - loss: 0.6903 - accuracy: 0.53 - ETA: 2s - loss: 0.6904 - accuracy: 0.53 - ETA: 2s - loss: 0.6904 - accuracy: 0.53 - ETA: 1s - loss: 0.6904 - accuracy: 0.53 - ETA: 1s - loss: 0.6904 - accuracy: 0.53 - ETA: 1s - loss: 0.6903 - accuracy: 0.53 - ETA: 1s - loss: 0.6903 - accuracy: 0.53 - ETA: 1s - loss: 0.6903 - accuracy: 0.53 - ETA: 1s - loss: 0.6903 - accuracy: 0.53 - ETA: 1s - loss: 0.6903 - accuracy: 0.53 - ETA: 1s - loss: 0.6903 - accuracy: 0.53 - ETA: 0s - loss: 0.6903 - accuracy: 0.53 - ETA: 0s - loss: 0.6903 - accuracy: 0.53 - ETA: 0s - loss: 0.6903 - accuracy: 0.53 - ETA: 0s - loss: 0.6903 - accuracy: 0.53 - ETA: 0s - loss: 0.6904 - accuracy: 0.53 - ETA: 0s - loss: 0.6904 - accuracy: 0.53 - ETA: 0s - loss: 0.6904 - accuracy: 0.53 - ETA: 0s - loss: 0.6904 - accuracy: 0.53 - 10s 242us/step - loss: 0.6905 - accuracy: 0.5384\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.69047, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-01-0.6905.hdf5\n",
      "Epoch 2/50\n",
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6922 - accuracy: 0.52 - ETA: 8s - loss: 0.6913 - accuracy: 0.52 - ETA: 8s - loss: 0.6920 - accuracy: 0.52 - ETA: 8s - loss: 0.6921 - accuracy: 0.52 - ETA: 8s - loss: 0.6913 - accuracy: 0.52 - ETA: 8s - loss: 0.6906 - accuracy: 0.53 - ETA: 8s - loss: 0.6904 - accuracy: 0.53 - ETA: 7s - loss: 0.6899 - accuracy: 0.54 - ETA: 7s - loss: 0.6902 - accuracy: 0.53 - ETA: 7s - loss: 0.6898 - accuracy: 0.54 - ETA: 7s - loss: 0.6893 - accuracy: 0.54 - ETA: 7s - loss: 0.6895 - accuracy: 0.54 - ETA: 7s - loss: 0.6894 - accuracy: 0.54 - ETA: 7s - loss: 0.6896 - accuracy: 0.54 - ETA: 7s - loss: 0.6894 - accuracy: 0.54 - ETA: 6s - loss: 0.6893 - accuracy: 0.54 - ETA: 6s - loss: 0.6889 - accuracy: 0.54 - ETA: 6s - loss: 0.6888 - accuracy: 0.54 - ETA: 6s - loss: 0.6890 - accuracy: 0.54 - ETA: 6s - loss: 0.6888 - accuracy: 0.54 - ETA: 6s - loss: 0.6887 - accuracy: 0.54 - ETA: 6s - loss: 0.6889 - accuracy: 0.54 - ETA: 6s - loss: 0.6891 - accuracy: 0.54 - ETA: 6s - loss: 0.6889 - accuracy: 0.54 - ETA: 5s - loss: 0.6890 - accuracy: 0.54 - ETA: 5s - loss: 0.6891 - accuracy: 0.54 - ETA: 5s - loss: 0.6893 - accuracy: 0.54 - ETA: 5s - loss: 0.6894 - accuracy: 0.54 - ETA: 5s - loss: 0.6896 - accuracy: 0.54 - ETA: 5s - loss: 0.6898 - accuracy: 0.54 - ETA: 5s - loss: 0.6896 - accuracy: 0.54 - ETA: 5s - loss: 0.6896 - accuracy: 0.54 - ETA: 5s - loss: 0.6895 - accuracy: 0.54 - ETA: 4s - loss: 0.6896 - accuracy: 0.54 - ETA: 4s - loss: 0.6896 - accuracy: 0.54 - ETA: 4s - loss: 0.6897 - accuracy: 0.54 - ETA: 4s - loss: 0.6897 - accuracy: 0.54 - ETA: 4s - loss: 0.6896 - accuracy: 0.54 - ETA: 4s - loss: 0.6894 - accuracy: 0.54 - ETA: 4s - loss: 0.6894 - accuracy: 0.54 - ETA: 4s - loss: 0.6894 - accuracy: 0.54 - ETA: 4s - loss: 0.6895 - accuracy: 0.54 - ETA: 3s - loss: 0.6895 - accuracy: 0.54 - ETA: 3s - loss: 0.6896 - accuracy: 0.54 - ETA: 3s - loss: 0.6896 - accuracy: 0.54 - ETA: 3s - loss: 0.6896 - accuracy: 0.54 - ETA: 3s - loss: 0.6897 - accuracy: 0.54 - ETA: 3s - loss: 0.6896 - accuracy: 0.54 - ETA: 3s - loss: 0.6897 - accuracy: 0.54 - ETA: 3s - loss: 0.6898 - accuracy: 0.54 - ETA: 3s - loss: 0.6897 - accuracy: 0.54 - ETA: 2s - loss: 0.6897 - accuracy: 0.54 - ETA: 2s - loss: 0.6897 - accuracy: 0.54 - ETA: 2s - loss: 0.6896 - accuracy: 0.54 - ETA: 2s - loss: 0.6896 - accuracy: 0.54 - ETA: 2s - loss: 0.6896 - accuracy: 0.54 - ETA: 2s - loss: 0.6896 - accuracy: 0.54 - ETA: 2s - loss: 0.6897 - accuracy: 0.54 - ETA: 2s - loss: 0.6897 - accuracy: 0.54 - ETA: 2s - loss: 0.6898 - accuracy: 0.54 - ETA: 1s - loss: 0.6896 - accuracy: 0.54 - ETA: 1s - loss: 0.6896 - accuracy: 0.54 - ETA: 1s - loss: 0.6896 - accuracy: 0.54 - ETA: 1s - loss: 0.6897 - accuracy: 0.54 - ETA: 1s - loss: 0.6897 - accuracy: 0.54 - ETA: 1s - loss: 0.6897 - accuracy: 0.54 - ETA: 1s - loss: 0.6897 - accuracy: 0.54 - ETA: 1s - loss: 0.6898 - accuracy: 0.54 - ETA: 1s - loss: 0.6898 - accuracy: 0.54 - ETA: 0s - loss: 0.6898 - accuracy: 0.54 - ETA: 0s - loss: 0.6898 - accuracy: 0.54 - ETA: 0s - loss: 0.6899 - accuracy: 0.53 - ETA: 0s - loss: 0.6899 - accuracy: 0.53 - ETA: 0s - loss: 0.6899 - accuracy: 0.53 - ETA: 0s - loss: 0.6900 - accuracy: 0.53 - ETA: 0s - loss: 0.6900 - accuracy: 0.53 - ETA: 0s - loss: 0.6900 - accuracy: 0.53 - ETA: 0s - loss: 0.6900 - accuracy: 0.53 - 9s 218us/step - loss: 0.6900 - accuracy: 0.5393\n",
      "\n",
      "Epoch 00002: loss improved from 0.69047 to 0.68998, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-02-0.6900.hdf5\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6883 - accuracy: 0.56 - ETA: 8s - loss: 0.6906 - accuracy: 0.53 - ETA: 8s - loss: 0.6917 - accuracy: 0.52 - ETA: 8s - loss: 0.6906 - accuracy: 0.52 - ETA: 8s - loss: 0.6907 - accuracy: 0.52 - ETA: 7s - loss: 0.6904 - accuracy: 0.52 - ETA: 7s - loss: 0.6905 - accuracy: 0.52 - ETA: 7s - loss: 0.6907 - accuracy: 0.52 - ETA: 7s - loss: 0.6906 - accuracy: 0.53 - ETA: 7s - loss: 0.6907 - accuracy: 0.52 - ETA: 7s - loss: 0.6904 - accuracy: 0.53 - ETA: 7s - loss: 0.6901 - accuracy: 0.53 - ETA: 7s - loss: 0.6902 - accuracy: 0.53 - ETA: 7s - loss: 0.6903 - accuracy: 0.53 - ETA: 7s - loss: 0.6899 - accuracy: 0.53 - ETA: 6s - loss: 0.6899 - accuracy: 0.53 - ETA: 6s - loss: 0.6899 - accuracy: 0.53 - ETA: 6s - loss: 0.6897 - accuracy: 0.53 - ETA: 6s - loss: 0.6897 - accuracy: 0.53 - ETA: 6s - loss: 0.6896 - accuracy: 0.53 - ETA: 6s - loss: 0.6894 - accuracy: 0.53 - ETA: 6s - loss: 0.6898 - accuracy: 0.53 - ETA: 6s - loss: 0.6896 - accuracy: 0.53 - ETA: 6s - loss: 0.6897 - accuracy: 0.53 - ETA: 5s - loss: 0.6895 - accuracy: 0.53 - ETA: 5s - loss: 0.6894 - accuracy: 0.53 - ETA: 5s - loss: 0.6896 - accuracy: 0.53 - ETA: 5s - loss: 0.6895 - accuracy: 0.53 - ETA: 5s - loss: 0.6893 - accuracy: 0.53 - ETA: 5s - loss: 0.6890 - accuracy: 0.54 - ETA: 5s - loss: 0.6892 - accuracy: 0.54 - ETA: 5s - loss: 0.6890 - accuracy: 0.54 - ETA: 5s - loss: 0.6891 - accuracy: 0.54 - ETA: 4s - loss: 0.6890 - accuracy: 0.54 - ETA: 4s - loss: 0.6890 - accuracy: 0.54 - ETA: 4s - loss: 0.6890 - accuracy: 0.54 - ETA: 4s - loss: 0.6891 - accuracy: 0.54 - ETA: 4s - loss: 0.6891 - accuracy: 0.54 - ETA: 4s - loss: 0.6890 - accuracy: 0.54 - ETA: 4s - loss: 0.6890 - accuracy: 0.54 - ETA: 4s - loss: 0.6891 - accuracy: 0.54 - ETA: 4s - loss: 0.6890 - accuracy: 0.54 - ETA: 3s - loss: 0.6890 - accuracy: 0.54 - ETA: 3s - loss: 0.6890 - accuracy: 0.54 - ETA: 3s - loss: 0.6889 - accuracy: 0.54 - ETA: 3s - loss: 0.6890 - accuracy: 0.54 - ETA: 3s - loss: 0.6891 - accuracy: 0.54 - ETA: 3s - loss: 0.6892 - accuracy: 0.53 - ETA: 3s - loss: 0.6892 - accuracy: 0.53 - ETA: 3s - loss: 0.6892 - accuracy: 0.53 - ETA: 3s - loss: 0.6891 - accuracy: 0.53 - ETA: 2s - loss: 0.6891 - accuracy: 0.54 - ETA: 2s - loss: 0.6892 - accuracy: 0.54 - ETA: 2s - loss: 0.6893 - accuracy: 0.53 - ETA: 2s - loss: 0.6892 - accuracy: 0.53 - ETA: 2s - loss: 0.6893 - accuracy: 0.53 - ETA: 2s - loss: 0.6893 - accuracy: 0.53 - ETA: 2s - loss: 0.6894 - accuracy: 0.53 - ETA: 2s - loss: 0.6893 - accuracy: 0.53 - ETA: 2s - loss: 0.6893 - accuracy: 0.53 - ETA: 1s - loss: 0.6894 - accuracy: 0.53 - ETA: 1s - loss: 0.6894 - accuracy: 0.53 - ETA: 1s - loss: 0.6895 - accuracy: 0.53 - ETA: 1s - loss: 0.6895 - accuracy: 0.53 - ETA: 1s - loss: 0.6895 - accuracy: 0.53 - ETA: 1s - loss: 0.6895 - accuracy: 0.53 - ETA: 1s - loss: 0.6896 - accuracy: 0.53 - ETA: 1s - loss: 0.6895 - accuracy: 0.53 - ETA: 1s - loss: 0.6895 - accuracy: 0.53 - ETA: 0s - loss: 0.6895 - accuracy: 0.53 - ETA: 0s - loss: 0.6895 - accuracy: 0.53 - ETA: 0s - loss: 0.6894 - accuracy: 0.53 - ETA: 0s - loss: 0.6894 - accuracy: 0.53 - ETA: 0s - loss: 0.6893 - accuracy: 0.53 - ETA: 0s - loss: 0.6892 - accuracy: 0.53 - ETA: 0s - loss: 0.6892 - accuracy: 0.53 - ETA: 0s - loss: 0.6892 - accuracy: 0.53 - ETA: 0s - loss: 0.6892 - accuracy: 0.53 - 9s 217us/step - loss: 0.6893 - accuracy: 0.5390\n",
      "\n",
      "Epoch 00003: loss improved from 0.68998 to 0.68932, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-03-0.6893.hdf5\n",
      "Epoch 4/50\n",
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6986 - accuracy: 0.51 - ETA: 7s - loss: 0.6971 - accuracy: 0.50 - ETA: 7s - loss: 0.6947 - accuracy: 0.51 - ETA: 7s - loss: 0.6926 - accuracy: 0.52 - ETA: 7s - loss: 0.6900 - accuracy: 0.53 - ETA: 7s - loss: 0.6892 - accuracy: 0.54 - ETA: 7s - loss: 0.6887 - accuracy: 0.54 - ETA: 7s - loss: 0.6882 - accuracy: 0.54 - ETA: 7s - loss: 0.6884 - accuracy: 0.54 - ETA: 7s - loss: 0.6882 - accuracy: 0.54 - ETA: 7s - loss: 0.6879 - accuracy: 0.54 - ETA: 7s - loss: 0.6880 - accuracy: 0.54 - ETA: 7s - loss: 0.6878 - accuracy: 0.54 - ETA: 6s - loss: 0.6882 - accuracy: 0.54 - ETA: 6s - loss: 0.6890 - accuracy: 0.54 - ETA: 6s - loss: 0.6888 - accuracy: 0.54 - ETA: 6s - loss: 0.6891 - accuracy: 0.54 - ETA: 6s - loss: 0.6892 - accuracy: 0.54 - ETA: 6s - loss: 0.6896 - accuracy: 0.53 - ETA: 6s - loss: 0.6893 - accuracy: 0.54 - ETA: 6s - loss: 0.6891 - accuracy: 0.54 - ETA: 6s - loss: 0.6891 - accuracy: 0.54 - ETA: 5s - loss: 0.6889 - accuracy: 0.54 - ETA: 5s - loss: 0.6891 - accuracy: 0.54 - ETA: 5s - loss: 0.6892 - accuracy: 0.54 - ETA: 5s - loss: 0.6890 - accuracy: 0.54 - ETA: 5s - loss: 0.6889 - accuracy: 0.54 - ETA: 5s - loss: 0.6892 - accuracy: 0.54 - ETA: 5s - loss: 0.6893 - accuracy: 0.53 - ETA: 5s - loss: 0.6893 - accuracy: 0.53 - ETA: 5s - loss: 0.6892 - accuracy: 0.53 - ETA: 5s - loss: 0.6892 - accuracy: 0.53 - ETA: 4s - loss: 0.6891 - accuracy: 0.54 - ETA: 4s - loss: 0.6890 - accuracy: 0.54 - ETA: 4s - loss: 0.6890 - accuracy: 0.54 - ETA: 4s - loss: 0.6888 - accuracy: 0.54 - ETA: 4s - loss: 0.6888 - accuracy: 0.54 - ETA: 4s - loss: 0.6887 - accuracy: 0.54 - ETA: 4s - loss: 0.6886 - accuracy: 0.54 - ETA: 4s - loss: 0.6886 - accuracy: 0.54 - ETA: 4s - loss: 0.6886 - accuracy: 0.54 - ETA: 3s - loss: 0.6886 - accuracy: 0.54 - ETA: 3s - loss: 0.6886 - accuracy: 0.54 - ETA: 3s - loss: 0.6888 - accuracy: 0.54 - ETA: 3s - loss: 0.6886 - accuracy: 0.54 - ETA: 3s - loss: 0.6887 - accuracy: 0.54 - ETA: 3s - loss: 0.6887 - accuracy: 0.54 - ETA: 3s - loss: 0.6888 - accuracy: 0.54 - ETA: 3s - loss: 0.6888 - accuracy: 0.54 - ETA: 3s - loss: 0.6888 - accuracy: 0.54 - ETA: 2s - loss: 0.6889 - accuracy: 0.54 - ETA: 2s - loss: 0.6888 - accuracy: 0.54 - ETA: 2s - loss: 0.6888 - accuracy: 0.54 - ETA: 2s - loss: 0.6888 - accuracy: 0.54 - ETA: 2s - loss: 0.6888 - accuracy: 0.54 - ETA: 2s - loss: 0.6888 - accuracy: 0.54 - ETA: 2s - loss: 0.6888 - accuracy: 0.54 - ETA: 2s - loss: 0.6888 - accuracy: 0.54 - ETA: 2s - loss: 0.6888 - accuracy: 0.54 - ETA: 2s - loss: 0.6887 - accuracy: 0.54 - ETA: 1s - loss: 0.6888 - accuracy: 0.54 - ETA: 1s - loss: 0.6888 - accuracy: 0.54 - ETA: 1s - loss: 0.6888 - accuracy: 0.54 - ETA: 1s - loss: 0.6886 - accuracy: 0.54 - ETA: 1s - loss: 0.6885 - accuracy: 0.54 - ETA: 1s - loss: 0.6885 - accuracy: 0.54 - ETA: 1s - loss: 0.6886 - accuracy: 0.54 - ETA: 1s - loss: 0.6886 - accuracy: 0.54 - ETA: 1s - loss: 0.6886 - accuracy: 0.54 - ETA: 0s - loss: 0.6888 - accuracy: 0.54 - ETA: 0s - loss: 0.6889 - accuracy: 0.54 - ETA: 0s - loss: 0.6890 - accuracy: 0.54 - ETA: 0s - loss: 0.6891 - accuracy: 0.53 - ETA: 0s - loss: 0.6890 - accuracy: 0.53 - ETA: 0s - loss: 0.6890 - accuracy: 0.54 - ETA: 0s - loss: 0.6890 - accuracy: 0.53 - ETA: 0s - loss: 0.6891 - accuracy: 0.53 - ETA: 0s - loss: 0.6891 - accuracy: 0.53 - 9s 217us/step - loss: 0.6891 - accuracy: 0.5394\n",
      "\n",
      "Epoch 00004: loss improved from 0.68932 to 0.68909, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-04-0.6891.hdf5\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6889 - accuracy: 0.51 - ETA: 8s - loss: 0.6888 - accuracy: 0.52 - ETA: 8s - loss: 0.6893 - accuracy: 0.52 - ETA: 8s - loss: 0.6892 - accuracy: 0.52 - ETA: 8s - loss: 0.6892 - accuracy: 0.53 - ETA: 8s - loss: 0.6900 - accuracy: 0.52 - ETA: 8s - loss: 0.6901 - accuracy: 0.52 - ETA: 8s - loss: 0.6895 - accuracy: 0.52 - ETA: 8s - loss: 0.6893 - accuracy: 0.53 - ETA: 8s - loss: 0.6889 - accuracy: 0.53 - ETA: 7s - loss: 0.6886 - accuracy: 0.53 - ETA: 7s - loss: 0.6888 - accuracy: 0.53 - ETA: 7s - loss: 0.6894 - accuracy: 0.53 - ETA: 7s - loss: 0.6898 - accuracy: 0.53 - ETA: 7s - loss: 0.6896 - accuracy: 0.53 - ETA: 7s - loss: 0.6896 - accuracy: 0.53 - ETA: 7s - loss: 0.6895 - accuracy: 0.53 - ETA: 7s - loss: 0.6897 - accuracy: 0.53 - ETA: 7s - loss: 0.6895 - accuracy: 0.53 - ETA: 6s - loss: 0.6894 - accuracy: 0.53 - ETA: 6s - loss: 0.6892 - accuracy: 0.53 - ETA: 6s - loss: 0.6891 - accuracy: 0.53 - ETA: 6s - loss: 0.6889 - accuracy: 0.53 - ETA: 6s - loss: 0.6891 - accuracy: 0.53 - ETA: 6s - loss: 0.6889 - accuracy: 0.53 - ETA: 6s - loss: 0.6889 - accuracy: 0.53 - ETA: 6s - loss: 0.6887 - accuracy: 0.53 - ETA: 5s - loss: 0.6887 - accuracy: 0.53 - ETA: 5s - loss: 0.6888 - accuracy: 0.53 - ETA: 5s - loss: 0.6887 - accuracy: 0.53 - ETA: 5s - loss: 0.6889 - accuracy: 0.53 - ETA: 5s - loss: 0.6888 - accuracy: 0.53 - ETA: 5s - loss: 0.6888 - accuracy: 0.53 - ETA: 5s - loss: 0.6888 - accuracy: 0.53 - ETA: 5s - loss: 0.6888 - accuracy: 0.53 - ETA: 5s - loss: 0.6888 - accuracy: 0.53 - ETA: 4s - loss: 0.6887 - accuracy: 0.53 - ETA: 4s - loss: 0.6886 - accuracy: 0.53 - ETA: 4s - loss: 0.6886 - accuracy: 0.53 - ETA: 4s - loss: 0.6886 - accuracy: 0.53 - ETA: 4s - loss: 0.6886 - accuracy: 0.53 - ETA: 4s - loss: 0.6887 - accuracy: 0.53 - ETA: 4s - loss: 0.6886 - accuracy: 0.53 - ETA: 4s - loss: 0.6887 - accuracy: 0.53 - ETA: 3s - loss: 0.6887 - accuracy: 0.53 - ETA: 3s - loss: 0.6888 - accuracy: 0.53 - ETA: 3s - loss: 0.6888 - accuracy: 0.53 - ETA: 3s - loss: 0.6888 - accuracy: 0.53 - ETA: 3s - loss: 0.6887 - accuracy: 0.53 - ETA: 3s - loss: 0.6885 - accuracy: 0.53 - ETA: 3s - loss: 0.6884 - accuracy: 0.54 - ETA: 3s - loss: 0.6886 - accuracy: 0.53 - ETA: 2s - loss: 0.6885 - accuracy: 0.53 - ETA: 2s - loss: 0.6886 - accuracy: 0.53 - ETA: 2s - loss: 0.6886 - accuracy: 0.53 - ETA: 2s - loss: 0.6886 - accuracy: 0.53 - ETA: 2s - loss: 0.6885 - accuracy: 0.53 - ETA: 2s - loss: 0.6884 - accuracy: 0.54 - ETA: 2s - loss: 0.6885 - accuracy: 0.53 - ETA: 2s - loss: 0.6885 - accuracy: 0.54 - ETA: 2s - loss: 0.6885 - accuracy: 0.54 - ETA: 1s - loss: 0.6884 - accuracy: 0.54 - ETA: 1s - loss: 0.6884 - accuracy: 0.54 - ETA: 1s - loss: 0.6883 - accuracy: 0.54 - ETA: 1s - loss: 0.6883 - accuracy: 0.54 - ETA: 1s - loss: 0.6882 - accuracy: 0.54 - ETA: 1s - loss: 0.6882 - accuracy: 0.54 - ETA: 1s - loss: 0.6881 - accuracy: 0.54 - ETA: 1s - loss: 0.6881 - accuracy: 0.54 - ETA: 0s - loss: 0.6881 - accuracy: 0.54 - ETA: 0s - loss: 0.6881 - accuracy: 0.54 - ETA: 0s - loss: 0.6881 - accuracy: 0.54 - ETA: 0s - loss: 0.6881 - accuracy: 0.54 - ETA: 0s - loss: 0.6882 - accuracy: 0.54 - ETA: 0s - loss: 0.6882 - accuracy: 0.54 - ETA: 0s - loss: 0.6881 - accuracy: 0.54 - ETA: 0s - loss: 0.6881 - accuracy: 0.54 - ETA: 0s - loss: 0.6880 - accuracy: 0.54 - 9s 222us/step - loss: 0.6881 - accuracy: 0.5424\n",
      "\n",
      "Epoch 00005: loss improved from 0.68909 to 0.68808, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-05-0.6881.hdf5\n",
      "Epoch 6/50\n",
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6853 - accuracy: 0.53 - ETA: 8s - loss: 0.6816 - accuracy: 0.55 - ETA: 8s - loss: 0.6817 - accuracy: 0.55 - ETA: 8s - loss: 0.6832 - accuracy: 0.55 - ETA: 8s - loss: 0.6863 - accuracy: 0.54 - ETA: 8s - loss: 0.6861 - accuracy: 0.54 - ETA: 8s - loss: 0.6859 - accuracy: 0.54 - ETA: 8s - loss: 0.6860 - accuracy: 0.54 - ETA: 7s - loss: 0.6858 - accuracy: 0.55 - ETA: 7s - loss: 0.6863 - accuracy: 0.54 - ETA: 7s - loss: 0.6861 - accuracy: 0.55 - ETA: 7s - loss: 0.6865 - accuracy: 0.54 - ETA: 7s - loss: 0.6865 - accuracy: 0.54 - ETA: 7s - loss: 0.6864 - accuracy: 0.54 - ETA: 7s - loss: 0.6867 - accuracy: 0.54 - ETA: 7s - loss: 0.6865 - accuracy: 0.54 - ETA: 7s - loss: 0.6866 - accuracy: 0.54 - ETA: 6s - loss: 0.6865 - accuracy: 0.54 - ETA: 6s - loss: 0.6865 - accuracy: 0.54 - ETA: 6s - loss: 0.6866 - accuracy: 0.54 - ETA: 6s - loss: 0.6871 - accuracy: 0.54 - ETA: 6s - loss: 0.6871 - accuracy: 0.54 - ETA: 6s - loss: 0.6872 - accuracy: 0.54 - ETA: 6s - loss: 0.6873 - accuracy: 0.54 - ETA: 6s - loss: 0.6874 - accuracy: 0.54 - ETA: 6s - loss: 0.6875 - accuracy: 0.54 - ETA: 5s - loss: 0.6875 - accuracy: 0.54 - ETA: 5s - loss: 0.6874 - accuracy: 0.54 - ETA: 5s - loss: 0.6874 - accuracy: 0.54 - ETA: 5s - loss: 0.6874 - accuracy: 0.54 - ETA: 5s - loss: 0.6875 - accuracy: 0.54 - ETA: 5s - loss: 0.6875 - accuracy: 0.54 - ETA: 5s - loss: 0.6876 - accuracy: 0.54 - ETA: 5s - loss: 0.6874 - accuracy: 0.54 - ETA: 4s - loss: 0.6876 - accuracy: 0.54 - ETA: 4s - loss: 0.6877 - accuracy: 0.54 - ETA: 4s - loss: 0.6879 - accuracy: 0.54 - ETA: 4s - loss: 0.6878 - accuracy: 0.54 - ETA: 4s - loss: 0.6880 - accuracy: 0.54 - ETA: 4s - loss: 0.6879 - accuracy: 0.54 - ETA: 4s - loss: 0.6881 - accuracy: 0.54 - ETA: 4s - loss: 0.6881 - accuracy: 0.54 - ETA: 4s - loss: 0.6880 - accuracy: 0.54 - ETA: 3s - loss: 0.6879 - accuracy: 0.54 - ETA: 3s - loss: 0.6879 - accuracy: 0.54 - ETA: 3s - loss: 0.6880 - accuracy: 0.54 - ETA: 3s - loss: 0.6878 - accuracy: 0.54 - ETA: 3s - loss: 0.6879 - accuracy: 0.54 - ETA: 3s - loss: 0.6879 - accuracy: 0.54 - ETA: 3s - loss: 0.6879 - accuracy: 0.54 - ETA: 3s - loss: 0.6878 - accuracy: 0.54 - ETA: 3s - loss: 0.6879 - accuracy: 0.54 - ETA: 2s - loss: 0.6879 - accuracy: 0.54 - ETA: 2s - loss: 0.6879 - accuracy: 0.54 - ETA: 2s - loss: 0.6879 - accuracy: 0.54 - ETA: 2s - loss: 0.6880 - accuracy: 0.54 - ETA: 2s - loss: 0.6880 - accuracy: 0.54 - ETA: 2s - loss: 0.6881 - accuracy: 0.54 - ETA: 2s - loss: 0.6881 - accuracy: 0.54 - ETA: 2s - loss: 0.6881 - accuracy: 0.54 - ETA: 1s - loss: 0.6880 - accuracy: 0.54 - ETA: 1s - loss: 0.6880 - accuracy: 0.54 - ETA: 1s - loss: 0.6879 - accuracy: 0.54 - ETA: 1s - loss: 0.6879 - accuracy: 0.54 - ETA: 1s - loss: 0.6879 - accuracy: 0.54 - ETA: 1s - loss: 0.6878 - accuracy: 0.54 - ETA: 1s - loss: 0.6879 - accuracy: 0.54 - ETA: 1s - loss: 0.6879 - accuracy: 0.54 - ETA: 1s - loss: 0.6880 - accuracy: 0.54 - ETA: 0s - loss: 0.6882 - accuracy: 0.54 - ETA: 0s - loss: 0.6881 - accuracy: 0.54 - ETA: 0s - loss: 0.6881 - accuracy: 0.54 - ETA: 0s - loss: 0.6881 - accuracy: 0.54 - ETA: 0s - loss: 0.6880 - accuracy: 0.54 - ETA: 0s - loss: 0.6879 - accuracy: 0.54 - ETA: 0s - loss: 0.6879 - accuracy: 0.54 - ETA: 0s - loss: 0.6878 - accuracy: 0.54 - ETA: 0s - loss: 0.6878 - accuracy: 0.54 - 9s 222us/step - loss: 0.6878 - accuracy: 0.5435\n",
      "\n",
      "Epoch 00006: loss improved from 0.68808 to 0.68779, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-06-0.6878.hdf5\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6816 - accuracy: 0.57 - ETA: 8s - loss: 0.6828 - accuracy: 0.56 - ETA: 8s - loss: 0.6855 - accuracy: 0.55 - ETA: 8s - loss: 0.6852 - accuracy: 0.54 - ETA: 8s - loss: 0.6838 - accuracy: 0.55 - ETA: 8s - loss: 0.6841 - accuracy: 0.55 - ETA: 8s - loss: 0.6848 - accuracy: 0.55 - ETA: 7s - loss: 0.6861 - accuracy: 0.55 - ETA: 7s - loss: 0.6852 - accuracy: 0.55 - ETA: 7s - loss: 0.6854 - accuracy: 0.55 - ETA: 7s - loss: 0.6857 - accuracy: 0.55 - ETA: 7s - loss: 0.6852 - accuracy: 0.55 - ETA: 7s - loss: 0.6853 - accuracy: 0.55 - ETA: 7s - loss: 0.6855 - accuracy: 0.55 - ETA: 7s - loss: 0.6857 - accuracy: 0.55 - ETA: 7s - loss: 0.6855 - accuracy: 0.55 - ETA: 7s - loss: 0.6857 - accuracy: 0.55 - ETA: 6s - loss: 0.6860 - accuracy: 0.55 - ETA: 6s - loss: 0.6859 - accuracy: 0.55 - ETA: 6s - loss: 0.6860 - accuracy: 0.54 - ETA: 6s - loss: 0.6857 - accuracy: 0.55 - ETA: 6s - loss: 0.6856 - accuracy: 0.55 - ETA: 6s - loss: 0.6856 - accuracy: 0.55 - ETA: 6s - loss: 0.6857 - accuracy: 0.55 - ETA: 6s - loss: 0.6857 - accuracy: 0.55 - ETA: 6s - loss: 0.6857 - accuracy: 0.55 - ETA: 5s - loss: 0.6857 - accuracy: 0.55 - ETA: 5s - loss: 0.6855 - accuracy: 0.55 - ETA: 5s - loss: 0.6855 - accuracy: 0.55 - ETA: 5s - loss: 0.6854 - accuracy: 0.55 - ETA: 5s - loss: 0.6854 - accuracy: 0.55 - ETA: 5s - loss: 0.6854 - accuracy: 0.55 - ETA: 5s - loss: 0.6856 - accuracy: 0.55 - ETA: 5s - loss: 0.6858 - accuracy: 0.55 - ETA: 5s - loss: 0.6860 - accuracy: 0.54 - ETA: 4s - loss: 0.6859 - accuracy: 0.54 - ETA: 4s - loss: 0.6859 - accuracy: 0.55 - ETA: 4s - loss: 0.6858 - accuracy: 0.55 - ETA: 4s - loss: 0.6858 - accuracy: 0.55 - ETA: 4s - loss: 0.6859 - accuracy: 0.55 - ETA: 4s - loss: 0.6859 - accuracy: 0.55 - ETA: 4s - loss: 0.6858 - accuracy: 0.55 - ETA: 4s - loss: 0.6862 - accuracy: 0.54 - ETA: 4s - loss: 0.6859 - accuracy: 0.55 - ETA: 3s - loss: 0.6860 - accuracy: 0.54 - ETA: 3s - loss: 0.6863 - accuracy: 0.54 - ETA: 3s - loss: 0.6862 - accuracy: 0.54 - ETA: 3s - loss: 0.6863 - accuracy: 0.54 - ETA: 3s - loss: 0.6865 - accuracy: 0.54 - ETA: 3s - loss: 0.6864 - accuracy: 0.54 - ETA: 3s - loss: 0.6864 - accuracy: 0.54 - ETA: 3s - loss: 0.6864 - accuracy: 0.54 - ETA: 2s - loss: 0.6864 - accuracy: 0.54 - ETA: 2s - loss: 0.6863 - accuracy: 0.54 - ETA: 2s - loss: 0.6864 - accuracy: 0.54 - ETA: 2s - loss: 0.6864 - accuracy: 0.54 - ETA: 2s - loss: 0.6865 - accuracy: 0.54 - ETA: 2s - loss: 0.6866 - accuracy: 0.54 - ETA: 2s - loss: 0.6865 - accuracy: 0.54 - ETA: 2s - loss: 0.6865 - accuracy: 0.54 - ETA: 2s - loss: 0.6864 - accuracy: 0.54 - ETA: 1s - loss: 0.6865 - accuracy: 0.54 - ETA: 1s - loss: 0.6865 - accuracy: 0.54 - ETA: 1s - loss: 0.6865 - accuracy: 0.54 - ETA: 1s - loss: 0.6866 - accuracy: 0.54 - ETA: 1s - loss: 0.6866 - accuracy: 0.54 - ETA: 1s - loss: 0.6867 - accuracy: 0.54 - ETA: 1s - loss: 0.6867 - accuracy: 0.54 - ETA: 1s - loss: 0.6867 - accuracy: 0.54 - ETA: 0s - loss: 0.6868 - accuracy: 0.54 - ETA: 0s - loss: 0.6869 - accuracy: 0.54 - ETA: 0s - loss: 0.6870 - accuracy: 0.54 - ETA: 0s - loss: 0.6870 - accuracy: 0.54 - ETA: 0s - loss: 0.6871 - accuracy: 0.54 - ETA: 0s - loss: 0.6872 - accuracy: 0.54 - ETA: 0s - loss: 0.6871 - accuracy: 0.54 - ETA: 0s - loss: 0.6872 - accuracy: 0.54 - ETA: 0s - loss: 0.6872 - accuracy: 0.54 - 9s 225us/step - loss: 0.6873 - accuracy: 0.5446\n",
      "\n",
      "Epoch 00007: loss improved from 0.68779 to 0.68725, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-07-0.6873.hdf5\n",
      "Epoch 8/50\n",
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6893 - accuracy: 0.55 - ETA: 8s - loss: 0.6875 - accuracy: 0.54 - ETA: 8s - loss: 0.6867 - accuracy: 0.55 - ETA: 8s - loss: 0.6884 - accuracy: 0.54 - ETA: 8s - loss: 0.6883 - accuracy: 0.54 - ETA: 8s - loss: 0.6879 - accuracy: 0.54 - ETA: 7s - loss: 0.6879 - accuracy: 0.54 - ETA: 7s - loss: 0.6871 - accuracy: 0.55 - ETA: 7s - loss: 0.6869 - accuracy: 0.55 - ETA: 7s - loss: 0.6872 - accuracy: 0.55 - ETA: 7s - loss: 0.6872 - accuracy: 0.55 - ETA: 7s - loss: 0.6874 - accuracy: 0.54 - ETA: 7s - loss: 0.6880 - accuracy: 0.54 - ETA: 7s - loss: 0.6881 - accuracy: 0.54 - ETA: 7s - loss: 0.6877 - accuracy: 0.54 - ETA: 7s - loss: 0.6872 - accuracy: 0.54 - ETA: 7s - loss: 0.6869 - accuracy: 0.54 - ETA: 6s - loss: 0.6871 - accuracy: 0.54 - ETA: 6s - loss: 0.6873 - accuracy: 0.54 - ETA: 6s - loss: 0.6872 - accuracy: 0.54 - ETA: 6s - loss: 0.6877 - accuracy: 0.54 - ETA: 6s - loss: 0.6874 - accuracy: 0.54 - ETA: 6s - loss: 0.6872 - accuracy: 0.54 - ETA: 6s - loss: 0.6872 - accuracy: 0.54 - ETA: 6s - loss: 0.6870 - accuracy: 0.54 - ETA: 6s - loss: 0.6869 - accuracy: 0.54 - ETA: 6s - loss: 0.6868 - accuracy: 0.54 - ETA: 5s - loss: 0.6869 - accuracy: 0.54 - ETA: 5s - loss: 0.6868 - accuracy: 0.54 - ETA: 5s - loss: 0.6866 - accuracy: 0.54 - ETA: 5s - loss: 0.6867 - accuracy: 0.54 - ETA: 5s - loss: 0.6868 - accuracy: 0.54 - ETA: 5s - loss: 0.6866 - accuracy: 0.54 - ETA: 5s - loss: 0.6865 - accuracy: 0.54 - ETA: 5s - loss: 0.6862 - accuracy: 0.54 - ETA: 5s - loss: 0.6860 - accuracy: 0.54 - ETA: 4s - loss: 0.6863 - accuracy: 0.54 - ETA: 4s - loss: 0.6861 - accuracy: 0.54 - ETA: 4s - loss: 0.6865 - accuracy: 0.54 - ETA: 4s - loss: 0.6865 - accuracy: 0.54 - ETA: 4s - loss: 0.6866 - accuracy: 0.54 - ETA: 4s - loss: 0.6866 - accuracy: 0.54 - ETA: 4s - loss: 0.6866 - accuracy: 0.54 - ETA: 4s - loss: 0.6866 - accuracy: 0.54 - ETA: 4s - loss: 0.6866 - accuracy: 0.54 - ETA: 3s - loss: 0.6866 - accuracy: 0.54 - ETA: 3s - loss: 0.6865 - accuracy: 0.54 - ETA: 3s - loss: 0.6866 - accuracy: 0.54 - ETA: 3s - loss: 0.6866 - accuracy: 0.54 - ETA: 3s - loss: 0.6865 - accuracy: 0.54 - ETA: 3s - loss: 0.6866 - accuracy: 0.54 - ETA: 3s - loss: 0.6866 - accuracy: 0.54 - ETA: 3s - loss: 0.6866 - accuracy: 0.54 - ETA: 2s - loss: 0.6867 - accuracy: 0.54 - ETA: 2s - loss: 0.6868 - accuracy: 0.54 - ETA: 2s - loss: 0.6868 - accuracy: 0.54 - ETA: 2s - loss: 0.6869 - accuracy: 0.54 - ETA: 2s - loss: 0.6870 - accuracy: 0.54 - ETA: 2s - loss: 0.6870 - accuracy: 0.54 - ETA: 2s - loss: 0.6870 - accuracy: 0.54 - ETA: 2s - loss: 0.6869 - accuracy: 0.54 - ETA: 1s - loss: 0.6869 - accuracy: 0.54 - ETA: 1s - loss: 0.6868 - accuracy: 0.54 - ETA: 1s - loss: 0.6869 - accuracy: 0.54 - ETA: 1s - loss: 0.6868 - accuracy: 0.54 - ETA: 1s - loss: 0.6868 - accuracy: 0.54 - ETA: 1s - loss: 0.6866 - accuracy: 0.54 - ETA: 1s - loss: 0.6865 - accuracy: 0.54 - ETA: 1s - loss: 0.6866 - accuracy: 0.54 - ETA: 1s - loss: 0.6867 - accuracy: 0.54 - ETA: 0s - loss: 0.6867 - accuracy: 0.54 - ETA: 0s - loss: 0.6867 - accuracy: 0.54 - ETA: 0s - loss: 0.6867 - accuracy: 0.54 - ETA: 0s - loss: 0.6868 - accuracy: 0.54 - ETA: 0s - loss: 0.6869 - accuracy: 0.54 - ETA: 0s - loss: 0.6870 - accuracy: 0.54 - ETA: 0s - loss: 0.6869 - accuracy: 0.54 - ETA: 0s - loss: 0.6870 - accuracy: 0.54 - 9s 229us/step - loss: 0.6870 - accuracy: 0.5453\n",
      "\n",
      "Epoch 00008: loss improved from 0.68725 to 0.68701, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-08-0.6870.hdf5\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6809 - accuracy: 0.57 - ETA: 8s - loss: 0.6835 - accuracy: 0.56 - ETA: 8s - loss: 0.6842 - accuracy: 0.56 - ETA: 7s - loss: 0.6854 - accuracy: 0.55 - ETA: 7s - loss: 0.6864 - accuracy: 0.53 - ETA: 7s - loss: 0.6875 - accuracy: 0.53 - ETA: 7s - loss: 0.6877 - accuracy: 0.53 - ETA: 7s - loss: 0.6876 - accuracy: 0.53 - ETA: 7s - loss: 0.6878 - accuracy: 0.53 - ETA: 7s - loss: 0.6871 - accuracy: 0.54 - ETA: 7s - loss: 0.6869 - accuracy: 0.54 - ETA: 7s - loss: 0.6868 - accuracy: 0.54 - ETA: 7s - loss: 0.6870 - accuracy: 0.54 - ETA: 6s - loss: 0.6865 - accuracy: 0.54 - ETA: 6s - loss: 0.6859 - accuracy: 0.54 - ETA: 6s - loss: 0.6852 - accuracy: 0.54 - ETA: 6s - loss: 0.6855 - accuracy: 0.54 - ETA: 6s - loss: 0.6854 - accuracy: 0.55 - ETA: 6s - loss: 0.6858 - accuracy: 0.54 - ETA: 6s - loss: 0.6858 - accuracy: 0.54 - ETA: 6s - loss: 0.6858 - accuracy: 0.54 - ETA: 6s - loss: 0.6856 - accuracy: 0.55 - ETA: 6s - loss: 0.6853 - accuracy: 0.55 - ETA: 5s - loss: 0.6852 - accuracy: 0.55 - ETA: 5s - loss: 0.6853 - accuracy: 0.55 - ETA: 5s - loss: 0.6856 - accuracy: 0.54 - ETA: 5s - loss: 0.6857 - accuracy: 0.54 - ETA: 5s - loss: 0.6855 - accuracy: 0.54 - ETA: 5s - loss: 0.6857 - accuracy: 0.54 - ETA: 5s - loss: 0.6857 - accuracy: 0.54 - ETA: 5s - loss: 0.6856 - accuracy: 0.54 - ETA: 5s - loss: 0.6856 - accuracy: 0.54 - ETA: 4s - loss: 0.6859 - accuracy: 0.54 - ETA: 4s - loss: 0.6859 - accuracy: 0.54 - ETA: 4s - loss: 0.6860 - accuracy: 0.54 - ETA: 4s - loss: 0.6859 - accuracy: 0.54 - ETA: 4s - loss: 0.6860 - accuracy: 0.54 - ETA: 4s - loss: 0.6861 - accuracy: 0.54 - ETA: 4s - loss: 0.6860 - accuracy: 0.54 - ETA: 4s - loss: 0.6860 - accuracy: 0.54 - ETA: 4s - loss: 0.6859 - accuracy: 0.54 - ETA: 3s - loss: 0.6857 - accuracy: 0.54 - ETA: 3s - loss: 0.6856 - accuracy: 0.54 - ETA: 3s - loss: 0.6855 - accuracy: 0.54 - ETA: 3s - loss: 0.6855 - accuracy: 0.54 - ETA: 3s - loss: 0.6854 - accuracy: 0.54 - ETA: 3s - loss: 0.6858 - accuracy: 0.54 - ETA: 3s - loss: 0.6859 - accuracy: 0.54 - ETA: 3s - loss: 0.6858 - accuracy: 0.54 - ETA: 3s - loss: 0.6859 - accuracy: 0.54 - ETA: 3s - loss: 0.6860 - accuracy: 0.54 - ETA: 2s - loss: 0.6861 - accuracy: 0.54 - ETA: 2s - loss: 0.6861 - accuracy: 0.54 - ETA: 2s - loss: 0.6862 - accuracy: 0.54 - ETA: 2s - loss: 0.6863 - accuracy: 0.54 - ETA: 2s - loss: 0.6862 - accuracy: 0.54 - ETA: 2s - loss: 0.6862 - accuracy: 0.54 - ETA: 2s - loss: 0.6862 - accuracy: 0.54 - ETA: 2s - loss: 0.6862 - accuracy: 0.54 - ETA: 2s - loss: 0.6862 - accuracy: 0.54 - ETA: 1s - loss: 0.6863 - accuracy: 0.54 - ETA: 1s - loss: 0.6862 - accuracy: 0.54 - ETA: 1s - loss: 0.6862 - accuracy: 0.54 - ETA: 1s - loss: 0.6862 - accuracy: 0.54 - ETA: 1s - loss: 0.6862 - accuracy: 0.54 - ETA: 1s - loss: 0.6863 - accuracy: 0.54 - ETA: 1s - loss: 0.6863 - accuracy: 0.54 - ETA: 1s - loss: 0.6864 - accuracy: 0.54 - ETA: 1s - loss: 0.6865 - accuracy: 0.54 - ETA: 0s - loss: 0.6865 - accuracy: 0.54 - ETA: 0s - loss: 0.6865 - accuracy: 0.54 - ETA: 0s - loss: 0.6867 - accuracy: 0.54 - ETA: 0s - loss: 0.6867 - accuracy: 0.54 - ETA: 0s - loss: 0.6867 - accuracy: 0.54 - ETA: 0s - loss: 0.6867 - accuracy: 0.54 - ETA: 0s - loss: 0.6867 - accuracy: 0.54 - ETA: 0s - loss: 0.6866 - accuracy: 0.54 - ETA: 0s - loss: 0.6867 - accuracy: 0.54 - 9s 219us/step - loss: 0.6867 - accuracy: 0.5459\n",
      "\n",
      "Epoch 00009: loss improved from 0.68701 to 0.68666, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-09-0.6867.hdf5\n",
      "Epoch 10/50\n",
      "40268/40268 [==============================] - ETA: 9s - loss: 0.6874 - accuracy: 0.55 - ETA: 9s - loss: 0.6881 - accuracy: 0.54 - ETA: 9s - loss: 0.6892 - accuracy: 0.54 - ETA: 9s - loss: 0.6886 - accuracy: 0.54 - ETA: 9s - loss: 0.6885 - accuracy: 0.54 - ETA: 9s - loss: 0.6882 - accuracy: 0.54 - ETA: 9s - loss: 0.6867 - accuracy: 0.55 - ETA: 9s - loss: 0.6875 - accuracy: 0.54 - ETA: 9s - loss: 0.6886 - accuracy: 0.54 - ETA: 9s - loss: 0.6889 - accuracy: 0.54 - ETA: 9s - loss: 0.6880 - accuracy: 0.54 - ETA: 9s - loss: 0.6877 - accuracy: 0.54 - ETA: 9s - loss: 0.6872 - accuracy: 0.54 - ETA: 8s - loss: 0.6875 - accuracy: 0.54 - ETA: 8s - loss: 0.6875 - accuracy: 0.54 - ETA: 8s - loss: 0.6873 - accuracy: 0.54 - ETA: 8s - loss: 0.6872 - accuracy: 0.54 - ETA: 8s - loss: 0.6872 - accuracy: 0.54 - ETA: 8s - loss: 0.6877 - accuracy: 0.54 - ETA: 8s - loss: 0.6877 - accuracy: 0.54 - ETA: 8s - loss: 0.6873 - accuracy: 0.54 - ETA: 7s - loss: 0.6869 - accuracy: 0.54 - ETA: 7s - loss: 0.6865 - accuracy: 0.54 - ETA: 7s - loss: 0.6866 - accuracy: 0.54 - ETA: 7s - loss: 0.6866 - accuracy: 0.54 - ETA: 7s - loss: 0.6866 - accuracy: 0.54 - ETA: 7s - loss: 0.6866 - accuracy: 0.54 - ETA: 7s - loss: 0.6865 - accuracy: 0.54 - ETA: 6s - loss: 0.6864 - accuracy: 0.54 - ETA: 6s - loss: 0.6865 - accuracy: 0.54 - ETA: 6s - loss: 0.6864 - accuracy: 0.54 - ETA: 6s - loss: 0.6862 - accuracy: 0.55 - ETA: 6s - loss: 0.6860 - accuracy: 0.55 - ETA: 6s - loss: 0.6858 - accuracy: 0.55 - ETA: 6s - loss: 0.6856 - accuracy: 0.55 - ETA: 5s - loss: 0.6857 - accuracy: 0.55 - ETA: 5s - loss: 0.6857 - accuracy: 0.55 - ETA: 5s - loss: 0.6857 - accuracy: 0.55 - ETA: 5s - loss: 0.6857 - accuracy: 0.55 - ETA: 5s - loss: 0.6859 - accuracy: 0.54 - ETA: 5s - loss: 0.6859 - accuracy: 0.54 - ETA: 5s - loss: 0.6859 - accuracy: 0.54 - ETA: 5s - loss: 0.6861 - accuracy: 0.54 - ETA: 4s - loss: 0.6863 - accuracy: 0.54 - ETA: 4s - loss: 0.6863 - accuracy: 0.54 - ETA: 4s - loss: 0.6860 - accuracy: 0.54 - ETA: 4s - loss: 0.6858 - accuracy: 0.54 - ETA: 4s - loss: 0.6859 - accuracy: 0.54 - ETA: 4s - loss: 0.6860 - accuracy: 0.54 - ETA: 4s - loss: 0.6861 - accuracy: 0.54 - ETA: 3s - loss: 0.6860 - accuracy: 0.54 - ETA: 3s - loss: 0.6861 - accuracy: 0.54 - ETA: 3s - loss: 0.6861 - accuracy: 0.54 - ETA: 3s - loss: 0.6862 - accuracy: 0.54 - ETA: 3s - loss: 0.6862 - accuracy: 0.54 - ETA: 3s - loss: 0.6861 - accuracy: 0.54 - ETA: 3s - loss: 0.6861 - accuracy: 0.54 - ETA: 2s - loss: 0.6861 - accuracy: 0.54 - ETA: 2s - loss: 0.6860 - accuracy: 0.54 - ETA: 2s - loss: 0.6861 - accuracy: 0.54 - ETA: 2s - loss: 0.6859 - accuracy: 0.54 - ETA: 2s - loss: 0.6861 - accuracy: 0.54 - ETA: 2s - loss: 0.6860 - accuracy: 0.54 - ETA: 2s - loss: 0.6858 - accuracy: 0.54 - ETA: 1s - loss: 0.6857 - accuracy: 0.54 - ETA: 1s - loss: 0.6858 - accuracy: 0.54 - ETA: 1s - loss: 0.6858 - accuracy: 0.54 - ETA: 1s - loss: 0.6862 - accuracy: 0.54 - ETA: 1s - loss: 0.6860 - accuracy: 0.54 - ETA: 1s - loss: 0.6860 - accuracy: 0.54 - ETA: 1s - loss: 0.6859 - accuracy: 0.54 - ETA: 0s - loss: 0.6859 - accuracy: 0.54 - ETA: 0s - loss: 0.6859 - accuracy: 0.54 - ETA: 0s - loss: 0.6858 - accuracy: 0.54 - ETA: 0s - loss: 0.6860 - accuracy: 0.54 - ETA: 0s - loss: 0.6860 - accuracy: 0.54 - ETA: 0s - loss: 0.6860 - accuracy: 0.54 - ETA: 0s - loss: 0.6860 - accuracy: 0.54 - 11s 272us/step - loss: 0.6861 - accuracy: 0.5470\n",
      "\n",
      "Epoch 00010: loss improved from 0.68666 to 0.68609, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-10-0.6861.hdf5\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 9s - loss: 0.6843 - accuracy: 0.54 - ETA: 9s - loss: 0.6795 - accuracy: 0.57 - ETA: 9s - loss: 0.6808 - accuracy: 0.57 - ETA: 9s - loss: 0.6804 - accuracy: 0.57 - ETA: 9s - loss: 0.6805 - accuracy: 0.57 - ETA: 9s - loss: 0.6826 - accuracy: 0.56 - ETA: 9s - loss: 0.6829 - accuracy: 0.55 - ETA: 9s - loss: 0.6825 - accuracy: 0.56 - ETA: 9s - loss: 0.6826 - accuracy: 0.56 - ETA: 9s - loss: 0.6832 - accuracy: 0.55 - ETA: 9s - loss: 0.6838 - accuracy: 0.55 - ETA: 9s - loss: 0.6842 - accuracy: 0.55 - ETA: 9s - loss: 0.6843 - accuracy: 0.55 - ETA: 9s - loss: 0.6848 - accuracy: 0.55 - ETA: 9s - loss: 0.6854 - accuracy: 0.55 - ETA: 8s - loss: 0.6858 - accuracy: 0.54 - ETA: 8s - loss: 0.6859 - accuracy: 0.54 - ETA: 8s - loss: 0.6857 - accuracy: 0.55 - ETA: 8s - loss: 0.6855 - accuracy: 0.55 - ETA: 8s - loss: 0.6861 - accuracy: 0.54 - ETA: 8s - loss: 0.6861 - accuracy: 0.54 - ETA: 8s - loss: 0.6858 - accuracy: 0.54 - ETA: 8s - loss: 0.6857 - accuracy: 0.55 - ETA: 7s - loss: 0.6855 - accuracy: 0.55 - ETA: 7s - loss: 0.6854 - accuracy: 0.55 - ETA: 7s - loss: 0.6854 - accuracy: 0.55 - ETA: 7s - loss: 0.6856 - accuracy: 0.55 - ETA: 7s - loss: 0.6857 - accuracy: 0.55 - ETA: 7s - loss: 0.6855 - accuracy: 0.55 - ETA: 7s - loss: 0.6860 - accuracy: 0.55 - ETA: 6s - loss: 0.6858 - accuracy: 0.55 - ETA: 6s - loss: 0.6859 - accuracy: 0.55 - ETA: 6s - loss: 0.6859 - accuracy: 0.55 - ETA: 6s - loss: 0.6860 - accuracy: 0.55 - ETA: 6s - loss: 0.6861 - accuracy: 0.55 - ETA: 6s - loss: 0.6862 - accuracy: 0.55 - ETA: 6s - loss: 0.6863 - accuracy: 0.55 - ETA: 5s - loss: 0.6862 - accuracy: 0.55 - ETA: 5s - loss: 0.6862 - accuracy: 0.55 - ETA: 5s - loss: 0.6862 - accuracy: 0.54 - ETA: 5s - loss: 0.6861 - accuracy: 0.55 - ETA: 5s - loss: 0.6860 - accuracy: 0.55 - ETA: 5s - loss: 0.6860 - accuracy: 0.54 - ETA: 5s - loss: 0.6861 - accuracy: 0.54 - ETA: 4s - loss: 0.6862 - accuracy: 0.54 - ETA: 4s - loss: 0.6862 - accuracy: 0.54 - ETA: 4s - loss: 0.6862 - accuracy: 0.54 - ETA: 4s - loss: 0.6862 - accuracy: 0.54 - ETA: 4s - loss: 0.6862 - accuracy: 0.54 - ETA: 4s - loss: 0.6862 - accuracy: 0.54 - ETA: 3s - loss: 0.6862 - accuracy: 0.54 - ETA: 3s - loss: 0.6863 - accuracy: 0.54 - ETA: 3s - loss: 0.6863 - accuracy: 0.54 - ETA: 3s - loss: 0.6862 - accuracy: 0.54 - ETA: 3s - loss: 0.6861 - accuracy: 0.54 - ETA: 3s - loss: 0.6860 - accuracy: 0.54 - ETA: 3s - loss: 0.6860 - accuracy: 0.54 - ETA: 2s - loss: 0.6858 - accuracy: 0.54 - ETA: 2s - loss: 0.6860 - accuracy: 0.54 - ETA: 2s - loss: 0.6858 - accuracy: 0.54 - ETA: 2s - loss: 0.6859 - accuracy: 0.54 - ETA: 2s - loss: 0.6858 - accuracy: 0.54 - ETA: 2s - loss: 0.6859 - accuracy: 0.54 - ETA: 2s - loss: 0.6858 - accuracy: 0.54 - ETA: 1s - loss: 0.6858 - accuracy: 0.54 - ETA: 1s - loss: 0.6858 - accuracy: 0.54 - ETA: 1s - loss: 0.6859 - accuracy: 0.54 - ETA: 1s - loss: 0.6859 - accuracy: 0.54 - ETA: 1s - loss: 0.6859 - accuracy: 0.54 - ETA: 1s - loss: 0.6859 - accuracy: 0.54 - ETA: 1s - loss: 0.6861 - accuracy: 0.54 - ETA: 0s - loss: 0.6861 - accuracy: 0.54 - ETA: 0s - loss: 0.6861 - accuracy: 0.54 - ETA: 0s - loss: 0.6861 - accuracy: 0.54 - ETA: 0s - loss: 0.6862 - accuracy: 0.54 - ETA: 0s - loss: 0.6861 - accuracy: 0.54 - ETA: 0s - loss: 0.6862 - accuracy: 0.54 - ETA: 0s - loss: 0.6861 - accuracy: 0.54 - 10s 258us/step - loss: 0.6862 - accuracy: 0.5470\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.68609\n",
      "Epoch 12/50\n",
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6752 - accuracy: 0.58 - ETA: 7s - loss: 0.6766 - accuracy: 0.57 - ETA: 7s - loss: 0.6802 - accuracy: 0.55 - ETA: 7s - loss: 0.6794 - accuracy: 0.56 - ETA: 7s - loss: 0.6834 - accuracy: 0.55 - ETA: 7s - loss: 0.6831 - accuracy: 0.55 - ETA: 7s - loss: 0.6813 - accuracy: 0.55 - ETA: 7s - loss: 0.6815 - accuracy: 0.55 - ETA: 7s - loss: 0.6822 - accuracy: 0.54 - ETA: 7s - loss: 0.6827 - accuracy: 0.54 - ETA: 7s - loss: 0.6836 - accuracy: 0.54 - ETA: 7s - loss: 0.6844 - accuracy: 0.54 - ETA: 7s - loss: 0.6846 - accuracy: 0.54 - ETA: 7s - loss: 0.6849 - accuracy: 0.54 - ETA: 6s - loss: 0.6849 - accuracy: 0.54 - ETA: 6s - loss: 0.6849 - accuracy: 0.54 - ETA: 6s - loss: 0.6854 - accuracy: 0.54 - ETA: 6s - loss: 0.6854 - accuracy: 0.54 - ETA: 6s - loss: 0.6855 - accuracy: 0.54 - ETA: 6s - loss: 0.6854 - accuracy: 0.54 - ETA: 6s - loss: 0.6852 - accuracy: 0.54 - ETA: 6s - loss: 0.6855 - accuracy: 0.54 - ETA: 6s - loss: 0.6855 - accuracy: 0.54 - ETA: 5s - loss: 0.6859 - accuracy: 0.54 - ETA: 5s - loss: 0.6859 - accuracy: 0.54 - ETA: 5s - loss: 0.6858 - accuracy: 0.54 - ETA: 5s - loss: 0.6858 - accuracy: 0.54 - ETA: 5s - loss: 0.6859 - accuracy: 0.54 - ETA: 5s - loss: 0.6859 - accuracy: 0.54 - ETA: 5s - loss: 0.6857 - accuracy: 0.54 - ETA: 5s - loss: 0.6857 - accuracy: 0.54 - ETA: 5s - loss: 0.6858 - accuracy: 0.54 - ETA: 4s - loss: 0.6860 - accuracy: 0.54 - ETA: 4s - loss: 0.6862 - accuracy: 0.54 - ETA: 4s - loss: 0.6863 - accuracy: 0.54 - ETA: 4s - loss: 0.6864 - accuracy: 0.54 - ETA: 4s - loss: 0.6864 - accuracy: 0.54 - ETA: 4s - loss: 0.6863 - accuracy: 0.54 - ETA: 4s - loss: 0.6862 - accuracy: 0.54 - ETA: 4s - loss: 0.6863 - accuracy: 0.54 - ETA: 4s - loss: 0.6863 - accuracy: 0.54 - ETA: 3s - loss: 0.6862 - accuracy: 0.54 - ETA: 3s - loss: 0.6862 - accuracy: 0.54 - ETA: 3s - loss: 0.6860 - accuracy: 0.54 - ETA: 3s - loss: 0.6859 - accuracy: 0.54 - ETA: 3s - loss: 0.6860 - accuracy: 0.54 - ETA: 3s - loss: 0.6859 - accuracy: 0.54 - ETA: 3s - loss: 0.6858 - accuracy: 0.54 - ETA: 3s - loss: 0.6858 - accuracy: 0.54 - ETA: 3s - loss: 0.6856 - accuracy: 0.54 - ETA: 3s - loss: 0.6857 - accuracy: 0.54 - ETA: 2s - loss: 0.6856 - accuracy: 0.54 - ETA: 2s - loss: 0.6857 - accuracy: 0.54 - ETA: 2s - loss: 0.6856 - accuracy: 0.54 - ETA: 2s - loss: 0.6856 - accuracy: 0.54 - ETA: 2s - loss: 0.6857 - accuracy: 0.54 - ETA: 2s - loss: 0.6858 - accuracy: 0.54 - ETA: 2s - loss: 0.6859 - accuracy: 0.54 - ETA: 2s - loss: 0.6858 - accuracy: 0.54 - ETA: 2s - loss: 0.6858 - accuracy: 0.54 - ETA: 1s - loss: 0.6856 - accuracy: 0.54 - ETA: 1s - loss: 0.6856 - accuracy: 0.54 - ETA: 1s - loss: 0.6856 - accuracy: 0.54 - ETA: 1s - loss: 0.6856 - accuracy: 0.54 - ETA: 1s - loss: 0.6856 - accuracy: 0.54 - ETA: 1s - loss: 0.6856 - accuracy: 0.54 - ETA: 1s - loss: 0.6855 - accuracy: 0.54 - ETA: 1s - loss: 0.6855 - accuracy: 0.54 - ETA: 1s - loss: 0.6854 - accuracy: 0.54 - ETA: 0s - loss: 0.6854 - accuracy: 0.54 - ETA: 0s - loss: 0.6853 - accuracy: 0.54 - ETA: 0s - loss: 0.6854 - accuracy: 0.54 - ETA: 0s - loss: 0.6854 - accuracy: 0.54 - ETA: 0s - loss: 0.6854 - accuracy: 0.54 - ETA: 0s - loss: 0.6855 - accuracy: 0.54 - ETA: 0s - loss: 0.6855 - accuracy: 0.54 - ETA: 0s - loss: 0.6855 - accuracy: 0.54 - ETA: 0s - loss: 0.6855 - accuracy: 0.54 - 9s 213us/step - loss: 0.6855 - accuracy: 0.5460\n",
      "\n",
      "Epoch 00012: loss improved from 0.68609 to 0.68551, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-12-0.6855.hdf5\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6862 - accuracy: 0.53 - ETA: 7s - loss: 0.6834 - accuracy: 0.55 - ETA: 7s - loss: 0.6840 - accuracy: 0.54 - ETA: 7s - loss: 0.6846 - accuracy: 0.54 - ETA: 8s - loss: 0.6832 - accuracy: 0.55 - ETA: 8s - loss: 0.6836 - accuracy: 0.55 - ETA: 7s - loss: 0.6838 - accuracy: 0.55 - ETA: 7s - loss: 0.6845 - accuracy: 0.54 - ETA: 7s - loss: 0.6851 - accuracy: 0.54 - ETA: 7s - loss: 0.6852 - accuracy: 0.55 - ETA: 7s - loss: 0.6851 - accuracy: 0.55 - ETA: 7s - loss: 0.6844 - accuracy: 0.55 - ETA: 7s - loss: 0.6844 - accuracy: 0.55 - ETA: 7s - loss: 0.6848 - accuracy: 0.55 - ETA: 7s - loss: 0.6846 - accuracy: 0.55 - ETA: 6s - loss: 0.6845 - accuracy: 0.55 - ETA: 6s - loss: 0.6849 - accuracy: 0.55 - ETA: 6s - loss: 0.6848 - accuracy: 0.55 - ETA: 6s - loss: 0.6844 - accuracy: 0.55 - ETA: 6s - loss: 0.6849 - accuracy: 0.55 - ETA: 6s - loss: 0.6848 - accuracy: 0.55 - ETA: 6s - loss: 0.6846 - accuracy: 0.55 - ETA: 6s - loss: 0.6844 - accuracy: 0.55 - ETA: 6s - loss: 0.6844 - accuracy: 0.55 - ETA: 5s - loss: 0.6848 - accuracy: 0.55 - ETA: 5s - loss: 0.6846 - accuracy: 0.55 - ETA: 5s - loss: 0.6845 - accuracy: 0.55 - ETA: 5s - loss: 0.6844 - accuracy: 0.55 - ETA: 5s - loss: 0.6846 - accuracy: 0.55 - ETA: 5s - loss: 0.6845 - accuracy: 0.55 - ETA: 5s - loss: 0.6845 - accuracy: 0.55 - ETA: 5s - loss: 0.6842 - accuracy: 0.55 - ETA: 5s - loss: 0.6843 - accuracy: 0.55 - ETA: 4s - loss: 0.6843 - accuracy: 0.55 - ETA: 4s - loss: 0.6843 - accuracy: 0.55 - ETA: 4s - loss: 0.6839 - accuracy: 0.55 - ETA: 4s - loss: 0.6837 - accuracy: 0.55 - ETA: 4s - loss: 0.6837 - accuracy: 0.55 - ETA: 4s - loss: 0.6840 - accuracy: 0.55 - ETA: 4s - loss: 0.6841 - accuracy: 0.55 - ETA: 4s - loss: 0.6842 - accuracy: 0.55 - ETA: 4s - loss: 0.6842 - accuracy: 0.55 - ETA: 3s - loss: 0.6840 - accuracy: 0.55 - ETA: 3s - loss: 0.6841 - accuracy: 0.55 - ETA: 3s - loss: 0.6841 - accuracy: 0.55 - ETA: 3s - loss: 0.6842 - accuracy: 0.55 - ETA: 3s - loss: 0.6842 - accuracy: 0.55 - ETA: 3s - loss: 0.6843 - accuracy: 0.55 - ETA: 3s - loss: 0.6842 - accuracy: 0.55 - ETA: 3s - loss: 0.6842 - accuracy: 0.55 - ETA: 3s - loss: 0.6842 - accuracy: 0.55 - ETA: 2s - loss: 0.6843 - accuracy: 0.55 - ETA: 2s - loss: 0.6841 - accuracy: 0.55 - ETA: 2s - loss: 0.6842 - accuracy: 0.55 - ETA: 2s - loss: 0.6845 - accuracy: 0.55 - ETA: 2s - loss: 0.6844 - accuracy: 0.55 - ETA: 2s - loss: 0.6845 - accuracy: 0.55 - ETA: 2s - loss: 0.6846 - accuracy: 0.55 - ETA: 2s - loss: 0.6846 - accuracy: 0.55 - ETA: 2s - loss: 0.6846 - accuracy: 0.55 - ETA: 1s - loss: 0.6847 - accuracy: 0.55 - ETA: 1s - loss: 0.6846 - accuracy: 0.55 - ETA: 1s - loss: 0.6845 - accuracy: 0.55 - ETA: 1s - loss: 0.6845 - accuracy: 0.55 - ETA: 1s - loss: 0.6845 - accuracy: 0.55 - ETA: 1s - loss: 0.6844 - accuracy: 0.55 - ETA: 1s - loss: 0.6845 - accuracy: 0.55 - ETA: 1s - loss: 0.6845 - accuracy: 0.55 - ETA: 1s - loss: 0.6845 - accuracy: 0.55 - ETA: 0s - loss: 0.6846 - accuracy: 0.55 - ETA: 0s - loss: 0.6847 - accuracy: 0.55 - ETA: 0s - loss: 0.6847 - accuracy: 0.55 - ETA: 0s - loss: 0.6848 - accuracy: 0.54 - ETA: 0s - loss: 0.6849 - accuracy: 0.54 - ETA: 0s - loss: 0.6850 - accuracy: 0.54 - ETA: 0s - loss: 0.6850 - accuracy: 0.55 - ETA: 0s - loss: 0.6850 - accuracy: 0.54 - ETA: 0s - loss: 0.6851 - accuracy: 0.54 - 9s 214us/step - loss: 0.6851 - accuracy: 0.5496\n",
      "\n",
      "Epoch 00013: loss improved from 0.68551 to 0.68510, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-13-0.6851.hdf5\n",
      "Epoch 14/50\n",
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6869 - accuracy: 0.53 - ETA: 7s - loss: 0.6861 - accuracy: 0.52 - ETA: 7s - loss: 0.6870 - accuracy: 0.53 - ETA: 7s - loss: 0.6863 - accuracy: 0.54 - ETA: 7s - loss: 0.6866 - accuracy: 0.54 - ETA: 7s - loss: 0.6862 - accuracy: 0.54 - ETA: 7s - loss: 0.6852 - accuracy: 0.54 - ETA: 7s - loss: 0.6851 - accuracy: 0.54 - ETA: 7s - loss: 0.6852 - accuracy: 0.54 - ETA: 7s - loss: 0.6848 - accuracy: 0.54 - ETA: 7s - loss: 0.6849 - accuracy: 0.54 - ETA: 7s - loss: 0.6844 - accuracy: 0.54 - ETA: 7s - loss: 0.6844 - accuracy: 0.54 - ETA: 6s - loss: 0.6847 - accuracy: 0.54 - ETA: 6s - loss: 0.6851 - accuracy: 0.54 - ETA: 6s - loss: 0.6852 - accuracy: 0.54 - ETA: 6s - loss: 0.6852 - accuracy: 0.54 - ETA: 6s - loss: 0.6853 - accuracy: 0.54 - ETA: 6s - loss: 0.6851 - accuracy: 0.54 - ETA: 6s - loss: 0.6852 - accuracy: 0.54 - ETA: 6s - loss: 0.6853 - accuracy: 0.54 - ETA: 6s - loss: 0.6851 - accuracy: 0.54 - ETA: 6s - loss: 0.6852 - accuracy: 0.54 - ETA: 5s - loss: 0.6850 - accuracy: 0.54 - ETA: 5s - loss: 0.6847 - accuracy: 0.54 - ETA: 5s - loss: 0.6849 - accuracy: 0.54 - ETA: 5s - loss: 0.6846 - accuracy: 0.54 - ETA: 5s - loss: 0.6847 - accuracy: 0.54 - ETA: 5s - loss: 0.6850 - accuracy: 0.54 - ETA: 5s - loss: 0.6850 - accuracy: 0.54 - ETA: 5s - loss: 0.6850 - accuracy: 0.54 - ETA: 5s - loss: 0.6850 - accuracy: 0.54 - ETA: 5s - loss: 0.6847 - accuracy: 0.54 - ETA: 4s - loss: 0.6849 - accuracy: 0.54 - ETA: 4s - loss: 0.6851 - accuracy: 0.54 - ETA: 4s - loss: 0.6851 - accuracy: 0.54 - ETA: 4s - loss: 0.6851 - accuracy: 0.54 - ETA: 4s - loss: 0.6853 - accuracy: 0.54 - ETA: 4s - loss: 0.6852 - accuracy: 0.54 - ETA: 4s - loss: 0.6852 - accuracy: 0.54 - ETA: 4s - loss: 0.6851 - accuracy: 0.54 - ETA: 4s - loss: 0.6850 - accuracy: 0.54 - ETA: 4s - loss: 0.6850 - accuracy: 0.54 - ETA: 3s - loss: 0.6849 - accuracy: 0.54 - ETA: 3s - loss: 0.6849 - accuracy: 0.54 - ETA: 3s - loss: 0.6849 - accuracy: 0.54 - ETA: 3s - loss: 0.6851 - accuracy: 0.54 - ETA: 3s - loss: 0.6850 - accuracy: 0.54 - ETA: 3s - loss: 0.6851 - accuracy: 0.54 - ETA: 3s - loss: 0.6851 - accuracy: 0.54 - ETA: 3s - loss: 0.6852 - accuracy: 0.54 - ETA: 3s - loss: 0.6851 - accuracy: 0.54 - ETA: 2s - loss: 0.6850 - accuracy: 0.54 - ETA: 2s - loss: 0.6850 - accuracy: 0.54 - ETA: 2s - loss: 0.6849 - accuracy: 0.54 - ETA: 2s - loss: 0.6848 - accuracy: 0.54 - ETA: 2s - loss: 0.6848 - accuracy: 0.54 - ETA: 2s - loss: 0.6848 - accuracy: 0.54 - ETA: 2s - loss: 0.6849 - accuracy: 0.54 - ETA: 2s - loss: 0.6849 - accuracy: 0.54 - ETA: 2s - loss: 0.6850 - accuracy: 0.54 - ETA: 1s - loss: 0.6849 - accuracy: 0.54 - ETA: 1s - loss: 0.6849 - accuracy: 0.54 - ETA: 1s - loss: 0.6849 - accuracy: 0.54 - ETA: 1s - loss: 0.6849 - accuracy: 0.54 - ETA: 1s - loss: 0.6850 - accuracy: 0.54 - ETA: 1s - loss: 0.6850 - accuracy: 0.54 - ETA: 1s - loss: 0.6850 - accuracy: 0.54 - ETA: 1s - loss: 0.6849 - accuracy: 0.54 - ETA: 0s - loss: 0.6850 - accuracy: 0.54 - ETA: 0s - loss: 0.6850 - accuracy: 0.54 - ETA: 0s - loss: 0.6849 - accuracy: 0.54 - ETA: 0s - loss: 0.6849 - accuracy: 0.54 - ETA: 0s - loss: 0.6848 - accuracy: 0.54 - ETA: 0s - loss: 0.6847 - accuracy: 0.54 - ETA: 0s - loss: 0.6847 - accuracy: 0.54 - ETA: 0s - loss: 0.6845 - accuracy: 0.54 - ETA: 0s - loss: 0.6847 - accuracy: 0.54 - 9s 224us/step - loss: 0.6847 - accuracy: 0.5490\n",
      "\n",
      "Epoch 00014: loss improved from 0.68510 to 0.68471, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-14-0.6847.hdf5\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6782 - accuracy: 0.55 - ETA: 8s - loss: 0.6837 - accuracy: 0.54 - ETA: 8s - loss: 0.6837 - accuracy: 0.54 - ETA: 8s - loss: 0.6833 - accuracy: 0.55 - ETA: 8s - loss: 0.6818 - accuracy: 0.55 - ETA: 8s - loss: 0.6812 - accuracy: 0.55 - ETA: 8s - loss: 0.6811 - accuracy: 0.55 - ETA: 7s - loss: 0.6812 - accuracy: 0.55 - ETA: 7s - loss: 0.6822 - accuracy: 0.55 - ETA: 7s - loss: 0.6816 - accuracy: 0.55 - ETA: 7s - loss: 0.6818 - accuracy: 0.55 - ETA: 7s - loss: 0.6822 - accuracy: 0.55 - ETA: 7s - loss: 0.6823 - accuracy: 0.55 - ETA: 7s - loss: 0.6825 - accuracy: 0.55 - ETA: 6s - loss: 0.6832 - accuracy: 0.55 - ETA: 6s - loss: 0.6831 - accuracy: 0.55 - ETA: 6s - loss: 0.6825 - accuracy: 0.55 - ETA: 6s - loss: 0.6821 - accuracy: 0.55 - ETA: 6s - loss: 0.6823 - accuracy: 0.55 - ETA: 6s - loss: 0.6825 - accuracy: 0.55 - ETA: 6s - loss: 0.6826 - accuracy: 0.55 - ETA: 6s - loss: 0.6826 - accuracy: 0.55 - ETA: 6s - loss: 0.6825 - accuracy: 0.55 - ETA: 5s - loss: 0.6828 - accuracy: 0.55 - ETA: 5s - loss: 0.6830 - accuracy: 0.55 - ETA: 5s - loss: 0.6827 - accuracy: 0.55 - ETA: 5s - loss: 0.6828 - accuracy: 0.55 - ETA: 5s - loss: 0.6827 - accuracy: 0.55 - ETA: 5s - loss: 0.6828 - accuracy: 0.55 - ETA: 5s - loss: 0.6829 - accuracy: 0.55 - ETA: 5s - loss: 0.6831 - accuracy: 0.55 - ETA: 5s - loss: 0.6833 - accuracy: 0.55 - ETA: 4s - loss: 0.6833 - accuracy: 0.55 - ETA: 4s - loss: 0.6836 - accuracy: 0.55 - ETA: 4s - loss: 0.6835 - accuracy: 0.55 - ETA: 4s - loss: 0.6836 - accuracy: 0.55 - ETA: 4s - loss: 0.6839 - accuracy: 0.55 - ETA: 4s - loss: 0.6839 - accuracy: 0.55 - ETA: 4s - loss: 0.6837 - accuracy: 0.55 - ETA: 4s - loss: 0.6838 - accuracy: 0.55 - ETA: 4s - loss: 0.6839 - accuracy: 0.55 - ETA: 3s - loss: 0.6840 - accuracy: 0.55 - ETA: 3s - loss: 0.6839 - accuracy: 0.55 - ETA: 3s - loss: 0.6840 - accuracy: 0.55 - ETA: 3s - loss: 0.6843 - accuracy: 0.55 - ETA: 3s - loss: 0.6842 - accuracy: 0.54 - ETA: 3s - loss: 0.6842 - accuracy: 0.55 - ETA: 3s - loss: 0.6844 - accuracy: 0.54 - ETA: 3s - loss: 0.6843 - accuracy: 0.55 - ETA: 3s - loss: 0.6843 - accuracy: 0.54 - ETA: 3s - loss: 0.6843 - accuracy: 0.54 - ETA: 2s - loss: 0.6843 - accuracy: 0.54 - ETA: 2s - loss: 0.6845 - accuracy: 0.54 - ETA: 2s - loss: 0.6846 - accuracy: 0.54 - ETA: 2s - loss: 0.6847 - accuracy: 0.54 - ETA: 2s - loss: 0.6845 - accuracy: 0.54 - ETA: 2s - loss: 0.6844 - accuracy: 0.54 - ETA: 2s - loss: 0.6843 - accuracy: 0.54 - ETA: 2s - loss: 0.6843 - accuracy: 0.54 - ETA: 2s - loss: 0.6843 - accuracy: 0.54 - ETA: 1s - loss: 0.6843 - accuracy: 0.54 - ETA: 1s - loss: 0.6843 - accuracy: 0.54 - ETA: 1s - loss: 0.6842 - accuracy: 0.54 - ETA: 1s - loss: 0.6842 - accuracy: 0.54 - ETA: 1s - loss: 0.6841 - accuracy: 0.54 - ETA: 1s - loss: 0.6840 - accuracy: 0.55 - ETA: 1s - loss: 0.6840 - accuracy: 0.55 - ETA: 1s - loss: 0.6840 - accuracy: 0.54 - ETA: 1s - loss: 0.6840 - accuracy: 0.55 - ETA: 0s - loss: 0.6840 - accuracy: 0.55 - ETA: 0s - loss: 0.6840 - accuracy: 0.55 - ETA: 0s - loss: 0.6841 - accuracy: 0.55 - ETA: 0s - loss: 0.6841 - accuracy: 0.55 - ETA: 0s - loss: 0.6841 - accuracy: 0.55 - ETA: 0s - loss: 0.6841 - accuracy: 0.55 - ETA: 0s - loss: 0.6841 - accuracy: 0.55 - ETA: 0s - loss: 0.6841 - accuracy: 0.55 - ETA: 0s - loss: 0.6839 - accuracy: 0.55 - 9s 212us/step - loss: 0.6839 - accuracy: 0.5509\n",
      "\n",
      "Epoch 00015: loss improved from 0.68471 to 0.68390, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-15-0.6839.hdf5\n",
      "Epoch 16/50\n",
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6796 - accuracy: 0.58 - ETA: 7s - loss: 0.6801 - accuracy: 0.57 - ETA: 7s - loss: 0.6826 - accuracy: 0.56 - ETA: 7s - loss: 0.6827 - accuracy: 0.55 - ETA: 7s - loss: 0.6827 - accuracy: 0.54 - ETA: 7s - loss: 0.6815 - accuracy: 0.55 - ETA: 7s - loss: 0.6812 - accuracy: 0.55 - ETA: 7s - loss: 0.6804 - accuracy: 0.55 - ETA: 7s - loss: 0.6799 - accuracy: 0.56 - ETA: 7s - loss: 0.6801 - accuracy: 0.56 - ETA: 7s - loss: 0.6801 - accuracy: 0.55 - ETA: 7s - loss: 0.6799 - accuracy: 0.56 - ETA: 7s - loss: 0.6804 - accuracy: 0.55 - ETA: 6s - loss: 0.6806 - accuracy: 0.55 - ETA: 6s - loss: 0.6808 - accuracy: 0.55 - ETA: 6s - loss: 0.6815 - accuracy: 0.55 - ETA: 6s - loss: 0.6818 - accuracy: 0.55 - ETA: 6s - loss: 0.6817 - accuracy: 0.55 - ETA: 6s - loss: 0.6814 - accuracy: 0.55 - ETA: 6s - loss: 0.6820 - accuracy: 0.55 - ETA: 6s - loss: 0.6824 - accuracy: 0.55 - ETA: 6s - loss: 0.6825 - accuracy: 0.55 - ETA: 6s - loss: 0.6824 - accuracy: 0.55 - ETA: 5s - loss: 0.6826 - accuracy: 0.55 - ETA: 5s - loss: 0.6829 - accuracy: 0.55 - ETA: 5s - loss: 0.6829 - accuracy: 0.55 - ETA: 5s - loss: 0.6831 - accuracy: 0.55 - ETA: 5s - loss: 0.6833 - accuracy: 0.55 - ETA: 5s - loss: 0.6831 - accuracy: 0.55 - ETA: 5s - loss: 0.6833 - accuracy: 0.55 - ETA: 5s - loss: 0.6833 - accuracy: 0.55 - ETA: 5s - loss: 0.6834 - accuracy: 0.55 - ETA: 4s - loss: 0.6832 - accuracy: 0.55 - ETA: 4s - loss: 0.6829 - accuracy: 0.55 - ETA: 4s - loss: 0.6831 - accuracy: 0.55 - ETA: 4s - loss: 0.6831 - accuracy: 0.55 - ETA: 4s - loss: 0.6830 - accuracy: 0.55 - ETA: 4s - loss: 0.6830 - accuracy: 0.55 - ETA: 4s - loss: 0.6829 - accuracy: 0.55 - ETA: 4s - loss: 0.6828 - accuracy: 0.55 - ETA: 4s - loss: 0.6827 - accuracy: 0.55 - ETA: 3s - loss: 0.6826 - accuracy: 0.55 - ETA: 3s - loss: 0.6828 - accuracy: 0.55 - ETA: 3s - loss: 0.6829 - accuracy: 0.55 - ETA: 3s - loss: 0.6829 - accuracy: 0.55 - ETA: 3s - loss: 0.6830 - accuracy: 0.55 - ETA: 3s - loss: 0.6831 - accuracy: 0.55 - ETA: 3s - loss: 0.6831 - accuracy: 0.55 - ETA: 3s - loss: 0.6833 - accuracy: 0.55 - ETA: 3s - loss: 0.6831 - accuracy: 0.55 - ETA: 3s - loss: 0.6833 - accuracy: 0.55 - ETA: 2s - loss: 0.6832 - accuracy: 0.55 - ETA: 2s - loss: 0.6831 - accuracy: 0.55 - ETA: 2s - loss: 0.6831 - accuracy: 0.55 - ETA: 2s - loss: 0.6830 - accuracy: 0.55 - ETA: 2s - loss: 0.6830 - accuracy: 0.55 - ETA: 2s - loss: 0.6830 - accuracy: 0.55 - ETA: 2s - loss: 0.6831 - accuracy: 0.55 - ETA: 2s - loss: 0.6831 - accuracy: 0.55 - ETA: 2s - loss: 0.6832 - accuracy: 0.55 - ETA: 1s - loss: 0.6834 - accuracy: 0.55 - ETA: 1s - loss: 0.6834 - accuracy: 0.55 - ETA: 1s - loss: 0.6836 - accuracy: 0.55 - ETA: 1s - loss: 0.6837 - accuracy: 0.55 - ETA: 1s - loss: 0.6836 - accuracy: 0.55 - ETA: 1s - loss: 0.6837 - accuracy: 0.55 - ETA: 1s - loss: 0.6836 - accuracy: 0.55 - ETA: 1s - loss: 0.6836 - accuracy: 0.55 - ETA: 1s - loss: 0.6837 - accuracy: 0.55 - ETA: 0s - loss: 0.6837 - accuracy: 0.55 - ETA: 0s - loss: 0.6835 - accuracy: 0.55 - ETA: 0s - loss: 0.6835 - accuracy: 0.55 - ETA: 0s - loss: 0.6836 - accuracy: 0.55 - ETA: 0s - loss: 0.6836 - accuracy: 0.55 - ETA: 0s - loss: 0.6835 - accuracy: 0.55 - ETA: 0s - loss: 0.6835 - accuracy: 0.55 - ETA: 0s - loss: 0.6835 - accuracy: 0.55 - ETA: 0s - loss: 0.6836 - accuracy: 0.55 - 9s 214us/step - loss: 0.6836 - accuracy: 0.5524\n",
      "\n",
      "Epoch 00016: loss improved from 0.68390 to 0.68364, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-16-0.6836.hdf5\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6810 - accuracy: 0.55 - ETA: 8s - loss: 0.6826 - accuracy: 0.54 - ETA: 8s - loss: 0.6841 - accuracy: 0.54 - ETA: 8s - loss: 0.6843 - accuracy: 0.55 - ETA: 7s - loss: 0.6843 - accuracy: 0.55 - ETA: 7s - loss: 0.6846 - accuracy: 0.55 - ETA: 7s - loss: 0.6836 - accuracy: 0.55 - ETA: 7s - loss: 0.6840 - accuracy: 0.55 - ETA: 7s - loss: 0.6835 - accuracy: 0.55 - ETA: 7s - loss: 0.6833 - accuracy: 0.55 - ETA: 7s - loss: 0.6830 - accuracy: 0.55 - ETA: 7s - loss: 0.6835 - accuracy: 0.55 - ETA: 7s - loss: 0.6838 - accuracy: 0.55 - ETA: 7s - loss: 0.6840 - accuracy: 0.55 - ETA: 6s - loss: 0.6833 - accuracy: 0.55 - ETA: 6s - loss: 0.6827 - accuracy: 0.56 - ETA: 6s - loss: 0.6827 - accuracy: 0.55 - ETA: 6s - loss: 0.6830 - accuracy: 0.55 - ETA: 6s - loss: 0.6830 - accuracy: 0.55 - ETA: 6s - loss: 0.6835 - accuracy: 0.55 - ETA: 6s - loss: 0.6835 - accuracy: 0.55 - ETA: 6s - loss: 0.6830 - accuracy: 0.55 - ETA: 6s - loss: 0.6834 - accuracy: 0.55 - ETA: 5s - loss: 0.6830 - accuracy: 0.55 - ETA: 5s - loss: 0.6831 - accuracy: 0.55 - ETA: 5s - loss: 0.6829 - accuracy: 0.55 - ETA: 5s - loss: 0.6828 - accuracy: 0.55 - ETA: 5s - loss: 0.6827 - accuracy: 0.55 - ETA: 5s - loss: 0.6825 - accuracy: 0.55 - ETA: 5s - loss: 0.6826 - accuracy: 0.55 - ETA: 5s - loss: 0.6827 - accuracy: 0.55 - ETA: 5s - loss: 0.6826 - accuracy: 0.55 - ETA: 4s - loss: 0.6824 - accuracy: 0.55 - ETA: 4s - loss: 0.6823 - accuracy: 0.55 - ETA: 4s - loss: 0.6823 - accuracy: 0.55 - ETA: 4s - loss: 0.6823 - accuracy: 0.55 - ETA: 4s - loss: 0.6825 - accuracy: 0.55 - ETA: 4s - loss: 0.6822 - accuracy: 0.55 - ETA: 4s - loss: 0.6823 - accuracy: 0.55 - ETA: 4s - loss: 0.6822 - accuracy: 0.55 - ETA: 4s - loss: 0.6822 - accuracy: 0.55 - ETA: 3s - loss: 0.6824 - accuracy: 0.55 - ETA: 3s - loss: 0.6823 - accuracy: 0.55 - ETA: 3s - loss: 0.6821 - accuracy: 0.55 - ETA: 3s - loss: 0.6821 - accuracy: 0.55 - ETA: 3s - loss: 0.6820 - accuracy: 0.55 - ETA: 3s - loss: 0.6820 - accuracy: 0.55 - ETA: 3s - loss: 0.6819 - accuracy: 0.55 - ETA: 3s - loss: 0.6820 - accuracy: 0.55 - ETA: 3s - loss: 0.6821 - accuracy: 0.55 - ETA: 3s - loss: 0.6820 - accuracy: 0.55 - ETA: 2s - loss: 0.6821 - accuracy: 0.55 - ETA: 2s - loss: 0.6819 - accuracy: 0.55 - ETA: 2s - loss: 0.6819 - accuracy: 0.55 - ETA: 2s - loss: 0.6820 - accuracy: 0.55 - ETA: 2s - loss: 0.6819 - accuracy: 0.55 - ETA: 2s - loss: 0.6819 - accuracy: 0.55 - ETA: 2s - loss: 0.6819 - accuracy: 0.55 - ETA: 2s - loss: 0.6819 - accuracy: 0.55 - ETA: 2s - loss: 0.6819 - accuracy: 0.55 - ETA: 1s - loss: 0.6821 - accuracy: 0.55 - ETA: 1s - loss: 0.6821 - accuracy: 0.55 - ETA: 1s - loss: 0.6822 - accuracy: 0.55 - ETA: 1s - loss: 0.6822 - accuracy: 0.55 - ETA: 1s - loss: 0.6821 - accuracy: 0.55 - ETA: 1s - loss: 0.6820 - accuracy: 0.55 - ETA: 1s - loss: 0.6821 - accuracy: 0.55 - ETA: 1s - loss: 0.6822 - accuracy: 0.55 - ETA: 1s - loss: 0.6822 - accuracy: 0.55 - ETA: 0s - loss: 0.6823 - accuracy: 0.55 - ETA: 0s - loss: 0.6824 - accuracy: 0.55 - ETA: 0s - loss: 0.6825 - accuracy: 0.55 - ETA: 0s - loss: 0.6826 - accuracy: 0.55 - ETA: 0s - loss: 0.6826 - accuracy: 0.55 - ETA: 0s - loss: 0.6826 - accuracy: 0.55 - ETA: 0s - loss: 0.6825 - accuracy: 0.55 - ETA: 0s - loss: 0.6826 - accuracy: 0.55 - ETA: 0s - loss: 0.6826 - accuracy: 0.55 - 9s 223us/step - loss: 0.6827 - accuracy: 0.5557\n",
      "\n",
      "Epoch 00017: loss improved from 0.68364 to 0.68267, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-17-0.6827.hdf5\n",
      "Epoch 18/50\n",
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6768 - accuracy: 0.58 - ETA: 8s - loss: 0.6807 - accuracy: 0.56 - ETA: 8s - loss: 0.6776 - accuracy: 0.58 - ETA: 8s - loss: 0.6796 - accuracy: 0.56 - ETA: 8s - loss: 0.6767 - accuracy: 0.56 - ETA: 8s - loss: 0.6781 - accuracy: 0.56 - ETA: 8s - loss: 0.6780 - accuracy: 0.56 - ETA: 8s - loss: 0.6790 - accuracy: 0.56 - ETA: 8s - loss: 0.6789 - accuracy: 0.56 - ETA: 7s - loss: 0.6805 - accuracy: 0.56 - ETA: 7s - loss: 0.6807 - accuracy: 0.55 - ETA: 7s - loss: 0.6812 - accuracy: 0.55 - ETA: 7s - loss: 0.6814 - accuracy: 0.55 - ETA: 7s - loss: 0.6811 - accuracy: 0.56 - ETA: 7s - loss: 0.6811 - accuracy: 0.55 - ETA: 7s - loss: 0.6816 - accuracy: 0.55 - ETA: 7s - loss: 0.6819 - accuracy: 0.55 - ETA: 7s - loss: 0.6819 - accuracy: 0.55 - ETA: 6s - loss: 0.6821 - accuracy: 0.55 - ETA: 6s - loss: 0.6819 - accuracy: 0.55 - ETA: 6s - loss: 0.6820 - accuracy: 0.55 - ETA: 6s - loss: 0.6821 - accuracy: 0.55 - ETA: 6s - loss: 0.6818 - accuracy: 0.55 - ETA: 6s - loss: 0.6819 - accuracy: 0.55 - ETA: 6s - loss: 0.6818 - accuracy: 0.55 - ETA: 6s - loss: 0.6817 - accuracy: 0.55 - ETA: 6s - loss: 0.6812 - accuracy: 0.56 - ETA: 5s - loss: 0.6814 - accuracy: 0.55 - ETA: 5s - loss: 0.6816 - accuracy: 0.55 - ETA: 5s - loss: 0.6821 - accuracy: 0.55 - ETA: 5s - loss: 0.6821 - accuracy: 0.55 - ETA: 5s - loss: 0.6822 - accuracy: 0.55 - ETA: 5s - loss: 0.6819 - accuracy: 0.55 - ETA: 5s - loss: 0.6820 - accuracy: 0.55 - ETA: 5s - loss: 0.6816 - accuracy: 0.55 - ETA: 4s - loss: 0.6818 - accuracy: 0.55 - ETA: 4s - loss: 0.6820 - accuracy: 0.55 - ETA: 4s - loss: 0.6821 - accuracy: 0.55 - ETA: 4s - loss: 0.6821 - accuracy: 0.55 - ETA: 4s - loss: 0.6821 - accuracy: 0.55 - ETA: 4s - loss: 0.6821 - accuracy: 0.55 - ETA: 4s - loss: 0.6821 - accuracy: 0.55 - ETA: 4s - loss: 0.6821 - accuracy: 0.55 - ETA: 3s - loss: 0.6822 - accuracy: 0.55 - ETA: 3s - loss: 0.6822 - accuracy: 0.55 - ETA: 3s - loss: 0.6820 - accuracy: 0.55 - ETA: 3s - loss: 0.6817 - accuracy: 0.55 - ETA: 3s - loss: 0.6815 - accuracy: 0.55 - ETA: 3s - loss: 0.6818 - accuracy: 0.55 - ETA: 3s - loss: 0.6818 - accuracy: 0.55 - ETA: 3s - loss: 0.6818 - accuracy: 0.55 - ETA: 3s - loss: 0.6821 - accuracy: 0.55 - ETA: 2s - loss: 0.6819 - accuracy: 0.55 - ETA: 2s - loss: 0.6818 - accuracy: 0.55 - ETA: 2s - loss: 0.6817 - accuracy: 0.55 - ETA: 2s - loss: 0.6818 - accuracy: 0.55 - ETA: 2s - loss: 0.6817 - accuracy: 0.55 - ETA: 2s - loss: 0.6819 - accuracy: 0.55 - ETA: 2s - loss: 0.6819 - accuracy: 0.55 - ETA: 2s - loss: 0.6820 - accuracy: 0.55 - ETA: 2s - loss: 0.6819 - accuracy: 0.55 - ETA: 1s - loss: 0.6820 - accuracy: 0.55 - ETA: 1s - loss: 0.6820 - accuracy: 0.55 - ETA: 1s - loss: 0.6819 - accuracy: 0.55 - ETA: 1s - loss: 0.6820 - accuracy: 0.55 - ETA: 1s - loss: 0.6820 - accuracy: 0.55 - ETA: 1s - loss: 0.6820 - accuracy: 0.55 - ETA: 1s - loss: 0.6819 - accuracy: 0.55 - ETA: 1s - loss: 0.6820 - accuracy: 0.55 - ETA: 0s - loss: 0.6821 - accuracy: 0.55 - ETA: 0s - loss: 0.6823 - accuracy: 0.55 - ETA: 0s - loss: 0.6823 - accuracy: 0.55 - ETA: 0s - loss: 0.6823 - accuracy: 0.55 - ETA: 0s - loss: 0.6824 - accuracy: 0.55 - ETA: 0s - loss: 0.6823 - accuracy: 0.55 - ETA: 0s - loss: 0.6823 - accuracy: 0.55 - ETA: 0s - loss: 0.6822 - accuracy: 0.55 - ETA: 0s - loss: 0.6822 - accuracy: 0.55 - 9s 221us/step - loss: 0.6823 - accuracy: 0.5560\n",
      "\n",
      "Epoch 00018: loss improved from 0.68267 to 0.68229, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-18-0.6823.hdf5\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6783 - accuracy: 0.58 - ETA: 7s - loss: 0.6799 - accuracy: 0.58 - ETA: 7s - loss: 0.6808 - accuracy: 0.57 - ETA: 7s - loss: 0.6813 - accuracy: 0.56 - ETA: 7s - loss: 0.6815 - accuracy: 0.56 - ETA: 7s - loss: 0.6814 - accuracy: 0.55 - ETA: 7s - loss: 0.6815 - accuracy: 0.56 - ETA: 7s - loss: 0.6829 - accuracy: 0.55 - ETA: 7s - loss: 0.6823 - accuracy: 0.55 - ETA: 7s - loss: 0.6817 - accuracy: 0.56 - ETA: 7s - loss: 0.6816 - accuracy: 0.56 - ETA: 7s - loss: 0.6814 - accuracy: 0.56 - ETA: 7s - loss: 0.6814 - accuracy: 0.56 - ETA: 6s - loss: 0.6804 - accuracy: 0.56 - ETA: 6s - loss: 0.6806 - accuracy: 0.56 - ETA: 6s - loss: 0.6799 - accuracy: 0.56 - ETA: 6s - loss: 0.6796 - accuracy: 0.56 - ETA: 6s - loss: 0.6795 - accuracy: 0.56 - ETA: 6s - loss: 0.6799 - accuracy: 0.56 - ETA: 6s - loss: 0.6798 - accuracy: 0.56 - ETA: 6s - loss: 0.6794 - accuracy: 0.56 - ETA: 6s - loss: 0.6797 - accuracy: 0.56 - ETA: 6s - loss: 0.6795 - accuracy: 0.56 - ETA: 5s - loss: 0.6796 - accuracy: 0.56 - ETA: 5s - loss: 0.6792 - accuracy: 0.56 - ETA: 5s - loss: 0.6792 - accuracy: 0.56 - ETA: 5s - loss: 0.6794 - accuracy: 0.56 - ETA: 5s - loss: 0.6795 - accuracy: 0.56 - ETA: 5s - loss: 0.6796 - accuracy: 0.56 - ETA: 5s - loss: 0.6795 - accuracy: 0.56 - ETA: 5s - loss: 0.6795 - accuracy: 0.56 - ETA: 5s - loss: 0.6798 - accuracy: 0.56 - ETA: 4s - loss: 0.6796 - accuracy: 0.56 - ETA: 4s - loss: 0.6796 - accuracy: 0.56 - ETA: 4s - loss: 0.6800 - accuracy: 0.55 - ETA: 4s - loss: 0.6800 - accuracy: 0.55 - ETA: 4s - loss: 0.6802 - accuracy: 0.55 - ETA: 4s - loss: 0.6801 - accuracy: 0.55 - ETA: 4s - loss: 0.6803 - accuracy: 0.55 - ETA: 4s - loss: 0.6804 - accuracy: 0.55 - ETA: 4s - loss: 0.6803 - accuracy: 0.56 - ETA: 3s - loss: 0.6805 - accuracy: 0.55 - ETA: 3s - loss: 0.6805 - accuracy: 0.55 - ETA: 3s - loss: 0.6805 - accuracy: 0.55 - ETA: 3s - loss: 0.6805 - accuracy: 0.55 - ETA: 3s - loss: 0.6805 - accuracy: 0.55 - ETA: 3s - loss: 0.6804 - accuracy: 0.55 - ETA: 3s - loss: 0.6804 - accuracy: 0.55 - ETA: 3s - loss: 0.6807 - accuracy: 0.55 - ETA: 3s - loss: 0.6809 - accuracy: 0.55 - ETA: 2s - loss: 0.6807 - accuracy: 0.55 - ETA: 2s - loss: 0.6805 - accuracy: 0.55 - ETA: 2s - loss: 0.6804 - accuracy: 0.55 - ETA: 2s - loss: 0.6803 - accuracy: 0.55 - ETA: 2s - loss: 0.6804 - accuracy: 0.55 - ETA: 2s - loss: 0.6804 - accuracy: 0.55 - ETA: 2s - loss: 0.6804 - accuracy: 0.55 - ETA: 2s - loss: 0.6806 - accuracy: 0.55 - ETA: 2s - loss: 0.6805 - accuracy: 0.55 - ETA: 2s - loss: 0.6804 - accuracy: 0.56 - ETA: 1s - loss: 0.6804 - accuracy: 0.56 - ETA: 1s - loss: 0.6805 - accuracy: 0.56 - ETA: 1s - loss: 0.6806 - accuracy: 0.56 - ETA: 1s - loss: 0.6806 - accuracy: 0.56 - ETA: 1s - loss: 0.6806 - accuracy: 0.56 - ETA: 1s - loss: 0.6806 - accuracy: 0.56 - ETA: 1s - loss: 0.6805 - accuracy: 0.56 - ETA: 1s - loss: 0.6805 - accuracy: 0.56 - ETA: 1s - loss: 0.6806 - accuracy: 0.56 - ETA: 0s - loss: 0.6807 - accuracy: 0.56 - ETA: 0s - loss: 0.6808 - accuracy: 0.56 - ETA: 0s - loss: 0.6807 - accuracy: 0.56 - ETA: 0s - loss: 0.6808 - accuracy: 0.55 - ETA: 0s - loss: 0.6808 - accuracy: 0.55 - ETA: 0s - loss: 0.6808 - accuracy: 0.55 - ETA: 0s - loss: 0.6810 - accuracy: 0.55 - ETA: 0s - loss: 0.6809 - accuracy: 0.55 - ETA: 0s - loss: 0.6809 - accuracy: 0.55 - 9s 212us/step - loss: 0.6808 - accuracy: 0.5593\n",
      "\n",
      "Epoch 00019: loss improved from 0.68229 to 0.68082, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-19-0.6808.hdf5\n",
      "Epoch 20/50\n",
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6834 - accuracy: 0.55 - ETA: 7s - loss: 0.6806 - accuracy: 0.54 - ETA: 7s - loss: 0.6808 - accuracy: 0.55 - ETA: 7s - loss: 0.6795 - accuracy: 0.56 - ETA: 7s - loss: 0.6802 - accuracy: 0.56 - ETA: 7s - loss: 0.6796 - accuracy: 0.56 - ETA: 7s - loss: 0.6793 - accuracy: 0.56 - ETA: 7s - loss: 0.6800 - accuracy: 0.55 - ETA: 7s - loss: 0.6800 - accuracy: 0.55 - ETA: 7s - loss: 0.6798 - accuracy: 0.55 - ETA: 7s - loss: 0.6797 - accuracy: 0.56 - ETA: 7s - loss: 0.6798 - accuracy: 0.55 - ETA: 7s - loss: 0.6805 - accuracy: 0.55 - ETA: 6s - loss: 0.6804 - accuracy: 0.55 - ETA: 6s - loss: 0.6805 - accuracy: 0.56 - ETA: 6s - loss: 0.6802 - accuracy: 0.56 - ETA: 6s - loss: 0.6804 - accuracy: 0.56 - ETA: 6s - loss: 0.6797 - accuracy: 0.56 - ETA: 6s - loss: 0.6800 - accuracy: 0.56 - ETA: 6s - loss: 0.6799 - accuracy: 0.56 - ETA: 6s - loss: 0.6797 - accuracy: 0.56 - ETA: 6s - loss: 0.6800 - accuracy: 0.56 - ETA: 5s - loss: 0.6800 - accuracy: 0.56 - ETA: 5s - loss: 0.6799 - accuracy: 0.56 - ETA: 5s - loss: 0.6804 - accuracy: 0.56 - ETA: 5s - loss: 0.6803 - accuracy: 0.56 - ETA: 5s - loss: 0.6803 - accuracy: 0.56 - ETA: 5s - loss: 0.6803 - accuracy: 0.56 - ETA: 5s - loss: 0.6803 - accuracy: 0.56 - ETA: 5s - loss: 0.6803 - accuracy: 0.56 - ETA: 5s - loss: 0.6800 - accuracy: 0.56 - ETA: 5s - loss: 0.6798 - accuracy: 0.56 - ETA: 4s - loss: 0.6798 - accuracy: 0.56 - ETA: 4s - loss: 0.6795 - accuracy: 0.56 - ETA: 4s - loss: 0.6798 - accuracy: 0.56 - ETA: 4s - loss: 0.6797 - accuracy: 0.56 - ETA: 4s - loss: 0.6798 - accuracy: 0.56 - ETA: 4s - loss: 0.6799 - accuracy: 0.56 - ETA: 4s - loss: 0.6801 - accuracy: 0.56 - ETA: 4s - loss: 0.6802 - accuracy: 0.56 - ETA: 4s - loss: 0.6800 - accuracy: 0.56 - ETA: 3s - loss: 0.6799 - accuracy: 0.56 - ETA: 3s - loss: 0.6801 - accuracy: 0.56 - ETA: 3s - loss: 0.6805 - accuracy: 0.56 - ETA: 3s - loss: 0.6804 - accuracy: 0.56 - ETA: 3s - loss: 0.6805 - accuracy: 0.56 - ETA: 3s - loss: 0.6804 - accuracy: 0.56 - ETA: 3s - loss: 0.6804 - accuracy: 0.56 - ETA: 3s - loss: 0.6806 - accuracy: 0.56 - ETA: 3s - loss: 0.6803 - accuracy: 0.56 - ETA: 2s - loss: 0.6801 - accuracy: 0.56 - ETA: 2s - loss: 0.6799 - accuracy: 0.56 - ETA: 2s - loss: 0.6800 - accuracy: 0.56 - ETA: 2s - loss: 0.6800 - accuracy: 0.56 - ETA: 2s - loss: 0.6798 - accuracy: 0.56 - ETA: 2s - loss: 0.6796 - accuracy: 0.56 - ETA: 2s - loss: 0.6799 - accuracy: 0.56 - ETA: 2s - loss: 0.6798 - accuracy: 0.56 - ETA: 2s - loss: 0.6797 - accuracy: 0.56 - ETA: 2s - loss: 0.6797 - accuracy: 0.56 - ETA: 1s - loss: 0.6796 - accuracy: 0.56 - ETA: 1s - loss: 0.6796 - accuracy: 0.56 - ETA: 1s - loss: 0.6796 - accuracy: 0.56 - ETA: 1s - loss: 0.6796 - accuracy: 0.56 - ETA: 1s - loss: 0.6798 - accuracy: 0.56 - ETA: 1s - loss: 0.6797 - accuracy: 0.56 - ETA: 1s - loss: 0.6798 - accuracy: 0.56 - ETA: 1s - loss: 0.6799 - accuracy: 0.56 - ETA: 1s - loss: 0.6801 - accuracy: 0.56 - ETA: 0s - loss: 0.6801 - accuracy: 0.56 - ETA: 0s - loss: 0.6801 - accuracy: 0.56 - ETA: 0s - loss: 0.6800 - accuracy: 0.56 - ETA: 0s - loss: 0.6801 - accuracy: 0.56 - ETA: 0s - loss: 0.6799 - accuracy: 0.56 - ETA: 0s - loss: 0.6799 - accuracy: 0.56 - ETA: 0s - loss: 0.6797 - accuracy: 0.56 - ETA: 0s - loss: 0.6798 - accuracy: 0.56 - ETA: 0s - loss: 0.6798 - accuracy: 0.56 - 9s 212us/step - loss: 0.6797 - accuracy: 0.5626\n",
      "\n",
      "Epoch 00020: loss improved from 0.68082 to 0.67973, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-20-0.6797.hdf5\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6626 - accuracy: 0.60 - ETA: 8s - loss: 0.6705 - accuracy: 0.58 - ETA: 8s - loss: 0.6720 - accuracy: 0.57 - ETA: 8s - loss: 0.6732 - accuracy: 0.56 - ETA: 7s - loss: 0.6761 - accuracy: 0.56 - ETA: 7s - loss: 0.6755 - accuracy: 0.57 - ETA: 7s - loss: 0.6771 - accuracy: 0.56 - ETA: 7s - loss: 0.6769 - accuracy: 0.56 - ETA: 7s - loss: 0.6749 - accuracy: 0.57 - ETA: 7s - loss: 0.6746 - accuracy: 0.57 - ETA: 7s - loss: 0.6748 - accuracy: 0.57 - ETA: 7s - loss: 0.6753 - accuracy: 0.57 - ETA: 7s - loss: 0.6756 - accuracy: 0.57 - ETA: 7s - loss: 0.6755 - accuracy: 0.57 - ETA: 7s - loss: 0.6757 - accuracy: 0.57 - ETA: 7s - loss: 0.6754 - accuracy: 0.57 - ETA: 7s - loss: 0.6755 - accuracy: 0.57 - ETA: 7s - loss: 0.6752 - accuracy: 0.57 - ETA: 6s - loss: 0.6747 - accuracy: 0.57 - ETA: 6s - loss: 0.6749 - accuracy: 0.57 - ETA: 6s - loss: 0.6756 - accuracy: 0.57 - ETA: 6s - loss: 0.6759 - accuracy: 0.56 - ETA: 6s - loss: 0.6763 - accuracy: 0.56 - ETA: 6s - loss: 0.6764 - accuracy: 0.56 - ETA: 6s - loss: 0.6768 - accuracy: 0.56 - ETA: 6s - loss: 0.6775 - accuracy: 0.56 - ETA: 6s - loss: 0.6776 - accuracy: 0.56 - ETA: 6s - loss: 0.6775 - accuracy: 0.56 - ETA: 6s - loss: 0.6777 - accuracy: 0.56 - ETA: 6s - loss: 0.6778 - accuracy: 0.56 - ETA: 6s - loss: 0.6780 - accuracy: 0.56 - ETA: 5s - loss: 0.6784 - accuracy: 0.56 - ETA: 5s - loss: 0.6781 - accuracy: 0.56 - ETA: 5s - loss: 0.6784 - accuracy: 0.56 - ETA: 5s - loss: 0.6786 - accuracy: 0.56 - ETA: 5s - loss: 0.6783 - accuracy: 0.56 - ETA: 5s - loss: 0.6783 - accuracy: 0.56 - ETA: 5s - loss: 0.6782 - accuracy: 0.56 - ETA: 5s - loss: 0.6780 - accuracy: 0.56 - ETA: 5s - loss: 0.6782 - accuracy: 0.56 - ETA: 4s - loss: 0.6780 - accuracy: 0.56 - ETA: 4s - loss: 0.6781 - accuracy: 0.56 - ETA: 4s - loss: 0.6779 - accuracy: 0.56 - ETA: 4s - loss: 0.6780 - accuracy: 0.56 - ETA: 4s - loss: 0.6782 - accuracy: 0.56 - ETA: 4s - loss: 0.6782 - accuracy: 0.56 - ETA: 4s - loss: 0.6780 - accuracy: 0.56 - ETA: 4s - loss: 0.6781 - accuracy: 0.56 - ETA: 3s - loss: 0.6781 - accuracy: 0.56 - ETA: 3s - loss: 0.6780 - accuracy: 0.56 - ETA: 3s - loss: 0.6781 - accuracy: 0.56 - ETA: 3s - loss: 0.6781 - accuracy: 0.56 - ETA: 3s - loss: 0.6780 - accuracy: 0.56 - ETA: 3s - loss: 0.6781 - accuracy: 0.56 - ETA: 3s - loss: 0.6783 - accuracy: 0.56 - ETA: 3s - loss: 0.6781 - accuracy: 0.56 - ETA: 2s - loss: 0.6780 - accuracy: 0.56 - ETA: 2s - loss: 0.6779 - accuracy: 0.56 - ETA: 2s - loss: 0.6779 - accuracy: 0.56 - ETA: 2s - loss: 0.6783 - accuracy: 0.56 - ETA: 2s - loss: 0.6784 - accuracy: 0.56 - ETA: 2s - loss: 0.6786 - accuracy: 0.56 - ETA: 2s - loss: 0.6786 - accuracy: 0.56 - ETA: 1s - loss: 0.6786 - accuracy: 0.56 - ETA: 1s - loss: 0.6786 - accuracy: 0.56 - ETA: 1s - loss: 0.6785 - accuracy: 0.56 - ETA: 1s - loss: 0.6784 - accuracy: 0.56 - ETA: 1s - loss: 0.6783 - accuracy: 0.56 - ETA: 1s - loss: 0.6783 - accuracy: 0.56 - ETA: 1s - loss: 0.6784 - accuracy: 0.56 - ETA: 1s - loss: 0.6783 - accuracy: 0.56 - ETA: 0s - loss: 0.6782 - accuracy: 0.56 - ETA: 0s - loss: 0.6782 - accuracy: 0.56 - ETA: 0s - loss: 0.6781 - accuracy: 0.56 - ETA: 0s - loss: 0.6782 - accuracy: 0.56 - ETA: 0s - loss: 0.6782 - accuracy: 0.56 - ETA: 0s - loss: 0.6782 - accuracy: 0.56 - ETA: 0s - loss: 0.6783 - accuracy: 0.56 - 11s 273us/step - loss: 0.6784 - accuracy: 0.5638\n",
      "\n",
      "Epoch 00021: loss improved from 0.67973 to 0.67840, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-21-0.6784.hdf5\n",
      "Epoch 22/50\n",
      "40268/40268 [==============================] - ETA: 13s - loss: 0.6780 - accuracy: 0.541 - ETA: 11s - loss: 0.6747 - accuracy: 0.556 - ETA: 10s - loss: 0.6750 - accuracy: 0.555 - ETA: 10s - loss: 0.6725 - accuracy: 0.569 - ETA: 9s - loss: 0.6711 - accuracy: 0.578 - ETA: 9s - loss: 0.6725 - accuracy: 0.57 - ETA: 9s - loss: 0.6722 - accuracy: 0.57 - ETA: 9s - loss: 0.6732 - accuracy: 0.57 - ETA: 8s - loss: 0.6735 - accuracy: 0.56 - ETA: 8s - loss: 0.6733 - accuracy: 0.57 - ETA: 8s - loss: 0.6733 - accuracy: 0.57 - ETA: 8s - loss: 0.6732 - accuracy: 0.57 - ETA: 8s - loss: 0.6729 - accuracy: 0.57 - ETA: 8s - loss: 0.6723 - accuracy: 0.57 - ETA: 8s - loss: 0.6723 - accuracy: 0.57 - ETA: 8s - loss: 0.6729 - accuracy: 0.57 - ETA: 8s - loss: 0.6725 - accuracy: 0.57 - ETA: 8s - loss: 0.6733 - accuracy: 0.57 - ETA: 7s - loss: 0.6736 - accuracy: 0.57 - ETA: 7s - loss: 0.6748 - accuracy: 0.57 - ETA: 7s - loss: 0.6748 - accuracy: 0.57 - ETA: 7s - loss: 0.6754 - accuracy: 0.57 - ETA: 7s - loss: 0.6755 - accuracy: 0.57 - ETA: 7s - loss: 0.6761 - accuracy: 0.56 - ETA: 7s - loss: 0.6761 - accuracy: 0.56 - ETA: 6s - loss: 0.6761 - accuracy: 0.56 - ETA: 6s - loss: 0.6758 - accuracy: 0.56 - ETA: 6s - loss: 0.6756 - accuracy: 0.56 - ETA: 6s - loss: 0.6759 - accuracy: 0.56 - ETA: 6s - loss: 0.6759 - accuracy: 0.56 - ETA: 6s - loss: 0.6757 - accuracy: 0.56 - ETA: 6s - loss: 0.6753 - accuracy: 0.57 - ETA: 6s - loss: 0.6755 - accuracy: 0.57 - ETA: 5s - loss: 0.6752 - accuracy: 0.57 - ETA: 5s - loss: 0.6755 - accuracy: 0.56 - ETA: 5s - loss: 0.6753 - accuracy: 0.56 - ETA: 5s - loss: 0.6754 - accuracy: 0.56 - ETA: 5s - loss: 0.6753 - accuracy: 0.56 - ETA: 5s - loss: 0.6752 - accuracy: 0.57 - ETA: 5s - loss: 0.6749 - accuracy: 0.56 - ETA: 4s - loss: 0.6751 - accuracy: 0.56 - ETA: 4s - loss: 0.6753 - accuracy: 0.56 - ETA: 4s - loss: 0.6756 - accuracy: 0.56 - ETA: 4s - loss: 0.6759 - accuracy: 0.56 - ETA: 4s - loss: 0.6757 - accuracy: 0.56 - ETA: 4s - loss: 0.6759 - accuracy: 0.56 - ETA: 4s - loss: 0.6761 - accuracy: 0.56 - ETA: 3s - loss: 0.6761 - accuracy: 0.56 - ETA: 3s - loss: 0.6759 - accuracy: 0.56 - ETA: 3s - loss: 0.6759 - accuracy: 0.56 - ETA: 3s - loss: 0.6759 - accuracy: 0.56 - ETA: 3s - loss: 0.6759 - accuracy: 0.56 - ETA: 3s - loss: 0.6760 - accuracy: 0.56 - ETA: 3s - loss: 0.6761 - accuracy: 0.56 - ETA: 3s - loss: 0.6765 - accuracy: 0.56 - ETA: 2s - loss: 0.6763 - accuracy: 0.56 - ETA: 2s - loss: 0.6765 - accuracy: 0.56 - ETA: 2s - loss: 0.6765 - accuracy: 0.56 - ETA: 2s - loss: 0.6766 - accuracy: 0.56 - ETA: 2s - loss: 0.6767 - accuracy: 0.56 - ETA: 2s - loss: 0.6768 - accuracy: 0.56 - ETA: 2s - loss: 0.6769 - accuracy: 0.56 - ETA: 1s - loss: 0.6768 - accuracy: 0.56 - ETA: 1s - loss: 0.6769 - accuracy: 0.56 - ETA: 1s - loss: 0.6769 - accuracy: 0.56 - ETA: 1s - loss: 0.6768 - accuracy: 0.56 - ETA: 1s - loss: 0.6766 - accuracy: 0.56 - ETA: 1s - loss: 0.6766 - accuracy: 0.56 - ETA: 1s - loss: 0.6767 - accuracy: 0.56 - ETA: 1s - loss: 0.6766 - accuracy: 0.56 - ETA: 0s - loss: 0.6764 - accuracy: 0.56 - ETA: 0s - loss: 0.6762 - accuracy: 0.56 - ETA: 0s - loss: 0.6764 - accuracy: 0.56 - ETA: 0s - loss: 0.6766 - accuracy: 0.56 - ETA: 0s - loss: 0.6768 - accuracy: 0.56 - ETA: 0s - loss: 0.6769 - accuracy: 0.56 - ETA: 0s - loss: 0.6769 - accuracy: 0.56 - ETA: 0s - loss: 0.6770 - accuracy: 0.56 - 10s 237us/step - loss: 0.6770 - accuracy: 0.5660\n",
      "\n",
      "Epoch 00022: loss improved from 0.67840 to 0.67700, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-22-0.6770.hdf5\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6750 - accuracy: 0.57 - ETA: 7s - loss: 0.6774 - accuracy: 0.57 - ETA: 7s - loss: 0.6752 - accuracy: 0.57 - ETA: 7s - loss: 0.6761 - accuracy: 0.57 - ETA: 7s - loss: 0.6728 - accuracy: 0.58 - ETA: 7s - loss: 0.6733 - accuracy: 0.57 - ETA: 7s - loss: 0.6737 - accuracy: 0.57 - ETA: 7s - loss: 0.6764 - accuracy: 0.57 - ETA: 7s - loss: 0.6757 - accuracy: 0.57 - ETA: 7s - loss: 0.6764 - accuracy: 0.56 - ETA: 7s - loss: 0.6758 - accuracy: 0.57 - ETA: 7s - loss: 0.6758 - accuracy: 0.57 - ETA: 7s - loss: 0.6758 - accuracy: 0.57 - ETA: 7s - loss: 0.6757 - accuracy: 0.57 - ETA: 7s - loss: 0.6759 - accuracy: 0.57 - ETA: 6s - loss: 0.6758 - accuracy: 0.57 - ETA: 6s - loss: 0.6762 - accuracy: 0.57 - ETA: 6s - loss: 0.6755 - accuracy: 0.57 - ETA: 6s - loss: 0.6757 - accuracy: 0.57 - ETA: 6s - loss: 0.6751 - accuracy: 0.57 - ETA: 6s - loss: 0.6753 - accuracy: 0.57 - ETA: 6s - loss: 0.6753 - accuracy: 0.57 - ETA: 6s - loss: 0.6756 - accuracy: 0.57 - ETA: 6s - loss: 0.6754 - accuracy: 0.57 - ETA: 5s - loss: 0.6751 - accuracy: 0.57 - ETA: 5s - loss: 0.6750 - accuracy: 0.57 - ETA: 5s - loss: 0.6750 - accuracy: 0.57 - ETA: 5s - loss: 0.6748 - accuracy: 0.57 - ETA: 5s - loss: 0.6753 - accuracy: 0.57 - ETA: 5s - loss: 0.6759 - accuracy: 0.57 - ETA: 5s - loss: 0.6759 - accuracy: 0.56 - ETA: 5s - loss: 0.6755 - accuracy: 0.56 - ETA: 5s - loss: 0.6754 - accuracy: 0.56 - ETA: 4s - loss: 0.6755 - accuracy: 0.57 - ETA: 4s - loss: 0.6756 - accuracy: 0.57 - ETA: 4s - loss: 0.6755 - accuracy: 0.57 - ETA: 4s - loss: 0.6754 - accuracy: 0.57 - ETA: 4s - loss: 0.6757 - accuracy: 0.57 - ETA: 4s - loss: 0.6751 - accuracy: 0.57 - ETA: 4s - loss: 0.6750 - accuracy: 0.57 - ETA: 4s - loss: 0.6750 - accuracy: 0.57 - ETA: 4s - loss: 0.6748 - accuracy: 0.57 - ETA: 3s - loss: 0.6747 - accuracy: 0.57 - ETA: 3s - loss: 0.6749 - accuracy: 0.57 - ETA: 3s - loss: 0.6748 - accuracy: 0.57 - ETA: 3s - loss: 0.6749 - accuracy: 0.57 - ETA: 3s - loss: 0.6749 - accuracy: 0.57 - ETA: 3s - loss: 0.6747 - accuracy: 0.57 - ETA: 3s - loss: 0.6748 - accuracy: 0.57 - ETA: 3s - loss: 0.6750 - accuracy: 0.57 - ETA: 3s - loss: 0.6750 - accuracy: 0.57 - ETA: 3s - loss: 0.6749 - accuracy: 0.57 - ETA: 2s - loss: 0.6750 - accuracy: 0.57 - ETA: 2s - loss: 0.6750 - accuracy: 0.57 - ETA: 2s - loss: 0.6750 - accuracy: 0.57 - ETA: 2s - loss: 0.6750 - accuracy: 0.57 - ETA: 2s - loss: 0.6751 - accuracy: 0.57 - ETA: 2s - loss: 0.6752 - accuracy: 0.57 - ETA: 2s - loss: 0.6751 - accuracy: 0.57 - ETA: 2s - loss: 0.6751 - accuracy: 0.57 - ETA: 1s - loss: 0.6751 - accuracy: 0.57 - ETA: 1s - loss: 0.6749 - accuracy: 0.57 - ETA: 1s - loss: 0.6751 - accuracy: 0.57 - ETA: 1s - loss: 0.6751 - accuracy: 0.57 - ETA: 1s - loss: 0.6751 - accuracy: 0.57 - ETA: 1s - loss: 0.6751 - accuracy: 0.57 - ETA: 1s - loss: 0.6749 - accuracy: 0.57 - ETA: 1s - loss: 0.6750 - accuracy: 0.57 - ETA: 1s - loss: 0.6750 - accuracy: 0.57 - ETA: 0s - loss: 0.6748 - accuracy: 0.57 - ETA: 0s - loss: 0.6747 - accuracy: 0.57 - ETA: 0s - loss: 0.6747 - accuracy: 0.57 - ETA: 0s - loss: 0.6750 - accuracy: 0.57 - ETA: 0s - loss: 0.6752 - accuracy: 0.57 - ETA: 0s - loss: 0.6751 - accuracy: 0.57 - ETA: 0s - loss: 0.6752 - accuracy: 0.57 - ETA: 0s - loss: 0.6753 - accuracy: 0.57 - ETA: 0s - loss: 0.6754 - accuracy: 0.57 - 9s 217us/step - loss: 0.6754 - accuracy: 0.5703\n",
      "\n",
      "Epoch 00023: loss improved from 0.67700 to 0.67537, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-23-0.6754.hdf5\n",
      "Epoch 24/50\n",
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6721 - accuracy: 0.57 - ETA: 7s - loss: 0.6659 - accuracy: 0.59 - ETA: 7s - loss: 0.6668 - accuracy: 0.59 - ETA: 7s - loss: 0.6673 - accuracy: 0.58 - ETA: 7s - loss: 0.6691 - accuracy: 0.58 - ETA: 7s - loss: 0.6688 - accuracy: 0.58 - ETA: 7s - loss: 0.6685 - accuracy: 0.58 - ETA: 7s - loss: 0.6683 - accuracy: 0.58 - ETA: 7s - loss: 0.6706 - accuracy: 0.57 - ETA: 7s - loss: 0.6717 - accuracy: 0.57 - ETA: 7s - loss: 0.6717 - accuracy: 0.56 - ETA: 7s - loss: 0.6717 - accuracy: 0.57 - ETA: 7s - loss: 0.6714 - accuracy: 0.57 - ETA: 7s - loss: 0.6715 - accuracy: 0.57 - ETA: 6s - loss: 0.6714 - accuracy: 0.57 - ETA: 6s - loss: 0.6711 - accuracy: 0.56 - ETA: 6s - loss: 0.6712 - accuracy: 0.56 - ETA: 6s - loss: 0.6715 - accuracy: 0.56 - ETA: 6s - loss: 0.6715 - accuracy: 0.56 - ETA: 6s - loss: 0.6715 - accuracy: 0.56 - ETA: 6s - loss: 0.6713 - accuracy: 0.57 - ETA: 6s - loss: 0.6710 - accuracy: 0.57 - ETA: 6s - loss: 0.6709 - accuracy: 0.57 - ETA: 6s - loss: 0.6710 - accuracy: 0.57 - ETA: 5s - loss: 0.6709 - accuracy: 0.57 - ETA: 5s - loss: 0.6712 - accuracy: 0.57 - ETA: 5s - loss: 0.6714 - accuracy: 0.57 - ETA: 5s - loss: 0.6715 - accuracy: 0.57 - ETA: 5s - loss: 0.6716 - accuracy: 0.57 - ETA: 5s - loss: 0.6722 - accuracy: 0.57 - ETA: 5s - loss: 0.6721 - accuracy: 0.57 - ETA: 5s - loss: 0.6719 - accuracy: 0.57 - ETA: 5s - loss: 0.6718 - accuracy: 0.57 - ETA: 5s - loss: 0.6718 - accuracy: 0.57 - ETA: 4s - loss: 0.6720 - accuracy: 0.57 - ETA: 4s - loss: 0.6716 - accuracy: 0.57 - ETA: 4s - loss: 0.6720 - accuracy: 0.57 - ETA: 4s - loss: 0.6720 - accuracy: 0.57 - ETA: 4s - loss: 0.6717 - accuracy: 0.57 - ETA: 4s - loss: 0.6717 - accuracy: 0.57 - ETA: 4s - loss: 0.6718 - accuracy: 0.57 - ETA: 4s - loss: 0.6718 - accuracy: 0.57 - ETA: 4s - loss: 0.6718 - accuracy: 0.57 - ETA: 3s - loss: 0.6716 - accuracy: 0.57 - ETA: 3s - loss: 0.6718 - accuracy: 0.57 - ETA: 3s - loss: 0.6720 - accuracy: 0.57 - ETA: 3s - loss: 0.6722 - accuracy: 0.57 - ETA: 3s - loss: 0.6722 - accuracy: 0.57 - ETA: 3s - loss: 0.6723 - accuracy: 0.57 - ETA: 3s - loss: 0.6722 - accuracy: 0.57 - ETA: 3s - loss: 0.6723 - accuracy: 0.57 - ETA: 3s - loss: 0.6723 - accuracy: 0.57 - ETA: 2s - loss: 0.6721 - accuracy: 0.57 - ETA: 2s - loss: 0.6720 - accuracy: 0.57 - ETA: 2s - loss: 0.6720 - accuracy: 0.57 - ETA: 2s - loss: 0.6722 - accuracy: 0.57 - ETA: 2s - loss: 0.6723 - accuracy: 0.57 - ETA: 2s - loss: 0.6722 - accuracy: 0.57 - ETA: 2s - loss: 0.6723 - accuracy: 0.57 - ETA: 2s - loss: 0.6726 - accuracy: 0.57 - ETA: 2s - loss: 0.6727 - accuracy: 0.57 - ETA: 1s - loss: 0.6727 - accuracy: 0.57 - ETA: 1s - loss: 0.6726 - accuracy: 0.57 - ETA: 1s - loss: 0.6723 - accuracy: 0.57 - ETA: 1s - loss: 0.6722 - accuracy: 0.57 - ETA: 1s - loss: 0.6724 - accuracy: 0.57 - ETA: 1s - loss: 0.6724 - accuracy: 0.57 - ETA: 1s - loss: 0.6725 - accuracy: 0.57 - ETA: 1s - loss: 0.6724 - accuracy: 0.57 - ETA: 0s - loss: 0.6721 - accuracy: 0.57 - ETA: 0s - loss: 0.6719 - accuracy: 0.57 - ETA: 0s - loss: 0.6716 - accuracy: 0.57 - ETA: 0s - loss: 0.6717 - accuracy: 0.57 - ETA: 0s - loss: 0.6716 - accuracy: 0.57 - ETA: 0s - loss: 0.6717 - accuracy: 0.57 - ETA: 0s - loss: 0.6717 - accuracy: 0.57 - ETA: 0s - loss: 0.6717 - accuracy: 0.57 - ETA: 0s - loss: 0.6717 - accuracy: 0.57 - 9s 224us/step - loss: 0.6716 - accuracy: 0.5765\n",
      "\n",
      "Epoch 00024: loss improved from 0.67537 to 0.67159, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-24-0.6716.hdf5\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6795 - accuracy: 0.57 - ETA: 7s - loss: 0.6708 - accuracy: 0.57 - ETA: 7s - loss: 0.6702 - accuracy: 0.58 - ETA: 7s - loss: 0.6689 - accuracy: 0.58 - ETA: 7s - loss: 0.6692 - accuracy: 0.58 - ETA: 7s - loss: 0.6686 - accuracy: 0.58 - ETA: 7s - loss: 0.6685 - accuracy: 0.58 - ETA: 7s - loss: 0.6696 - accuracy: 0.57 - ETA: 7s - loss: 0.6685 - accuracy: 0.58 - ETA: 7s - loss: 0.6675 - accuracy: 0.58 - ETA: 7s - loss: 0.6675 - accuracy: 0.58 - ETA: 7s - loss: 0.6660 - accuracy: 0.58 - ETA: 7s - loss: 0.6667 - accuracy: 0.58 - ETA: 6s - loss: 0.6671 - accuracy: 0.58 - ETA: 6s - loss: 0.6675 - accuracy: 0.58 - ETA: 6s - loss: 0.6670 - accuracy: 0.58 - ETA: 6s - loss: 0.6670 - accuracy: 0.58 - ETA: 6s - loss: 0.6671 - accuracy: 0.58 - ETA: 6s - loss: 0.6664 - accuracy: 0.58 - ETA: 6s - loss: 0.6666 - accuracy: 0.58 - ETA: 6s - loss: 0.6668 - accuracy: 0.58 - ETA: 6s - loss: 0.6671 - accuracy: 0.58 - ETA: 6s - loss: 0.6669 - accuracy: 0.58 - ETA: 5s - loss: 0.6670 - accuracy: 0.58 - ETA: 5s - loss: 0.6673 - accuracy: 0.58 - ETA: 5s - loss: 0.6677 - accuracy: 0.58 - ETA: 5s - loss: 0.6675 - accuracy: 0.58 - ETA: 5s - loss: 0.6683 - accuracy: 0.58 - ETA: 5s - loss: 0.6681 - accuracy: 0.58 - ETA: 5s - loss: 0.6682 - accuracy: 0.58 - ETA: 5s - loss: 0.6684 - accuracy: 0.58 - ETA: 5s - loss: 0.6689 - accuracy: 0.58 - ETA: 4s - loss: 0.6689 - accuracy: 0.58 - ETA: 4s - loss: 0.6696 - accuracy: 0.57 - ETA: 4s - loss: 0.6698 - accuracy: 0.57 - ETA: 4s - loss: 0.6695 - accuracy: 0.58 - ETA: 4s - loss: 0.6698 - accuracy: 0.58 - ETA: 4s - loss: 0.6694 - accuracy: 0.58 - ETA: 4s - loss: 0.6697 - accuracy: 0.58 - ETA: 4s - loss: 0.6698 - accuracy: 0.58 - ETA: 4s - loss: 0.6699 - accuracy: 0.58 - ETA: 3s - loss: 0.6701 - accuracy: 0.58 - ETA: 3s - loss: 0.6701 - accuracy: 0.57 - ETA: 3s - loss: 0.6702 - accuracy: 0.57 - ETA: 3s - loss: 0.6701 - accuracy: 0.58 - ETA: 3s - loss: 0.6699 - accuracy: 0.58 - ETA: 3s - loss: 0.6700 - accuracy: 0.58 - ETA: 3s - loss: 0.6699 - accuracy: 0.58 - ETA: 3s - loss: 0.6700 - accuracy: 0.58 - ETA: 3s - loss: 0.6698 - accuracy: 0.58 - ETA: 3s - loss: 0.6698 - accuracy: 0.58 - ETA: 2s - loss: 0.6701 - accuracy: 0.58 - ETA: 2s - loss: 0.6700 - accuracy: 0.58 - ETA: 2s - loss: 0.6702 - accuracy: 0.58 - ETA: 2s - loss: 0.6700 - accuracy: 0.58 - ETA: 2s - loss: 0.6700 - accuracy: 0.58 - ETA: 2s - loss: 0.6701 - accuracy: 0.57 - ETA: 2s - loss: 0.6700 - accuracy: 0.57 - ETA: 2s - loss: 0.6701 - accuracy: 0.57 - ETA: 2s - loss: 0.6702 - accuracy: 0.57 - ETA: 1s - loss: 0.6702 - accuracy: 0.57 - ETA: 1s - loss: 0.6701 - accuracy: 0.57 - ETA: 1s - loss: 0.6700 - accuracy: 0.57 - ETA: 1s - loss: 0.6699 - accuracy: 0.57 - ETA: 1s - loss: 0.6700 - accuracy: 0.57 - ETA: 1s - loss: 0.6701 - accuracy: 0.57 - ETA: 1s - loss: 0.6700 - accuracy: 0.57 - ETA: 1s - loss: 0.6698 - accuracy: 0.57 - ETA: 1s - loss: 0.6696 - accuracy: 0.57 - ETA: 0s - loss: 0.6699 - accuracy: 0.57 - ETA: 0s - loss: 0.6699 - accuracy: 0.57 - ETA: 0s - loss: 0.6695 - accuracy: 0.58 - ETA: 0s - loss: 0.6693 - accuracy: 0.58 - ETA: 0s - loss: 0.6693 - accuracy: 0.58 - ETA: 0s - loss: 0.6695 - accuracy: 0.58 - ETA: 0s - loss: 0.6693 - accuracy: 0.58 - ETA: 0s - loss: 0.6693 - accuracy: 0.58 - ETA: 0s - loss: 0.6693 - accuracy: 0.58 - 9s 212us/step - loss: 0.6693 - accuracy: 0.5808\n",
      "\n",
      "Epoch 00025: loss improved from 0.67159 to 0.66927, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-25-0.6693.hdf5\n",
      "Epoch 26/50\n",
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6674 - accuracy: 0.58 - ETA: 7s - loss: 0.6689 - accuracy: 0.58 - ETA: 8s - loss: 0.6689 - accuracy: 0.58 - ETA: 7s - loss: 0.6668 - accuracy: 0.58 - ETA: 7s - loss: 0.6694 - accuracy: 0.58 - ETA: 7s - loss: 0.6677 - accuracy: 0.58 - ETA: 7s - loss: 0.6672 - accuracy: 0.58 - ETA: 7s - loss: 0.6675 - accuracy: 0.58 - ETA: 7s - loss: 0.6658 - accuracy: 0.58 - ETA: 7s - loss: 0.6655 - accuracy: 0.58 - ETA: 7s - loss: 0.6660 - accuracy: 0.59 - ETA: 7s - loss: 0.6650 - accuracy: 0.59 - ETA: 7s - loss: 0.6643 - accuracy: 0.59 - ETA: 6s - loss: 0.6644 - accuracy: 0.59 - ETA: 6s - loss: 0.6643 - accuracy: 0.59 - ETA: 6s - loss: 0.6649 - accuracy: 0.59 - ETA: 6s - loss: 0.6651 - accuracy: 0.59 - ETA: 6s - loss: 0.6657 - accuracy: 0.58 - ETA: 6s - loss: 0.6654 - accuracy: 0.58 - ETA: 6s - loss: 0.6653 - accuracy: 0.58 - ETA: 6s - loss: 0.6657 - accuracy: 0.58 - ETA: 6s - loss: 0.6660 - accuracy: 0.58 - ETA: 6s - loss: 0.6661 - accuracy: 0.58 - ETA: 5s - loss: 0.6661 - accuracy: 0.58 - ETA: 5s - loss: 0.6657 - accuracy: 0.58 - ETA: 5s - loss: 0.6652 - accuracy: 0.59 - ETA: 5s - loss: 0.6649 - accuracy: 0.59 - ETA: 5s - loss: 0.6653 - accuracy: 0.59 - ETA: 5s - loss: 0.6655 - accuracy: 0.58 - ETA: 5s - loss: 0.6653 - accuracy: 0.58 - ETA: 5s - loss: 0.6656 - accuracy: 0.58 - ETA: 5s - loss: 0.6653 - accuracy: 0.58 - ETA: 4s - loss: 0.6654 - accuracy: 0.58 - ETA: 4s - loss: 0.6658 - accuracy: 0.58 - ETA: 4s - loss: 0.6654 - accuracy: 0.58 - ETA: 4s - loss: 0.6654 - accuracy: 0.59 - ETA: 4s - loss: 0.6657 - accuracy: 0.58 - ETA: 4s - loss: 0.6661 - accuracy: 0.58 - ETA: 4s - loss: 0.6661 - accuracy: 0.58 - ETA: 4s - loss: 0.6663 - accuracy: 0.58 - ETA: 4s - loss: 0.6660 - accuracy: 0.58 - ETA: 3s - loss: 0.6660 - accuracy: 0.58 - ETA: 3s - loss: 0.6660 - accuracy: 0.58 - ETA: 3s - loss: 0.6662 - accuracy: 0.58 - ETA: 3s - loss: 0.6665 - accuracy: 0.58 - ETA: 3s - loss: 0.6664 - accuracy: 0.58 - ETA: 3s - loss: 0.6664 - accuracy: 0.58 - ETA: 3s - loss: 0.6665 - accuracy: 0.58 - ETA: 3s - loss: 0.6661 - accuracy: 0.58 - ETA: 3s - loss: 0.6661 - accuracy: 0.58 - ETA: 3s - loss: 0.6662 - accuracy: 0.58 - ETA: 2s - loss: 0.6660 - accuracy: 0.58 - ETA: 2s - loss: 0.6660 - accuracy: 0.58 - ETA: 2s - loss: 0.6660 - accuracy: 0.58 - ETA: 2s - loss: 0.6662 - accuracy: 0.58 - ETA: 2s - loss: 0.6662 - accuracy: 0.58 - ETA: 2s - loss: 0.6662 - accuracy: 0.58 - ETA: 2s - loss: 0.6662 - accuracy: 0.58 - ETA: 2s - loss: 0.6664 - accuracy: 0.58 - ETA: 2s - loss: 0.6662 - accuracy: 0.58 - ETA: 1s - loss: 0.6660 - accuracy: 0.58 - ETA: 1s - loss: 0.6660 - accuracy: 0.58 - ETA: 1s - loss: 0.6660 - accuracy: 0.58 - ETA: 1s - loss: 0.6659 - accuracy: 0.58 - ETA: 1s - loss: 0.6659 - accuracy: 0.58 - ETA: 1s - loss: 0.6659 - accuracy: 0.58 - ETA: 1s - loss: 0.6660 - accuracy: 0.58 - ETA: 1s - loss: 0.6657 - accuracy: 0.58 - ETA: 1s - loss: 0.6657 - accuracy: 0.58 - ETA: 0s - loss: 0.6659 - accuracy: 0.58 - ETA: 0s - loss: 0.6660 - accuracy: 0.58 - ETA: 0s - loss: 0.6661 - accuracy: 0.58 - ETA: 0s - loss: 0.6664 - accuracy: 0.58 - ETA: 0s - loss: 0.6665 - accuracy: 0.58 - ETA: 0s - loss: 0.6665 - accuracy: 0.58 - ETA: 0s - loss: 0.6665 - accuracy: 0.58 - ETA: 0s - loss: 0.6668 - accuracy: 0.58 - ETA: 0s - loss: 0.6669 - accuracy: 0.58 - 9s 212us/step - loss: 0.6669 - accuracy: 0.5860\n",
      "\n",
      "Epoch 00026: loss improved from 0.66927 to 0.66688, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-26-0.6669.hdf5\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6643 - accuracy: 0.61 - ETA: 7s - loss: 0.6691 - accuracy: 0.59 - ETA: 7s - loss: 0.6676 - accuracy: 0.59 - ETA: 7s - loss: 0.6648 - accuracy: 0.60 - ETA: 7s - loss: 0.6628 - accuracy: 0.60 - ETA: 7s - loss: 0.6605 - accuracy: 0.60 - ETA: 7s - loss: 0.6631 - accuracy: 0.59 - ETA: 7s - loss: 0.6640 - accuracy: 0.59 - ETA: 7s - loss: 0.6640 - accuracy: 0.59 - ETA: 7s - loss: 0.6646 - accuracy: 0.59 - ETA: 7s - loss: 0.6648 - accuracy: 0.59 - ETA: 7s - loss: 0.6656 - accuracy: 0.58 - ETA: 7s - loss: 0.6662 - accuracy: 0.58 - ETA: 7s - loss: 0.6665 - accuracy: 0.58 - ETA: 6s - loss: 0.6660 - accuracy: 0.58 - ETA: 6s - loss: 0.6653 - accuracy: 0.59 - ETA: 6s - loss: 0.6645 - accuracy: 0.59 - ETA: 6s - loss: 0.6645 - accuracy: 0.59 - ETA: 6s - loss: 0.6636 - accuracy: 0.59 - ETA: 6s - loss: 0.6633 - accuracy: 0.59 - ETA: 6s - loss: 0.6633 - accuracy: 0.59 - ETA: 6s - loss: 0.6640 - accuracy: 0.59 - ETA: 6s - loss: 0.6643 - accuracy: 0.59 - ETA: 5s - loss: 0.6635 - accuracy: 0.59 - ETA: 5s - loss: 0.6633 - accuracy: 0.59 - ETA: 5s - loss: 0.6638 - accuracy: 0.59 - ETA: 5s - loss: 0.6636 - accuracy: 0.59 - ETA: 5s - loss: 0.6636 - accuracy: 0.59 - ETA: 5s - loss: 0.6643 - accuracy: 0.58 - ETA: 5s - loss: 0.6642 - accuracy: 0.58 - ETA: 5s - loss: 0.6641 - accuracy: 0.58 - ETA: 5s - loss: 0.6641 - accuracy: 0.58 - ETA: 4s - loss: 0.6640 - accuracy: 0.58 - ETA: 4s - loss: 0.6638 - accuracy: 0.58 - ETA: 4s - loss: 0.6636 - accuracy: 0.59 - ETA: 4s - loss: 0.6636 - accuracy: 0.59 - ETA: 4s - loss: 0.6644 - accuracy: 0.58 - ETA: 4s - loss: 0.6645 - accuracy: 0.58 - ETA: 4s - loss: 0.6643 - accuracy: 0.58 - ETA: 4s - loss: 0.6640 - accuracy: 0.59 - ETA: 4s - loss: 0.6641 - accuracy: 0.59 - ETA: 3s - loss: 0.6642 - accuracy: 0.58 - ETA: 3s - loss: 0.6638 - accuracy: 0.59 - ETA: 3s - loss: 0.6636 - accuracy: 0.58 - ETA: 3s - loss: 0.6637 - accuracy: 0.58 - ETA: 3s - loss: 0.6637 - accuracy: 0.58 - ETA: 3s - loss: 0.6637 - accuracy: 0.58 - ETA: 3s - loss: 0.6635 - accuracy: 0.59 - ETA: 3s - loss: 0.6634 - accuracy: 0.59 - ETA: 3s - loss: 0.6631 - accuracy: 0.59 - ETA: 3s - loss: 0.6630 - accuracy: 0.59 - ETA: 2s - loss: 0.6631 - accuracy: 0.59 - ETA: 2s - loss: 0.6629 - accuracy: 0.59 - ETA: 2s - loss: 0.6629 - accuracy: 0.59 - ETA: 2s - loss: 0.6632 - accuracy: 0.59 - ETA: 2s - loss: 0.6633 - accuracy: 0.59 - ETA: 2s - loss: 0.6633 - accuracy: 0.59 - ETA: 2s - loss: 0.6632 - accuracy: 0.59 - ETA: 2s - loss: 0.6629 - accuracy: 0.59 - ETA: 2s - loss: 0.6630 - accuracy: 0.59 - ETA: 1s - loss: 0.6632 - accuracy: 0.59 - ETA: 1s - loss: 0.6632 - accuracy: 0.59 - ETA: 1s - loss: 0.6633 - accuracy: 0.59 - ETA: 1s - loss: 0.6636 - accuracy: 0.59 - ETA: 1s - loss: 0.6635 - accuracy: 0.59 - ETA: 1s - loss: 0.6635 - accuracy: 0.59 - ETA: 1s - loss: 0.6638 - accuracy: 0.59 - ETA: 1s - loss: 0.6639 - accuracy: 0.59 - ETA: 1s - loss: 0.6636 - accuracy: 0.59 - ETA: 0s - loss: 0.6638 - accuracy: 0.59 - ETA: 0s - loss: 0.6636 - accuracy: 0.59 - ETA: 0s - loss: 0.6636 - accuracy: 0.59 - ETA: 0s - loss: 0.6636 - accuracy: 0.59 - ETA: 0s - loss: 0.6638 - accuracy: 0.59 - ETA: 0s - loss: 0.6639 - accuracy: 0.59 - ETA: 0s - loss: 0.6641 - accuracy: 0.59 - ETA: 0s - loss: 0.6640 - accuracy: 0.59 - ETA: 0s - loss: 0.6641 - accuracy: 0.59 - 9s 216us/step - loss: 0.6639 - accuracy: 0.5927\n",
      "\n",
      "Epoch 00027: loss improved from 0.66688 to 0.66390, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-27-0.6639.hdf5\n",
      "Epoch 28/50\n",
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6432 - accuracy: 0.60 - ETA: 8s - loss: 0.6460 - accuracy: 0.60 - ETA: 8s - loss: 0.6467 - accuracy: 0.60 - ETA: 8s - loss: 0.6508 - accuracy: 0.60 - ETA: 8s - loss: 0.6552 - accuracy: 0.60 - ETA: 8s - loss: 0.6549 - accuracy: 0.60 - ETA: 8s - loss: 0.6540 - accuracy: 0.59 - ETA: 8s - loss: 0.6548 - accuracy: 0.59 - ETA: 8s - loss: 0.6561 - accuracy: 0.59 - ETA: 8s - loss: 0.6567 - accuracy: 0.59 - ETA: 7s - loss: 0.6576 - accuracy: 0.59 - ETA: 7s - loss: 0.6576 - accuracy: 0.59 - ETA: 7s - loss: 0.6568 - accuracy: 0.59 - ETA: 7s - loss: 0.6570 - accuracy: 0.59 - ETA: 7s - loss: 0.6580 - accuracy: 0.59 - ETA: 7s - loss: 0.6568 - accuracy: 0.59 - ETA: 7s - loss: 0.6584 - accuracy: 0.59 - ETA: 7s - loss: 0.6582 - accuracy: 0.59 - ETA: 7s - loss: 0.6571 - accuracy: 0.59 - ETA: 6s - loss: 0.6581 - accuracy: 0.59 - ETA: 6s - loss: 0.6584 - accuracy: 0.59 - ETA: 6s - loss: 0.6581 - accuracy: 0.59 - ETA: 6s - loss: 0.6575 - accuracy: 0.59 - ETA: 6s - loss: 0.6575 - accuracy: 0.59 - ETA: 6s - loss: 0.6571 - accuracy: 0.59 - ETA: 6s - loss: 0.6575 - accuracy: 0.59 - ETA: 6s - loss: 0.6574 - accuracy: 0.59 - ETA: 5s - loss: 0.6577 - accuracy: 0.59 - ETA: 5s - loss: 0.6575 - accuracy: 0.59 - ETA: 5s - loss: 0.6575 - accuracy: 0.59 - ETA: 5s - loss: 0.6581 - accuracy: 0.59 - ETA: 5s - loss: 0.6582 - accuracy: 0.59 - ETA: 5s - loss: 0.6584 - accuracy: 0.59 - ETA: 5s - loss: 0.6586 - accuracy: 0.59 - ETA: 5s - loss: 0.6585 - accuracy: 0.59 - ETA: 4s - loss: 0.6589 - accuracy: 0.59 - ETA: 4s - loss: 0.6590 - accuracy: 0.59 - ETA: 4s - loss: 0.6592 - accuracy: 0.59 - ETA: 4s - loss: 0.6595 - accuracy: 0.59 - ETA: 4s - loss: 0.6598 - accuracy: 0.59 - ETA: 4s - loss: 0.6598 - accuracy: 0.59 - ETA: 4s - loss: 0.6598 - accuracy: 0.59 - ETA: 4s - loss: 0.6600 - accuracy: 0.59 - ETA: 3s - loss: 0.6602 - accuracy: 0.59 - ETA: 3s - loss: 0.6600 - accuracy: 0.59 - ETA: 3s - loss: 0.6599 - accuracy: 0.59 - ETA: 3s - loss: 0.6601 - accuracy: 0.59 - ETA: 3s - loss: 0.6599 - accuracy: 0.59 - ETA: 3s - loss: 0.6603 - accuracy: 0.59 - ETA: 3s - loss: 0.6599 - accuracy: 0.59 - ETA: 3s - loss: 0.6599 - accuracy: 0.59 - ETA: 3s - loss: 0.6602 - accuracy: 0.59 - ETA: 2s - loss: 0.6602 - accuracy: 0.59 - ETA: 2s - loss: 0.6605 - accuracy: 0.59 - ETA: 2s - loss: 0.6603 - accuracy: 0.59 - ETA: 2s - loss: 0.6604 - accuracy: 0.59 - ETA: 2s - loss: 0.6603 - accuracy: 0.59 - ETA: 2s - loss: 0.6602 - accuracy: 0.59 - ETA: 2s - loss: 0.6602 - accuracy: 0.59 - ETA: 2s - loss: 0.6603 - accuracy: 0.59 - ETA: 1s - loss: 0.6603 - accuracy: 0.59 - ETA: 1s - loss: 0.6601 - accuracy: 0.59 - ETA: 1s - loss: 0.6603 - accuracy: 0.59 - ETA: 1s - loss: 0.6602 - accuracy: 0.59 - ETA: 1s - loss: 0.6602 - accuracy: 0.59 - ETA: 1s - loss: 0.6601 - accuracy: 0.59 - ETA: 1s - loss: 0.6602 - accuracy: 0.59 - ETA: 1s - loss: 0.6604 - accuracy: 0.59 - ETA: 1s - loss: 0.6605 - accuracy: 0.59 - ETA: 0s - loss: 0.6605 - accuracy: 0.59 - ETA: 0s - loss: 0.6603 - accuracy: 0.59 - ETA: 0s - loss: 0.6602 - accuracy: 0.59 - ETA: 0s - loss: 0.6599 - accuracy: 0.59 - ETA: 0s - loss: 0.6599 - accuracy: 0.59 - ETA: 0s - loss: 0.6602 - accuracy: 0.59 - ETA: 0s - loss: 0.6603 - accuracy: 0.59 - ETA: 0s - loss: 0.6602 - accuracy: 0.59 - ETA: 0s - loss: 0.6602 - accuracy: 0.59 - 9s 218us/step - loss: 0.6604 - accuracy: 0.5936\n",
      "\n",
      "Epoch 00028: loss improved from 0.66390 to 0.66036, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-28-0.6604.hdf5\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6460 - accuracy: 0.62 - ETA: 8s - loss: 0.6514 - accuracy: 0.62 - ETA: 8s - loss: 0.6467 - accuracy: 0.62 - ETA: 8s - loss: 0.6494 - accuracy: 0.61 - ETA: 8s - loss: 0.6527 - accuracy: 0.61 - ETA: 8s - loss: 0.6539 - accuracy: 0.61 - ETA: 7s - loss: 0.6541 - accuracy: 0.60 - ETA: 7s - loss: 0.6524 - accuracy: 0.61 - ETA: 7s - loss: 0.6535 - accuracy: 0.61 - ETA: 7s - loss: 0.6546 - accuracy: 0.60 - ETA: 7s - loss: 0.6572 - accuracy: 0.60 - ETA: 7s - loss: 0.6562 - accuracy: 0.60 - ETA: 7s - loss: 0.6555 - accuracy: 0.60 - ETA: 7s - loss: 0.6561 - accuracy: 0.60 - ETA: 7s - loss: 0.6550 - accuracy: 0.60 - ETA: 6s - loss: 0.6543 - accuracy: 0.60 - ETA: 6s - loss: 0.6542 - accuracy: 0.60 - ETA: 6s - loss: 0.6544 - accuracy: 0.60 - ETA: 6s - loss: 0.6548 - accuracy: 0.60 - ETA: 6s - loss: 0.6544 - accuracy: 0.60 - ETA: 6s - loss: 0.6540 - accuracy: 0.60 - ETA: 6s - loss: 0.6548 - accuracy: 0.60 - ETA: 6s - loss: 0.6551 - accuracy: 0.60 - ETA: 6s - loss: 0.6554 - accuracy: 0.60 - ETA: 5s - loss: 0.6557 - accuracy: 0.60 - ETA: 5s - loss: 0.6552 - accuracy: 0.60 - ETA: 5s - loss: 0.6559 - accuracy: 0.60 - ETA: 5s - loss: 0.6558 - accuracy: 0.60 - ETA: 5s - loss: 0.6557 - accuracy: 0.60 - ETA: 5s - loss: 0.6563 - accuracy: 0.60 - ETA: 5s - loss: 0.6565 - accuracy: 0.60 - ETA: 5s - loss: 0.6563 - accuracy: 0.60 - ETA: 5s - loss: 0.6559 - accuracy: 0.60 - ETA: 4s - loss: 0.6561 - accuracy: 0.60 - ETA: 4s - loss: 0.6564 - accuracy: 0.60 - ETA: 4s - loss: 0.6564 - accuracy: 0.60 - ETA: 4s - loss: 0.6564 - accuracy: 0.60 - ETA: 4s - loss: 0.6564 - accuracy: 0.60 - ETA: 4s - loss: 0.6564 - accuracy: 0.60 - ETA: 4s - loss: 0.6562 - accuracy: 0.60 - ETA: 4s - loss: 0.6557 - accuracy: 0.60 - ETA: 4s - loss: 0.6556 - accuracy: 0.60 - ETA: 3s - loss: 0.6559 - accuracy: 0.60 - ETA: 3s - loss: 0.6559 - accuracy: 0.60 - ETA: 3s - loss: 0.6560 - accuracy: 0.60 - ETA: 3s - loss: 0.6560 - accuracy: 0.60 - ETA: 3s - loss: 0.6563 - accuracy: 0.60 - ETA: 3s - loss: 0.6565 - accuracy: 0.60 - ETA: 3s - loss: 0.6564 - accuracy: 0.60 - ETA: 3s - loss: 0.6563 - accuracy: 0.60 - ETA: 3s - loss: 0.6566 - accuracy: 0.60 - ETA: 2s - loss: 0.6566 - accuracy: 0.60 - ETA: 2s - loss: 0.6569 - accuracy: 0.60 - ETA: 2s - loss: 0.6569 - accuracy: 0.60 - ETA: 2s - loss: 0.6568 - accuracy: 0.60 - ETA: 2s - loss: 0.6568 - accuracy: 0.60 - ETA: 2s - loss: 0.6569 - accuracy: 0.60 - ETA: 2s - loss: 0.6569 - accuracy: 0.60 - ETA: 2s - loss: 0.6571 - accuracy: 0.60 - ETA: 2s - loss: 0.6570 - accuracy: 0.60 - ETA: 1s - loss: 0.6567 - accuracy: 0.60 - ETA: 1s - loss: 0.6567 - accuracy: 0.60 - ETA: 1s - loss: 0.6565 - accuracy: 0.60 - ETA: 1s - loss: 0.6567 - accuracy: 0.60 - ETA: 1s - loss: 0.6570 - accuracy: 0.59 - ETA: 1s - loss: 0.6570 - accuracy: 0.59 - ETA: 1s - loss: 0.6568 - accuracy: 0.59 - ETA: 1s - loss: 0.6569 - accuracy: 0.59 - ETA: 1s - loss: 0.6573 - accuracy: 0.59 - ETA: 0s - loss: 0.6575 - accuracy: 0.59 - ETA: 0s - loss: 0.6575 - accuracy: 0.59 - ETA: 0s - loss: 0.6574 - accuracy: 0.59 - ETA: 0s - loss: 0.6574 - accuracy: 0.59 - ETA: 0s - loss: 0.6575 - accuracy: 0.59 - ETA: 0s - loss: 0.6571 - accuracy: 0.59 - ETA: 0s - loss: 0.6575 - accuracy: 0.59 - ETA: 0s - loss: 0.6574 - accuracy: 0.59 - ETA: 0s - loss: 0.6573 - accuracy: 0.59 - 9s 218us/step - loss: 0.6573 - accuracy: 0.5982\n",
      "\n",
      "Epoch 00029: loss improved from 0.66036 to 0.65731, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-29-0.6573.hdf5\n",
      "Epoch 30/50\n",
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6499 - accuracy: 0.61 - ETA: 8s - loss: 0.6521 - accuracy: 0.61 - ETA: 8s - loss: 0.6550 - accuracy: 0.61 - ETA: 8s - loss: 0.6564 - accuracy: 0.60 - ETA: 8s - loss: 0.6545 - accuracy: 0.60 - ETA: 7s - loss: 0.6545 - accuracy: 0.61 - ETA: 7s - loss: 0.6554 - accuracy: 0.60 - ETA: 7s - loss: 0.6555 - accuracy: 0.60 - ETA: 7s - loss: 0.6569 - accuracy: 0.60 - ETA: 7s - loss: 0.6558 - accuracy: 0.60 - ETA: 7s - loss: 0.6558 - accuracy: 0.60 - ETA: 7s - loss: 0.6565 - accuracy: 0.60 - ETA: 7s - loss: 0.6557 - accuracy: 0.60 - ETA: 7s - loss: 0.6559 - accuracy: 0.60 - ETA: 6s - loss: 0.6551 - accuracy: 0.60 - ETA: 6s - loss: 0.6540 - accuracy: 0.60 - ETA: 6s - loss: 0.6540 - accuracy: 0.60 - ETA: 6s - loss: 0.6546 - accuracy: 0.60 - ETA: 6s - loss: 0.6545 - accuracy: 0.60 - ETA: 6s - loss: 0.6553 - accuracy: 0.60 - ETA: 6s - loss: 0.6551 - accuracy: 0.60 - ETA: 6s - loss: 0.6554 - accuracy: 0.60 - ETA: 6s - loss: 0.6548 - accuracy: 0.60 - ETA: 5s - loss: 0.6551 - accuracy: 0.60 - ETA: 5s - loss: 0.6553 - accuracy: 0.60 - ETA: 5s - loss: 0.6548 - accuracy: 0.60 - ETA: 5s - loss: 0.6545 - accuracy: 0.60 - ETA: 5s - loss: 0.6544 - accuracy: 0.60 - ETA: 5s - loss: 0.6545 - accuracy: 0.60 - ETA: 5s - loss: 0.6546 - accuracy: 0.60 - ETA: 5s - loss: 0.6550 - accuracy: 0.60 - ETA: 5s - loss: 0.6548 - accuracy: 0.60 - ETA: 4s - loss: 0.6545 - accuracy: 0.60 - ETA: 4s - loss: 0.6547 - accuracy: 0.60 - ETA: 4s - loss: 0.6546 - accuracy: 0.60 - ETA: 4s - loss: 0.6546 - accuracy: 0.60 - ETA: 4s - loss: 0.6543 - accuracy: 0.60 - ETA: 4s - loss: 0.6547 - accuracy: 0.59 - ETA: 4s - loss: 0.6544 - accuracy: 0.59 - ETA: 4s - loss: 0.6545 - accuracy: 0.59 - ETA: 4s - loss: 0.6544 - accuracy: 0.60 - ETA: 4s - loss: 0.6547 - accuracy: 0.60 - ETA: 3s - loss: 0.6547 - accuracy: 0.60 - ETA: 3s - loss: 0.6545 - accuracy: 0.60 - ETA: 3s - loss: 0.6545 - accuracy: 0.60 - ETA: 3s - loss: 0.6540 - accuracy: 0.60 - ETA: 3s - loss: 0.6537 - accuracy: 0.60 - ETA: 3s - loss: 0.6536 - accuracy: 0.60 - ETA: 3s - loss: 0.6536 - accuracy: 0.60 - ETA: 3s - loss: 0.6536 - accuracy: 0.60 - ETA: 3s - loss: 0.6535 - accuracy: 0.60 - ETA: 2s - loss: 0.6533 - accuracy: 0.60 - ETA: 2s - loss: 0.6534 - accuracy: 0.60 - ETA: 2s - loss: 0.6534 - accuracy: 0.60 - ETA: 2s - loss: 0.6534 - accuracy: 0.60 - ETA: 2s - loss: 0.6533 - accuracy: 0.60 - ETA: 2s - loss: 0.6533 - accuracy: 0.60 - ETA: 2s - loss: 0.6530 - accuracy: 0.60 - ETA: 2s - loss: 0.6527 - accuracy: 0.60 - ETA: 2s - loss: 0.6526 - accuracy: 0.60 - ETA: 1s - loss: 0.6527 - accuracy: 0.60 - ETA: 1s - loss: 0.6526 - accuracy: 0.60 - ETA: 1s - loss: 0.6526 - accuracy: 0.60 - ETA: 1s - loss: 0.6527 - accuracy: 0.60 - ETA: 1s - loss: 0.6528 - accuracy: 0.60 - ETA: 1s - loss: 0.6528 - accuracy: 0.60 - ETA: 1s - loss: 0.6530 - accuracy: 0.60 - ETA: 1s - loss: 0.6530 - accuracy: 0.60 - ETA: 1s - loss: 0.6529 - accuracy: 0.60 - ETA: 0s - loss: 0.6531 - accuracy: 0.60 - ETA: 0s - loss: 0.6530 - accuracy: 0.60 - ETA: 0s - loss: 0.6531 - accuracy: 0.60 - ETA: 0s - loss: 0.6531 - accuracy: 0.60 - ETA: 0s - loss: 0.6533 - accuracy: 0.60 - ETA: 0s - loss: 0.6534 - accuracy: 0.60 - ETA: 0s - loss: 0.6535 - accuracy: 0.60 - ETA: 0s - loss: 0.6535 - accuracy: 0.60 - ETA: 0s - loss: 0.6536 - accuracy: 0.60 - 9s 219us/step - loss: 0.6536 - accuracy: 0.6024\n",
      "\n",
      "Epoch 00030: loss improved from 0.65731 to 0.65357, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-30-0.6536.hdf5\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6424 - accuracy: 0.62 - ETA: 8s - loss: 0.6479 - accuracy: 0.62 - ETA: 8s - loss: 0.6461 - accuracy: 0.62 - ETA: 8s - loss: 0.6436 - accuracy: 0.62 - ETA: 8s - loss: 0.6445 - accuracy: 0.61 - ETA: 8s - loss: 0.6493 - accuracy: 0.61 - ETA: 8s - loss: 0.6458 - accuracy: 0.61 - ETA: 8s - loss: 0.6464 - accuracy: 0.61 - ETA: 8s - loss: 0.6472 - accuracy: 0.61 - ETA: 7s - loss: 0.6482 - accuracy: 0.61 - ETA: 7s - loss: 0.6481 - accuracy: 0.61 - ETA: 7s - loss: 0.6482 - accuracy: 0.61 - ETA: 7s - loss: 0.6491 - accuracy: 0.61 - ETA: 7s - loss: 0.6487 - accuracy: 0.61 - ETA: 7s - loss: 0.6470 - accuracy: 0.61 - ETA: 7s - loss: 0.6469 - accuracy: 0.61 - ETA: 7s - loss: 0.6463 - accuracy: 0.61 - ETA: 7s - loss: 0.6464 - accuracy: 0.61 - ETA: 6s - loss: 0.6466 - accuracy: 0.61 - ETA: 6s - loss: 0.6469 - accuracy: 0.61 - ETA: 6s - loss: 0.6476 - accuracy: 0.61 - ETA: 6s - loss: 0.6478 - accuracy: 0.61 - ETA: 6s - loss: 0.6479 - accuracy: 0.61 - ETA: 6s - loss: 0.6474 - accuracy: 0.61 - ETA: 6s - loss: 0.6479 - accuracy: 0.61 - ETA: 6s - loss: 0.6489 - accuracy: 0.61 - ETA: 6s - loss: 0.6495 - accuracy: 0.60 - ETA: 5s - loss: 0.6500 - accuracy: 0.60 - ETA: 5s - loss: 0.6492 - accuracy: 0.60 - ETA: 5s - loss: 0.6493 - accuracy: 0.60 - ETA: 5s - loss: 0.6493 - accuracy: 0.60 - ETA: 5s - loss: 0.6491 - accuracy: 0.60 - ETA: 5s - loss: 0.6484 - accuracy: 0.61 - ETA: 5s - loss: 0.6479 - accuracy: 0.61 - ETA: 5s - loss: 0.6482 - accuracy: 0.61 - ETA: 4s - loss: 0.6486 - accuracy: 0.61 - ETA: 4s - loss: 0.6491 - accuracy: 0.60 - ETA: 4s - loss: 0.6492 - accuracy: 0.60 - ETA: 4s - loss: 0.6490 - accuracy: 0.60 - ETA: 4s - loss: 0.6493 - accuracy: 0.60 - ETA: 4s - loss: 0.6499 - accuracy: 0.60 - ETA: 4s - loss: 0.6502 - accuracy: 0.60 - ETA: 4s - loss: 0.6502 - accuracy: 0.60 - ETA: 4s - loss: 0.6498 - accuracy: 0.60 - ETA: 3s - loss: 0.6500 - accuracy: 0.60 - ETA: 3s - loss: 0.6500 - accuracy: 0.60 - ETA: 3s - loss: 0.6497 - accuracy: 0.60 - ETA: 3s - loss: 0.6499 - accuracy: 0.60 - ETA: 3s - loss: 0.6497 - accuracy: 0.60 - ETA: 3s - loss: 0.6495 - accuracy: 0.60 - ETA: 3s - loss: 0.6497 - accuracy: 0.60 - ETA: 3s - loss: 0.6496 - accuracy: 0.60 - ETA: 3s - loss: 0.6495 - accuracy: 0.60 - ETA: 2s - loss: 0.6499 - accuracy: 0.60 - ETA: 2s - loss: 0.6499 - accuracy: 0.60 - ETA: 2s - loss: 0.6498 - accuracy: 0.60 - ETA: 2s - loss: 0.6498 - accuracy: 0.60 - ETA: 2s - loss: 0.6498 - accuracy: 0.60 - ETA: 2s - loss: 0.6499 - accuracy: 0.60 - ETA: 2s - loss: 0.6498 - accuracy: 0.60 - ETA: 2s - loss: 0.6500 - accuracy: 0.60 - ETA: 1s - loss: 0.6497 - accuracy: 0.60 - ETA: 1s - loss: 0.6501 - accuracy: 0.60 - ETA: 1s - loss: 0.6504 - accuracy: 0.60 - ETA: 1s - loss: 0.6505 - accuracy: 0.60 - ETA: 1s - loss: 0.6505 - accuracy: 0.60 - ETA: 1s - loss: 0.6509 - accuracy: 0.60 - ETA: 1s - loss: 0.6511 - accuracy: 0.60 - ETA: 1s - loss: 0.6511 - accuracy: 0.60 - ETA: 0s - loss: 0.6513 - accuracy: 0.60 - ETA: 0s - loss: 0.6513 - accuracy: 0.60 - ETA: 0s - loss: 0.6512 - accuracy: 0.60 - ETA: 0s - loss: 0.6513 - accuracy: 0.60 - ETA: 0s - loss: 0.6512 - accuracy: 0.60 - ETA: 0s - loss: 0.6512 - accuracy: 0.60 - ETA: 0s - loss: 0.6514 - accuracy: 0.60 - ETA: 0s - loss: 0.6514 - accuracy: 0.60 - ETA: 0s - loss: 0.6512 - accuracy: 0.60 - 9s 225us/step - loss: 0.6510 - accuracy: 0.6078\n",
      "\n",
      "Epoch 00031: loss improved from 0.65357 to 0.65104, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-31-0.6510.hdf5\n",
      "Epoch 32/50\n",
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6565 - accuracy: 0.57 - ETA: 8s - loss: 0.6501 - accuracy: 0.59 - ETA: 8s - loss: 0.6501 - accuracy: 0.60 - ETA: 8s - loss: 0.6508 - accuracy: 0.60 - ETA: 8s - loss: 0.6450 - accuracy: 0.61 - ETA: 8s - loss: 0.6445 - accuracy: 0.61 - ETA: 8s - loss: 0.6428 - accuracy: 0.61 - ETA: 8s - loss: 0.6437 - accuracy: 0.61 - ETA: 8s - loss: 0.6424 - accuracy: 0.61 - ETA: 8s - loss: 0.6417 - accuracy: 0.61 - ETA: 8s - loss: 0.6417 - accuracy: 0.61 - ETA: 7s - loss: 0.6422 - accuracy: 0.62 - ETA: 7s - loss: 0.6434 - accuracy: 0.61 - ETA: 7s - loss: 0.6431 - accuracy: 0.61 - ETA: 7s - loss: 0.6432 - accuracy: 0.61 - ETA: 7s - loss: 0.6430 - accuracy: 0.62 - ETA: 7s - loss: 0.6432 - accuracy: 0.62 - ETA: 7s - loss: 0.6428 - accuracy: 0.61 - ETA: 6s - loss: 0.6428 - accuracy: 0.61 - ETA: 6s - loss: 0.6427 - accuracy: 0.61 - ETA: 6s - loss: 0.6430 - accuracy: 0.61 - ETA: 6s - loss: 0.6431 - accuracy: 0.61 - ETA: 6s - loss: 0.6434 - accuracy: 0.61 - ETA: 6s - loss: 0.6443 - accuracy: 0.61 - ETA: 6s - loss: 0.6447 - accuracy: 0.61 - ETA: 5s - loss: 0.6445 - accuracy: 0.61 - ETA: 5s - loss: 0.6449 - accuracy: 0.61 - ETA: 5s - loss: 0.6456 - accuracy: 0.61 - ETA: 5s - loss: 0.6460 - accuracy: 0.61 - ETA: 5s - loss: 0.6465 - accuracy: 0.61 - ETA: 5s - loss: 0.6462 - accuracy: 0.61 - ETA: 5s - loss: 0.6459 - accuracy: 0.61 - ETA: 5s - loss: 0.6464 - accuracy: 0.61 - ETA: 5s - loss: 0.6471 - accuracy: 0.61 - ETA: 4s - loss: 0.6473 - accuracy: 0.61 - ETA: 4s - loss: 0.6479 - accuracy: 0.61 - ETA: 4s - loss: 0.6476 - accuracy: 0.61 - ETA: 4s - loss: 0.6469 - accuracy: 0.61 - ETA: 4s - loss: 0.6472 - accuracy: 0.61 - ETA: 4s - loss: 0.6470 - accuracy: 0.61 - ETA: 4s - loss: 0.6469 - accuracy: 0.61 - ETA: 4s - loss: 0.6468 - accuracy: 0.61 - ETA: 3s - loss: 0.6470 - accuracy: 0.61 - ETA: 3s - loss: 0.6466 - accuracy: 0.61 - ETA: 3s - loss: 0.6464 - accuracy: 0.61 - ETA: 3s - loss: 0.6458 - accuracy: 0.61 - ETA: 3s - loss: 0.6457 - accuracy: 0.61 - ETA: 3s - loss: 0.6459 - accuracy: 0.61 - ETA: 3s - loss: 0.6457 - accuracy: 0.61 - ETA: 3s - loss: 0.6460 - accuracy: 0.61 - ETA: 3s - loss: 0.6463 - accuracy: 0.61 - ETA: 2s - loss: 0.6459 - accuracy: 0.61 - ETA: 2s - loss: 0.6457 - accuracy: 0.61 - ETA: 2s - loss: 0.6459 - accuracy: 0.61 - ETA: 2s - loss: 0.6462 - accuracy: 0.61 - ETA: 2s - loss: 0.6460 - accuracy: 0.61 - ETA: 2s - loss: 0.6459 - accuracy: 0.61 - ETA: 2s - loss: 0.6459 - accuracy: 0.61 - ETA: 2s - loss: 0.6461 - accuracy: 0.61 - ETA: 2s - loss: 0.6462 - accuracy: 0.61 - ETA: 1s - loss: 0.6462 - accuracy: 0.61 - ETA: 1s - loss: 0.6462 - accuracy: 0.61 - ETA: 1s - loss: 0.6461 - accuracy: 0.61 - ETA: 1s - loss: 0.6459 - accuracy: 0.61 - ETA: 1s - loss: 0.6458 - accuracy: 0.61 - ETA: 1s - loss: 0.6457 - accuracy: 0.61 - ETA: 1s - loss: 0.6459 - accuracy: 0.61 - ETA: 1s - loss: 0.6460 - accuracy: 0.61 - ETA: 1s - loss: 0.6458 - accuracy: 0.61 - ETA: 0s - loss: 0.6460 - accuracy: 0.61 - ETA: 0s - loss: 0.6463 - accuracy: 0.61 - ETA: 0s - loss: 0.6461 - accuracy: 0.61 - ETA: 0s - loss: 0.6460 - accuracy: 0.61 - ETA: 0s - loss: 0.6460 - accuracy: 0.61 - ETA: 0s - loss: 0.6459 - accuracy: 0.61 - ETA: 0s - loss: 0.6460 - accuracy: 0.61 - ETA: 0s - loss: 0.6461 - accuracy: 0.61 - ETA: 0s - loss: 0.6458 - accuracy: 0.61 - 9s 223us/step - loss: 0.6458 - accuracy: 0.6129\n",
      "\n",
      "Epoch 00032: loss improved from 0.65104 to 0.64577, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-32-0.6458.hdf5\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6491 - accuracy: 0.60 - ETA: 8s - loss: 0.6405 - accuracy: 0.62 - ETA: 8s - loss: 0.6374 - accuracy: 0.63 - ETA: 8s - loss: 0.6395 - accuracy: 0.63 - ETA: 8s - loss: 0.6402 - accuracy: 0.62 - ETA: 8s - loss: 0.6410 - accuracy: 0.62 - ETA: 8s - loss: 0.6421 - accuracy: 0.62 - ETA: 8s - loss: 0.6395 - accuracy: 0.62 - ETA: 8s - loss: 0.6393 - accuracy: 0.62 - ETA: 7s - loss: 0.6386 - accuracy: 0.62 - ETA: 7s - loss: 0.6381 - accuracy: 0.62 - ETA: 7s - loss: 0.6387 - accuracy: 0.62 - ETA: 7s - loss: 0.6382 - accuracy: 0.62 - ETA: 7s - loss: 0.6393 - accuracy: 0.62 - ETA: 7s - loss: 0.6392 - accuracy: 0.62 - ETA: 7s - loss: 0.6398 - accuracy: 0.62 - ETA: 7s - loss: 0.6409 - accuracy: 0.62 - ETA: 7s - loss: 0.6411 - accuracy: 0.62 - ETA: 6s - loss: 0.6411 - accuracy: 0.62 - ETA: 6s - loss: 0.6410 - accuracy: 0.62 - ETA: 6s - loss: 0.6409 - accuracy: 0.62 - ETA: 6s - loss: 0.6415 - accuracy: 0.61 - ETA: 6s - loss: 0.6417 - accuracy: 0.61 - ETA: 6s - loss: 0.6415 - accuracy: 0.62 - ETA: 6s - loss: 0.6411 - accuracy: 0.61 - ETA: 6s - loss: 0.6414 - accuracy: 0.61 - ETA: 5s - loss: 0.6411 - accuracy: 0.62 - ETA: 5s - loss: 0.6400 - accuracy: 0.62 - ETA: 5s - loss: 0.6405 - accuracy: 0.62 - ETA: 5s - loss: 0.6408 - accuracy: 0.62 - ETA: 5s - loss: 0.6410 - accuracy: 0.62 - ETA: 5s - loss: 0.6411 - accuracy: 0.61 - ETA: 5s - loss: 0.6414 - accuracy: 0.61 - ETA: 5s - loss: 0.6419 - accuracy: 0.62 - ETA: 5s - loss: 0.6418 - accuracy: 0.62 - ETA: 4s - loss: 0.6410 - accuracy: 0.62 - ETA: 4s - loss: 0.6409 - accuracy: 0.62 - ETA: 4s - loss: 0.6407 - accuracy: 0.62 - ETA: 4s - loss: 0.6409 - accuracy: 0.62 - ETA: 4s - loss: 0.6404 - accuracy: 0.62 - ETA: 4s - loss: 0.6406 - accuracy: 0.62 - ETA: 4s - loss: 0.6411 - accuracy: 0.62 - ETA: 4s - loss: 0.6410 - accuracy: 0.62 - ETA: 4s - loss: 0.6413 - accuracy: 0.62 - ETA: 3s - loss: 0.6412 - accuracy: 0.62 - ETA: 3s - loss: 0.6418 - accuracy: 0.61 - ETA: 3s - loss: 0.6415 - accuracy: 0.62 - ETA: 3s - loss: 0.6415 - accuracy: 0.62 - ETA: 3s - loss: 0.6414 - accuracy: 0.62 - ETA: 3s - loss: 0.6414 - accuracy: 0.62 - ETA: 3s - loss: 0.6416 - accuracy: 0.61 - ETA: 3s - loss: 0.6421 - accuracy: 0.61 - ETA: 3s - loss: 0.6424 - accuracy: 0.61 - ETA: 2s - loss: 0.6424 - accuracy: 0.61 - ETA: 2s - loss: 0.6426 - accuracy: 0.61 - ETA: 2s - loss: 0.6426 - accuracy: 0.61 - ETA: 2s - loss: 0.6426 - accuracy: 0.61 - ETA: 2s - loss: 0.6423 - accuracy: 0.61 - ETA: 2s - loss: 0.6428 - accuracy: 0.61 - ETA: 2s - loss: 0.6427 - accuracy: 0.61 - ETA: 2s - loss: 0.6426 - accuracy: 0.61 - ETA: 1s - loss: 0.6428 - accuracy: 0.61 - ETA: 1s - loss: 0.6430 - accuracy: 0.61 - ETA: 1s - loss: 0.6429 - accuracy: 0.61 - ETA: 1s - loss: 0.6429 - accuracy: 0.61 - ETA: 1s - loss: 0.6431 - accuracy: 0.61 - ETA: 1s - loss: 0.6435 - accuracy: 0.61 - ETA: 1s - loss: 0.6437 - accuracy: 0.61 - ETA: 1s - loss: 0.6440 - accuracy: 0.61 - ETA: 1s - loss: 0.6443 - accuracy: 0.61 - ETA: 0s - loss: 0.6445 - accuracy: 0.61 - ETA: 0s - loss: 0.6443 - accuracy: 0.61 - ETA: 0s - loss: 0.6443 - accuracy: 0.61 - ETA: 0s - loss: 0.6440 - accuracy: 0.61 - ETA: 0s - loss: 0.6440 - accuracy: 0.61 - ETA: 0s - loss: 0.6440 - accuracy: 0.61 - ETA: 0s - loss: 0.6438 - accuracy: 0.61 - ETA: 0s - loss: 0.6439 - accuracy: 0.61 - 9s 228us/step - loss: 0.6438 - accuracy: 0.6157\n",
      "\n",
      "Epoch 00033: loss improved from 0.64577 to 0.64383, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-33-0.6438.hdf5\n",
      "Epoch 34/50\n",
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6424 - accuracy: 0.61 - ETA: 8s - loss: 0.6346 - accuracy: 0.62 - ETA: 8s - loss: 0.6410 - accuracy: 0.60 - ETA: 8s - loss: 0.6382 - accuracy: 0.61 - ETA: 8s - loss: 0.6371 - accuracy: 0.61 - ETA: 8s - loss: 0.6386 - accuracy: 0.61 - ETA: 8s - loss: 0.6395 - accuracy: 0.61 - ETA: 8s - loss: 0.6416 - accuracy: 0.61 - ETA: 8s - loss: 0.6406 - accuracy: 0.62 - ETA: 8s - loss: 0.6395 - accuracy: 0.62 - ETA: 8s - loss: 0.6395 - accuracy: 0.62 - ETA: 8s - loss: 0.6376 - accuracy: 0.62 - ETA: 7s - loss: 0.6372 - accuracy: 0.62 - ETA: 7s - loss: 0.6370 - accuracy: 0.62 - ETA: 7s - loss: 0.6375 - accuracy: 0.62 - ETA: 7s - loss: 0.6369 - accuracy: 0.62 - ETA: 7s - loss: 0.6356 - accuracy: 0.62 - ETA: 7s - loss: 0.6356 - accuracy: 0.62 - ETA: 7s - loss: 0.6356 - accuracy: 0.62 - ETA: 7s - loss: 0.6360 - accuracy: 0.62 - ETA: 7s - loss: 0.6358 - accuracy: 0.62 - ETA: 7s - loss: 0.6359 - accuracy: 0.62 - ETA: 7s - loss: 0.6355 - accuracy: 0.62 - ETA: 7s - loss: 0.6360 - accuracy: 0.62 - ETA: 7s - loss: 0.6369 - accuracy: 0.61 - ETA: 6s - loss: 0.6368 - accuracy: 0.61 - ETA: 6s - loss: 0.6368 - accuracy: 0.61 - ETA: 6s - loss: 0.6368 - accuracy: 0.61 - ETA: 6s - loss: 0.6366 - accuracy: 0.62 - ETA: 6s - loss: 0.6371 - accuracy: 0.62 - ETA: 6s - loss: 0.6367 - accuracy: 0.62 - ETA: 6s - loss: 0.6372 - accuracy: 0.62 - ETA: 6s - loss: 0.6371 - accuracy: 0.61 - ETA: 5s - loss: 0.6371 - accuracy: 0.61 - ETA: 5s - loss: 0.6370 - accuracy: 0.61 - ETA: 5s - loss: 0.6371 - accuracy: 0.62 - ETA: 5s - loss: 0.6379 - accuracy: 0.61 - ETA: 5s - loss: 0.6381 - accuracy: 0.61 - ETA: 5s - loss: 0.6380 - accuracy: 0.61 - ETA: 5s - loss: 0.6385 - accuracy: 0.61 - ETA: 5s - loss: 0.6385 - accuracy: 0.61 - ETA: 4s - loss: 0.6383 - accuracy: 0.61 - ETA: 4s - loss: 0.6379 - accuracy: 0.61 - ETA: 4s - loss: 0.6377 - accuracy: 0.61 - ETA: 4s - loss: 0.6376 - accuracy: 0.61 - ETA: 4s - loss: 0.6379 - accuracy: 0.61 - ETA: 4s - loss: 0.6382 - accuracy: 0.61 - ETA: 4s - loss: 0.6380 - accuracy: 0.61 - ETA: 3s - loss: 0.6383 - accuracy: 0.61 - ETA: 3s - loss: 0.6384 - accuracy: 0.61 - ETA: 3s - loss: 0.6390 - accuracy: 0.61 - ETA: 3s - loss: 0.6396 - accuracy: 0.61 - ETA: 3s - loss: 0.6394 - accuracy: 0.61 - ETA: 3s - loss: 0.6397 - accuracy: 0.61 - ETA: 3s - loss: 0.6395 - accuracy: 0.61 - ETA: 2s - loss: 0.6399 - accuracy: 0.61 - ETA: 2s - loss: 0.6399 - accuracy: 0.61 - ETA: 2s - loss: 0.6401 - accuracy: 0.61 - ETA: 2s - loss: 0.6401 - accuracy: 0.61 - ETA: 2s - loss: 0.6401 - accuracy: 0.61 - ETA: 2s - loss: 0.6399 - accuracy: 0.61 - ETA: 2s - loss: 0.6400 - accuracy: 0.61 - ETA: 2s - loss: 0.6400 - accuracy: 0.61 - ETA: 1s - loss: 0.6404 - accuracy: 0.61 - ETA: 1s - loss: 0.6405 - accuracy: 0.61 - ETA: 1s - loss: 0.6409 - accuracy: 0.61 - ETA: 1s - loss: 0.6408 - accuracy: 0.61 - ETA: 1s - loss: 0.6406 - accuracy: 0.61 - ETA: 1s - loss: 0.6408 - accuracy: 0.61 - ETA: 1s - loss: 0.6409 - accuracy: 0.61 - ETA: 0s - loss: 0.6408 - accuracy: 0.61 - ETA: 0s - loss: 0.6408 - accuracy: 0.61 - ETA: 0s - loss: 0.6406 - accuracy: 0.61 - ETA: 0s - loss: 0.6407 - accuracy: 0.61 - ETA: 0s - loss: 0.6403 - accuracy: 0.61 - ETA: 0s - loss: 0.6404 - accuracy: 0.61 - ETA: 0s - loss: 0.6406 - accuracy: 0.61 - ETA: 0s - loss: 0.6407 - accuracy: 0.61 - 10s 249us/step - loss: 0.6410 - accuracy: 0.6147\n",
      "\n",
      "Epoch 00034: loss improved from 0.64383 to 0.64103, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-34-0.6410.hdf5\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6432 - accuracy: 0.58 - ETA: 8s - loss: 0.6337 - accuracy: 0.62 - ETA: 8s - loss: 0.6301 - accuracy: 0.63 - ETA: 8s - loss: 0.6278 - accuracy: 0.63 - ETA: 8s - loss: 0.6273 - accuracy: 0.63 - ETA: 8s - loss: 0.6276 - accuracy: 0.64 - ETA: 8s - loss: 0.6299 - accuracy: 0.63 - ETA: 7s - loss: 0.6305 - accuracy: 0.63 - ETA: 7s - loss: 0.6307 - accuracy: 0.63 - ETA: 7s - loss: 0.6311 - accuracy: 0.63 - ETA: 7s - loss: 0.6321 - accuracy: 0.63 - ETA: 7s - loss: 0.6316 - accuracy: 0.63 - ETA: 7s - loss: 0.6304 - accuracy: 0.63 - ETA: 7s - loss: 0.6303 - accuracy: 0.63 - ETA: 7s - loss: 0.6306 - accuracy: 0.63 - ETA: 7s - loss: 0.6299 - accuracy: 0.63 - ETA: 6s - loss: 0.6302 - accuracy: 0.62 - ETA: 6s - loss: 0.6302 - accuracy: 0.63 - ETA: 6s - loss: 0.6303 - accuracy: 0.63 - ETA: 6s - loss: 0.6295 - accuracy: 0.63 - ETA: 6s - loss: 0.6302 - accuracy: 0.63 - ETA: 6s - loss: 0.6304 - accuracy: 0.63 - ETA: 6s - loss: 0.6306 - accuracy: 0.63 - ETA: 6s - loss: 0.6303 - accuracy: 0.63 - ETA: 6s - loss: 0.6309 - accuracy: 0.63 - ETA: 5s - loss: 0.6315 - accuracy: 0.63 - ETA: 5s - loss: 0.6322 - accuracy: 0.62 - ETA: 5s - loss: 0.6319 - accuracy: 0.62 - ETA: 5s - loss: 0.6316 - accuracy: 0.63 - ETA: 5s - loss: 0.6318 - accuracy: 0.62 - ETA: 5s - loss: 0.6315 - accuracy: 0.62 - ETA: 5s - loss: 0.6314 - accuracy: 0.63 - ETA: 5s - loss: 0.6315 - accuracy: 0.63 - ETA: 5s - loss: 0.6316 - accuracy: 0.63 - ETA: 4s - loss: 0.6315 - accuracy: 0.62 - ETA: 4s - loss: 0.6322 - accuracy: 0.62 - ETA: 4s - loss: 0.6326 - accuracy: 0.62 - ETA: 4s - loss: 0.6326 - accuracy: 0.62 - ETA: 4s - loss: 0.6323 - accuracy: 0.62 - ETA: 4s - loss: 0.6322 - accuracy: 0.62 - ETA: 4s - loss: 0.6320 - accuracy: 0.62 - ETA: 4s - loss: 0.6320 - accuracy: 0.62 - ETA: 4s - loss: 0.6323 - accuracy: 0.62 - ETA: 3s - loss: 0.6327 - accuracy: 0.62 - ETA: 3s - loss: 0.6328 - accuracy: 0.62 - ETA: 3s - loss: 0.6329 - accuracy: 0.62 - ETA: 3s - loss: 0.6326 - accuracy: 0.62 - ETA: 3s - loss: 0.6330 - accuracy: 0.62 - ETA: 3s - loss: 0.6334 - accuracy: 0.62 - ETA: 3s - loss: 0.6334 - accuracy: 0.62 - ETA: 3s - loss: 0.6340 - accuracy: 0.62 - ETA: 2s - loss: 0.6341 - accuracy: 0.62 - ETA: 2s - loss: 0.6341 - accuracy: 0.62 - ETA: 2s - loss: 0.6341 - accuracy: 0.62 - ETA: 2s - loss: 0.6343 - accuracy: 0.62 - ETA: 2s - loss: 0.6342 - accuracy: 0.62 - ETA: 2s - loss: 0.6341 - accuracy: 0.62 - ETA: 2s - loss: 0.6339 - accuracy: 0.62 - ETA: 2s - loss: 0.6337 - accuracy: 0.62 - ETA: 2s - loss: 0.6340 - accuracy: 0.62 - ETA: 1s - loss: 0.6337 - accuracy: 0.62 - ETA: 1s - loss: 0.6336 - accuracy: 0.62 - ETA: 1s - loss: 0.6337 - accuracy: 0.62 - ETA: 1s - loss: 0.6337 - accuracy: 0.62 - ETA: 1s - loss: 0.6337 - accuracy: 0.62 - ETA: 1s - loss: 0.6337 - accuracy: 0.62 - ETA: 1s - loss: 0.6341 - accuracy: 0.62 - ETA: 1s - loss: 0.6341 - accuracy: 0.62 - ETA: 1s - loss: 0.6343 - accuracy: 0.62 - ETA: 0s - loss: 0.6345 - accuracy: 0.62 - ETA: 0s - loss: 0.6344 - accuracy: 0.62 - ETA: 0s - loss: 0.6343 - accuracy: 0.62 - ETA: 0s - loss: 0.6345 - accuracy: 0.62 - ETA: 0s - loss: 0.6347 - accuracy: 0.62 - ETA: 0s - loss: 0.6346 - accuracy: 0.62 - ETA: 0s - loss: 0.6351 - accuracy: 0.62 - ETA: 0s - loss: 0.6354 - accuracy: 0.62 - ETA: 0s - loss: 0.6353 - accuracy: 0.62 - 9s 221us/step - loss: 0.6354 - accuracy: 0.6233\n",
      "\n",
      "Epoch 00035: loss improved from 0.64103 to 0.63537, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-35-0.6354.hdf5\n",
      "Epoch 36/50\n",
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6331 - accuracy: 0.63 - ETA: 8s - loss: 0.6365 - accuracy: 0.62 - ETA: 8s - loss: 0.6439 - accuracy: 0.60 - ETA: 8s - loss: 0.6340 - accuracy: 0.62 - ETA: 8s - loss: 0.6313 - accuracy: 0.62 - ETA: 8s - loss: 0.6318 - accuracy: 0.62 - ETA: 7s - loss: 0.6379 - accuracy: 0.62 - ETA: 7s - loss: 0.6406 - accuracy: 0.61 - ETA: 7s - loss: 0.6380 - accuracy: 0.62 - ETA: 7s - loss: 0.6380 - accuracy: 0.62 - ETA: 7s - loss: 0.6386 - accuracy: 0.62 - ETA: 7s - loss: 0.6376 - accuracy: 0.62 - ETA: 7s - loss: 0.6368 - accuracy: 0.62 - ETA: 7s - loss: 0.6370 - accuracy: 0.62 - ETA: 7s - loss: 0.6370 - accuracy: 0.62 - ETA: 6s - loss: 0.6378 - accuracy: 0.62 - ETA: 6s - loss: 0.6374 - accuracy: 0.62 - ETA: 6s - loss: 0.6373 - accuracy: 0.62 - ETA: 6s - loss: 0.6380 - accuracy: 0.62 - ETA: 6s - loss: 0.6372 - accuracy: 0.62 - ETA: 6s - loss: 0.6372 - accuracy: 0.62 - ETA: 6s - loss: 0.6366 - accuracy: 0.62 - ETA: 6s - loss: 0.6360 - accuracy: 0.62 - ETA: 6s - loss: 0.6369 - accuracy: 0.62 - ETA: 6s - loss: 0.6370 - accuracy: 0.62 - ETA: 5s - loss: 0.6365 - accuracy: 0.62 - ETA: 5s - loss: 0.6365 - accuracy: 0.62 - ETA: 5s - loss: 0.6364 - accuracy: 0.62 - ETA: 5s - loss: 0.6362 - accuracy: 0.62 - ETA: 5s - loss: 0.6365 - accuracy: 0.62 - ETA: 5s - loss: 0.6360 - accuracy: 0.62 - ETA: 5s - loss: 0.6362 - accuracy: 0.62 - ETA: 5s - loss: 0.6360 - accuracy: 0.62 - ETA: 5s - loss: 0.6353 - accuracy: 0.62 - ETA: 4s - loss: 0.6351 - accuracy: 0.62 - ETA: 4s - loss: 0.6351 - accuracy: 0.62 - ETA: 4s - loss: 0.6352 - accuracy: 0.62 - ETA: 4s - loss: 0.6354 - accuracy: 0.62 - ETA: 4s - loss: 0.6351 - accuracy: 0.62 - ETA: 4s - loss: 0.6346 - accuracy: 0.62 - ETA: 4s - loss: 0.6345 - accuracy: 0.62 - ETA: 4s - loss: 0.6349 - accuracy: 0.62 - ETA: 3s - loss: 0.6344 - accuracy: 0.62 - ETA: 3s - loss: 0.6340 - accuracy: 0.62 - ETA: 3s - loss: 0.6339 - accuracy: 0.62 - ETA: 3s - loss: 0.6342 - accuracy: 0.62 - ETA: 3s - loss: 0.6342 - accuracy: 0.62 - ETA: 3s - loss: 0.6343 - accuracy: 0.62 - ETA: 3s - loss: 0.6347 - accuracy: 0.62 - ETA: 3s - loss: 0.6348 - accuracy: 0.62 - ETA: 3s - loss: 0.6345 - accuracy: 0.62 - ETA: 2s - loss: 0.6347 - accuracy: 0.62 - ETA: 2s - loss: 0.6345 - accuracy: 0.62 - ETA: 2s - loss: 0.6346 - accuracy: 0.62 - ETA: 2s - loss: 0.6344 - accuracy: 0.62 - ETA: 2s - loss: 0.6346 - accuracy: 0.62 - ETA: 2s - loss: 0.6347 - accuracy: 0.62 - ETA: 2s - loss: 0.6348 - accuracy: 0.62 - ETA: 2s - loss: 0.6350 - accuracy: 0.62 - ETA: 2s - loss: 0.6347 - accuracy: 0.62 - ETA: 1s - loss: 0.6349 - accuracy: 0.62 - ETA: 1s - loss: 0.6348 - accuracy: 0.62 - ETA: 1s - loss: 0.6348 - accuracy: 0.62 - ETA: 1s - loss: 0.6347 - accuracy: 0.62 - ETA: 1s - loss: 0.6346 - accuracy: 0.62 - ETA: 1s - loss: 0.6345 - accuracy: 0.62 - ETA: 1s - loss: 0.6347 - accuracy: 0.62 - ETA: 1s - loss: 0.6345 - accuracy: 0.62 - ETA: 1s - loss: 0.6347 - accuracy: 0.62 - ETA: 0s - loss: 0.6349 - accuracy: 0.62 - ETA: 0s - loss: 0.6349 - accuracy: 0.62 - ETA: 0s - loss: 0.6349 - accuracy: 0.62 - ETA: 0s - loss: 0.6347 - accuracy: 0.62 - ETA: 0s - loss: 0.6346 - accuracy: 0.62 - ETA: 0s - loss: 0.6347 - accuracy: 0.62 - ETA: 0s - loss: 0.6345 - accuracy: 0.62 - ETA: 0s - loss: 0.6345 - accuracy: 0.62 - ETA: 0s - loss: 0.6347 - accuracy: 0.62 - 9s 216us/step - loss: 0.6347 - accuracy: 0.6231\n",
      "\n",
      "Epoch 00036: loss improved from 0.63537 to 0.63471, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-36-0.6347.hdf5\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6338 - accuracy: 0.61 - ETA: 7s - loss: 0.6350 - accuracy: 0.61 - ETA: 7s - loss: 0.6233 - accuracy: 0.62 - ETA: 7s - loss: 0.6228 - accuracy: 0.62 - ETA: 7s - loss: 0.6191 - accuracy: 0.62 - ETA: 7s - loss: 0.6245 - accuracy: 0.62 - ETA: 7s - loss: 0.6242 - accuracy: 0.62 - ETA: 7s - loss: 0.6234 - accuracy: 0.62 - ETA: 7s - loss: 0.6230 - accuracy: 0.62 - ETA: 7s - loss: 0.6231 - accuracy: 0.62 - ETA: 7s - loss: 0.6233 - accuracy: 0.63 - ETA: 7s - loss: 0.6223 - accuracy: 0.63 - ETA: 7s - loss: 0.6245 - accuracy: 0.62 - ETA: 7s - loss: 0.6244 - accuracy: 0.63 - ETA: 7s - loss: 0.6255 - accuracy: 0.63 - ETA: 6s - loss: 0.6242 - accuracy: 0.63 - ETA: 6s - loss: 0.6249 - accuracy: 0.63 - ETA: 6s - loss: 0.6250 - accuracy: 0.62 - ETA: 6s - loss: 0.6257 - accuracy: 0.63 - ETA: 6s - loss: 0.6266 - accuracy: 0.62 - ETA: 6s - loss: 0.6268 - accuracy: 0.63 - ETA: 6s - loss: 0.6262 - accuracy: 0.63 - ETA: 6s - loss: 0.6264 - accuracy: 0.63 - ETA: 5s - loss: 0.6270 - accuracy: 0.63 - ETA: 5s - loss: 0.6266 - accuracy: 0.63 - ETA: 5s - loss: 0.6260 - accuracy: 0.63 - ETA: 5s - loss: 0.6264 - accuracy: 0.63 - ETA: 5s - loss: 0.6270 - accuracy: 0.62 - ETA: 5s - loss: 0.6275 - accuracy: 0.62 - ETA: 5s - loss: 0.6276 - accuracy: 0.62 - ETA: 5s - loss: 0.6277 - accuracy: 0.62 - ETA: 5s - loss: 0.6275 - accuracy: 0.62 - ETA: 4s - loss: 0.6280 - accuracy: 0.62 - ETA: 4s - loss: 0.6290 - accuracy: 0.62 - ETA: 4s - loss: 0.6294 - accuracy: 0.62 - ETA: 4s - loss: 0.6291 - accuracy: 0.62 - ETA: 4s - loss: 0.6283 - accuracy: 0.62 - ETA: 4s - loss: 0.6285 - accuracy: 0.62 - ETA: 4s - loss: 0.6283 - accuracy: 0.62 - ETA: 4s - loss: 0.6284 - accuracy: 0.62 - ETA: 4s - loss: 0.6287 - accuracy: 0.62 - ETA: 4s - loss: 0.6290 - accuracy: 0.62 - ETA: 3s - loss: 0.6294 - accuracy: 0.62 - ETA: 3s - loss: 0.6296 - accuracy: 0.62 - ETA: 3s - loss: 0.6294 - accuracy: 0.62 - ETA: 3s - loss: 0.6295 - accuracy: 0.62 - ETA: 3s - loss: 0.6294 - accuracy: 0.62 - ETA: 3s - loss: 0.6292 - accuracy: 0.62 - ETA: 3s - loss: 0.6295 - accuracy: 0.62 - ETA: 3s - loss: 0.6295 - accuracy: 0.62 - ETA: 3s - loss: 0.6296 - accuracy: 0.62 - ETA: 3s - loss: 0.6296 - accuracy: 0.62 - ETA: 2s - loss: 0.6295 - accuracy: 0.62 - ETA: 2s - loss: 0.6300 - accuracy: 0.62 - ETA: 2s - loss: 0.6306 - accuracy: 0.62 - ETA: 2s - loss: 0.6305 - accuracy: 0.62 - ETA: 2s - loss: 0.6303 - accuracy: 0.62 - ETA: 2s - loss: 0.6305 - accuracy: 0.62 - ETA: 2s - loss: 0.6308 - accuracy: 0.62 - ETA: 2s - loss: 0.6308 - accuracy: 0.62 - ETA: 2s - loss: 0.6308 - accuracy: 0.62 - ETA: 1s - loss: 0.6310 - accuracy: 0.62 - ETA: 1s - loss: 0.6310 - accuracy: 0.62 - ETA: 1s - loss: 0.6312 - accuracy: 0.62 - ETA: 1s - loss: 0.6313 - accuracy: 0.62 - ETA: 1s - loss: 0.6313 - accuracy: 0.62 - ETA: 1s - loss: 0.6309 - accuracy: 0.62 - ETA: 1s - loss: 0.6307 - accuracy: 0.62 - ETA: 1s - loss: 0.6310 - accuracy: 0.62 - ETA: 0s - loss: 0.6308 - accuracy: 0.62 - ETA: 0s - loss: 0.6309 - accuracy: 0.62 - ETA: 0s - loss: 0.6305 - accuracy: 0.62 - ETA: 0s - loss: 0.6307 - accuracy: 0.62 - ETA: 0s - loss: 0.6307 - accuracy: 0.62 - ETA: 0s - loss: 0.6307 - accuracy: 0.62 - ETA: 0s - loss: 0.6308 - accuracy: 0.62 - ETA: 0s - loss: 0.6307 - accuracy: 0.62 - ETA: 0s - loss: 0.6305 - accuracy: 0.62 - 9s 224us/step - loss: 0.6306 - accuracy: 0.6274\n",
      "\n",
      "Epoch 00037: loss improved from 0.63471 to 0.63058, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-37-0.6306.hdf5\n",
      "Epoch 38/50\n",
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6233 - accuracy: 0.60 - ETA: 8s - loss: 0.6148 - accuracy: 0.62 - ETA: 8s - loss: 0.6113 - accuracy: 0.64 - ETA: 8s - loss: 0.6125 - accuracy: 0.64 - ETA: 8s - loss: 0.6128 - accuracy: 0.64 - ETA: 8s - loss: 0.6133 - accuracy: 0.64 - ETA: 8s - loss: 0.6155 - accuracy: 0.64 - ETA: 8s - loss: 0.6154 - accuracy: 0.64 - ETA: 8s - loss: 0.6168 - accuracy: 0.64 - ETA: 7s - loss: 0.6198 - accuracy: 0.64 - ETA: 7s - loss: 0.6192 - accuracy: 0.64 - ETA: 7s - loss: 0.6191 - accuracy: 0.63 - ETA: 7s - loss: 0.6197 - accuracy: 0.63 - ETA: 7s - loss: 0.6195 - accuracy: 0.63 - ETA: 7s - loss: 0.6208 - accuracy: 0.63 - ETA: 7s - loss: 0.6224 - accuracy: 0.63 - ETA: 7s - loss: 0.6228 - accuracy: 0.63 - ETA: 6s - loss: 0.6248 - accuracy: 0.63 - ETA: 6s - loss: 0.6246 - accuracy: 0.63 - ETA: 6s - loss: 0.6245 - accuracy: 0.63 - ETA: 6s - loss: 0.6244 - accuracy: 0.63 - ETA: 6s - loss: 0.6241 - accuracy: 0.63 - ETA: 6s - loss: 0.6228 - accuracy: 0.63 - ETA: 6s - loss: 0.6225 - accuracy: 0.63 - ETA: 6s - loss: 0.6237 - accuracy: 0.63 - ETA: 6s - loss: 0.6234 - accuracy: 0.63 - ETA: 5s - loss: 0.6236 - accuracy: 0.63 - ETA: 5s - loss: 0.6239 - accuracy: 0.63 - ETA: 5s - loss: 0.6240 - accuracy: 0.63 - ETA: 5s - loss: 0.6251 - accuracy: 0.63 - ETA: 5s - loss: 0.6255 - accuracy: 0.63 - ETA: 5s - loss: 0.6249 - accuracy: 0.63 - ETA: 5s - loss: 0.6249 - accuracy: 0.63 - ETA: 5s - loss: 0.6253 - accuracy: 0.63 - ETA: 4s - loss: 0.6252 - accuracy: 0.63 - ETA: 4s - loss: 0.6255 - accuracy: 0.63 - ETA: 4s - loss: 0.6253 - accuracy: 0.63 - ETA: 4s - loss: 0.6253 - accuracy: 0.63 - ETA: 4s - loss: 0.6260 - accuracy: 0.63 - ETA: 4s - loss: 0.6269 - accuracy: 0.62 - ETA: 4s - loss: 0.6266 - accuracy: 0.63 - ETA: 4s - loss: 0.6265 - accuracy: 0.63 - ETA: 4s - loss: 0.6262 - accuracy: 0.63 - ETA: 3s - loss: 0.6259 - accuracy: 0.63 - ETA: 3s - loss: 0.6257 - accuracy: 0.63 - ETA: 3s - loss: 0.6261 - accuracy: 0.63 - ETA: 3s - loss: 0.6265 - accuracy: 0.63 - ETA: 3s - loss: 0.6265 - accuracy: 0.63 - ETA: 3s - loss: 0.6267 - accuracy: 0.63 - ETA: 3s - loss: 0.6266 - accuracy: 0.63 - ETA: 3s - loss: 0.6269 - accuracy: 0.63 - ETA: 3s - loss: 0.6271 - accuracy: 0.62 - ETA: 2s - loss: 0.6274 - accuracy: 0.62 - ETA: 2s - loss: 0.6275 - accuracy: 0.62 - ETA: 2s - loss: 0.6271 - accuracy: 0.62 - ETA: 2s - loss: 0.6269 - accuracy: 0.62 - ETA: 2s - loss: 0.6271 - accuracy: 0.62 - ETA: 2s - loss: 0.6272 - accuracy: 0.62 - ETA: 2s - loss: 0.6273 - accuracy: 0.62 - ETA: 2s - loss: 0.6273 - accuracy: 0.62 - ETA: 1s - loss: 0.6273 - accuracy: 0.62 - ETA: 1s - loss: 0.6272 - accuracy: 0.62 - ETA: 1s - loss: 0.6271 - accuracy: 0.62 - ETA: 1s - loss: 0.6271 - accuracy: 0.62 - ETA: 1s - loss: 0.6275 - accuracy: 0.62 - ETA: 1s - loss: 0.6277 - accuracy: 0.62 - ETA: 1s - loss: 0.6281 - accuracy: 0.62 - ETA: 1s - loss: 0.6280 - accuracy: 0.62 - ETA: 1s - loss: 0.6281 - accuracy: 0.62 - ETA: 0s - loss: 0.6277 - accuracy: 0.62 - ETA: 0s - loss: 0.6275 - accuracy: 0.62 - ETA: 0s - loss: 0.6275 - accuracy: 0.62 - ETA: 0s - loss: 0.6277 - accuracy: 0.62 - ETA: 0s - loss: 0.6277 - accuracy: 0.62 - ETA: 0s - loss: 0.6277 - accuracy: 0.62 - ETA: 0s - loss: 0.6282 - accuracy: 0.62 - ETA: 0s - loss: 0.6280 - accuracy: 0.62 - ETA: 0s - loss: 0.6278 - accuracy: 0.62 - 9s 218us/step - loss: 0.6278 - accuracy: 0.6281\n",
      "\n",
      "Epoch 00038: loss improved from 0.63058 to 0.62785, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-38-0.6278.hdf5\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6168 - accuracy: 0.69 - ETA: 7s - loss: 0.6299 - accuracy: 0.65 - ETA: 7s - loss: 0.6280 - accuracy: 0.64 - ETA: 8s - loss: 0.6264 - accuracy: 0.65 - ETA: 7s - loss: 0.6246 - accuracy: 0.64 - ETA: 7s - loss: 0.6240 - accuracy: 0.64 - ETA: 7s - loss: 0.6220 - accuracy: 0.64 - ETA: 7s - loss: 0.6190 - accuracy: 0.64 - ETA: 7s - loss: 0.6180 - accuracy: 0.64 - ETA: 7s - loss: 0.6191 - accuracy: 0.64 - ETA: 7s - loss: 0.6200 - accuracy: 0.64 - ETA: 7s - loss: 0.6199 - accuracy: 0.64 - ETA: 7s - loss: 0.6190 - accuracy: 0.64 - ETA: 7s - loss: 0.6196 - accuracy: 0.64 - ETA: 6s - loss: 0.6201 - accuracy: 0.64 - ETA: 6s - loss: 0.6197 - accuracy: 0.64 - ETA: 6s - loss: 0.6202 - accuracy: 0.64 - ETA: 6s - loss: 0.6204 - accuracy: 0.64 - ETA: 6s - loss: 0.6199 - accuracy: 0.64 - ETA: 6s - loss: 0.6197 - accuracy: 0.64 - ETA: 6s - loss: 0.6201 - accuracy: 0.64 - ETA: 6s - loss: 0.6199 - accuracy: 0.64 - ETA: 6s - loss: 0.6194 - accuracy: 0.64 - ETA: 5s - loss: 0.6196 - accuracy: 0.64 - ETA: 5s - loss: 0.6201 - accuracy: 0.64 - ETA: 5s - loss: 0.6201 - accuracy: 0.64 - ETA: 5s - loss: 0.6202 - accuracy: 0.64 - ETA: 5s - loss: 0.6200 - accuracy: 0.64 - ETA: 5s - loss: 0.6204 - accuracy: 0.64 - ETA: 5s - loss: 0.6195 - accuracy: 0.64 - ETA: 5s - loss: 0.6195 - accuracy: 0.64 - ETA: 5s - loss: 0.6202 - accuracy: 0.64 - ETA: 4s - loss: 0.6201 - accuracy: 0.64 - ETA: 4s - loss: 0.6191 - accuracy: 0.64 - ETA: 4s - loss: 0.6195 - accuracy: 0.64 - ETA: 4s - loss: 0.6199 - accuracy: 0.64 - ETA: 4s - loss: 0.6200 - accuracy: 0.64 - ETA: 4s - loss: 0.6207 - accuracy: 0.64 - ETA: 4s - loss: 0.6207 - accuracy: 0.64 - ETA: 4s - loss: 0.6210 - accuracy: 0.63 - ETA: 4s - loss: 0.6216 - accuracy: 0.63 - ETA: 3s - loss: 0.6219 - accuracy: 0.63 - ETA: 3s - loss: 0.6222 - accuracy: 0.63 - ETA: 3s - loss: 0.6223 - accuracy: 0.63 - ETA: 3s - loss: 0.6229 - accuracy: 0.63 - ETA: 3s - loss: 0.6228 - accuracy: 0.63 - ETA: 3s - loss: 0.6230 - accuracy: 0.63 - ETA: 3s - loss: 0.6227 - accuracy: 0.63 - ETA: 3s - loss: 0.6224 - accuracy: 0.63 - ETA: 3s - loss: 0.6223 - accuracy: 0.63 - ETA: 3s - loss: 0.6226 - accuracy: 0.63 - ETA: 2s - loss: 0.6227 - accuracy: 0.63 - ETA: 2s - loss: 0.6228 - accuracy: 0.63 - ETA: 2s - loss: 0.6231 - accuracy: 0.63 - ETA: 2s - loss: 0.6229 - accuracy: 0.63 - ETA: 2s - loss: 0.6234 - accuracy: 0.63 - ETA: 2s - loss: 0.6239 - accuracy: 0.63 - ETA: 2s - loss: 0.6238 - accuracy: 0.63 - ETA: 2s - loss: 0.6241 - accuracy: 0.63 - ETA: 2s - loss: 0.6240 - accuracy: 0.63 - ETA: 1s - loss: 0.6242 - accuracy: 0.63 - ETA: 1s - loss: 0.6242 - accuracy: 0.63 - ETA: 1s - loss: 0.6240 - accuracy: 0.63 - ETA: 1s - loss: 0.6241 - accuracy: 0.63 - ETA: 1s - loss: 0.6242 - accuracy: 0.63 - ETA: 1s - loss: 0.6243 - accuracy: 0.63 - ETA: 1s - loss: 0.6246 - accuracy: 0.63 - ETA: 1s - loss: 0.6245 - accuracy: 0.63 - ETA: 1s - loss: 0.6241 - accuracy: 0.63 - ETA: 0s - loss: 0.6245 - accuracy: 0.63 - ETA: 0s - loss: 0.6248 - accuracy: 0.63 - ETA: 0s - loss: 0.6249 - accuracy: 0.63 - ETA: 0s - loss: 0.6254 - accuracy: 0.63 - ETA: 0s - loss: 0.6253 - accuracy: 0.63 - ETA: 0s - loss: 0.6251 - accuracy: 0.63 - ETA: 0s - loss: 0.6252 - accuracy: 0.63 - ETA: 0s - loss: 0.6253 - accuracy: 0.63 - ETA: 0s - loss: 0.6252 - accuracy: 0.63 - 9s 212us/step - loss: 0.6253 - accuracy: 0.6335\n",
      "\n",
      "Epoch 00039: loss improved from 0.62785 to 0.62527, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-39-0.6253.hdf5\n",
      "Epoch 40/50\n",
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6079 - accuracy: 0.68 - ETA: 8s - loss: 0.6244 - accuracy: 0.64 - ETA: 8s - loss: 0.6214 - accuracy: 0.64 - ETA: 8s - loss: 0.6191 - accuracy: 0.64 - ETA: 8s - loss: 0.6200 - accuracy: 0.64 - ETA: 8s - loss: 0.6214 - accuracy: 0.63 - ETA: 8s - loss: 0.6169 - accuracy: 0.64 - ETA: 8s - loss: 0.6173 - accuracy: 0.64 - ETA: 8s - loss: 0.6199 - accuracy: 0.63 - ETA: 8s - loss: 0.6219 - accuracy: 0.63 - ETA: 7s - loss: 0.6214 - accuracy: 0.63 - ETA: 7s - loss: 0.6194 - accuracy: 0.63 - ETA: 7s - loss: 0.6190 - accuracy: 0.63 - ETA: 7s - loss: 0.6180 - accuracy: 0.63 - ETA: 7s - loss: 0.6182 - accuracy: 0.64 - ETA: 7s - loss: 0.6179 - accuracy: 0.64 - ETA: 7s - loss: 0.6182 - accuracy: 0.64 - ETA: 7s - loss: 0.6183 - accuracy: 0.64 - ETA: 7s - loss: 0.6185 - accuracy: 0.63 - ETA: 6s - loss: 0.6185 - accuracy: 0.63 - ETA: 6s - loss: 0.6184 - accuracy: 0.64 - ETA: 6s - loss: 0.6197 - accuracy: 0.63 - ETA: 6s - loss: 0.6182 - accuracy: 0.63 - ETA: 6s - loss: 0.6187 - accuracy: 0.63 - ETA: 6s - loss: 0.6185 - accuracy: 0.64 - ETA: 6s - loss: 0.6192 - accuracy: 0.63 - ETA: 6s - loss: 0.6186 - accuracy: 0.63 - ETA: 5s - loss: 0.6192 - accuracy: 0.63 - ETA: 5s - loss: 0.6204 - accuracy: 0.63 - ETA: 5s - loss: 0.6200 - accuracy: 0.63 - ETA: 5s - loss: 0.6190 - accuracy: 0.63 - ETA: 5s - loss: 0.6185 - accuracy: 0.64 - ETA: 5s - loss: 0.6185 - accuracy: 0.64 - ETA: 5s - loss: 0.6187 - accuracy: 0.64 - ETA: 5s - loss: 0.6186 - accuracy: 0.64 - ETA: 5s - loss: 0.6185 - accuracy: 0.64 - ETA: 4s - loss: 0.6180 - accuracy: 0.64 - ETA: 4s - loss: 0.6175 - accuracy: 0.64 - ETA: 4s - loss: 0.6176 - accuracy: 0.64 - ETA: 4s - loss: 0.6175 - accuracy: 0.64 - ETA: 4s - loss: 0.6172 - accuracy: 0.64 - ETA: 4s - loss: 0.6174 - accuracy: 0.64 - ETA: 4s - loss: 0.6177 - accuracy: 0.64 - ETA: 4s - loss: 0.6179 - accuracy: 0.64 - ETA: 3s - loss: 0.6178 - accuracy: 0.64 - ETA: 3s - loss: 0.6180 - accuracy: 0.64 - ETA: 3s - loss: 0.6184 - accuracy: 0.64 - ETA: 3s - loss: 0.6179 - accuracy: 0.64 - ETA: 3s - loss: 0.6180 - accuracy: 0.64 - ETA: 3s - loss: 0.6180 - accuracy: 0.64 - ETA: 3s - loss: 0.6179 - accuracy: 0.64 - ETA: 3s - loss: 0.6184 - accuracy: 0.64 - ETA: 3s - loss: 0.6187 - accuracy: 0.64 - ETA: 2s - loss: 0.6187 - accuracy: 0.64 - ETA: 2s - loss: 0.6186 - accuracy: 0.64 - ETA: 2s - loss: 0.6185 - accuracy: 0.64 - ETA: 2s - loss: 0.6181 - accuracy: 0.64 - ETA: 2s - loss: 0.6183 - accuracy: 0.64 - ETA: 2s - loss: 0.6188 - accuracy: 0.64 - ETA: 2s - loss: 0.6191 - accuracy: 0.64 - ETA: 2s - loss: 0.6195 - accuracy: 0.64 - ETA: 1s - loss: 0.6199 - accuracy: 0.63 - ETA: 1s - loss: 0.6200 - accuracy: 0.63 - ETA: 1s - loss: 0.6202 - accuracy: 0.63 - ETA: 1s - loss: 0.6205 - accuracy: 0.63 - ETA: 1s - loss: 0.6205 - accuracy: 0.63 - ETA: 1s - loss: 0.6203 - accuracy: 0.63 - ETA: 1s - loss: 0.6206 - accuracy: 0.63 - ETA: 1s - loss: 0.6205 - accuracy: 0.63 - ETA: 1s - loss: 0.6206 - accuracy: 0.63 - ETA: 0s - loss: 0.6205 - accuracy: 0.63 - ETA: 0s - loss: 0.6205 - accuracy: 0.63 - ETA: 0s - loss: 0.6205 - accuracy: 0.64 - ETA: 0s - loss: 0.6202 - accuracy: 0.64 - ETA: 0s - loss: 0.6202 - accuracy: 0.64 - ETA: 0s - loss: 0.6204 - accuracy: 0.64 - ETA: 0s - loss: 0.6205 - accuracy: 0.64 - ETA: 0s - loss: 0.6202 - accuracy: 0.64 - 9s 234us/step - loss: 0.6203 - accuracy: 0.6400\n",
      "\n",
      "Epoch 00040: loss improved from 0.62527 to 0.62028, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-40-0.6203.hdf5\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 8s - loss: 0.5973 - accuracy: 0.67 - ETA: 8s - loss: 0.6061 - accuracy: 0.66 - ETA: 9s - loss: 0.6254 - accuracy: 0.63 - ETA: 8s - loss: 0.6192 - accuracy: 0.64 - ETA: 8s - loss: 0.6124 - accuracy: 0.64 - ETA: 8s - loss: 0.6118 - accuracy: 0.64 - ETA: 8s - loss: 0.6150 - accuracy: 0.64 - ETA: 8s - loss: 0.6122 - accuracy: 0.64 - ETA: 8s - loss: 0.6111 - accuracy: 0.65 - ETA: 8s - loss: 0.6099 - accuracy: 0.65 - ETA: 8s - loss: 0.6095 - accuracy: 0.65 - ETA: 8s - loss: 0.6108 - accuracy: 0.64 - ETA: 7s - loss: 0.6108 - accuracy: 0.64 - ETA: 7s - loss: 0.6122 - accuracy: 0.64 - ETA: 7s - loss: 0.6131 - accuracy: 0.64 - ETA: 7s - loss: 0.6141 - accuracy: 0.64 - ETA: 7s - loss: 0.6151 - accuracy: 0.64 - ETA: 7s - loss: 0.6152 - accuracy: 0.64 - ETA: 7s - loss: 0.6152 - accuracy: 0.64 - ETA: 7s - loss: 0.6146 - accuracy: 0.64 - ETA: 7s - loss: 0.6151 - accuracy: 0.64 - ETA: 6s - loss: 0.6166 - accuracy: 0.64 - ETA: 6s - loss: 0.6170 - accuracy: 0.64 - ETA: 6s - loss: 0.6178 - accuracy: 0.64 - ETA: 6s - loss: 0.6183 - accuracy: 0.64 - ETA: 6s - loss: 0.6183 - accuracy: 0.64 - ETA: 6s - loss: 0.6182 - accuracy: 0.64 - ETA: 6s - loss: 0.6192 - accuracy: 0.64 - ETA: 6s - loss: 0.6191 - accuracy: 0.64 - ETA: 6s - loss: 0.6193 - accuracy: 0.64 - ETA: 5s - loss: 0.6198 - accuracy: 0.63 - ETA: 5s - loss: 0.6206 - accuracy: 0.63 - ETA: 5s - loss: 0.6212 - accuracy: 0.63 - ETA: 5s - loss: 0.6212 - accuracy: 0.63 - ETA: 5s - loss: 0.6215 - accuracy: 0.63 - ETA: 5s - loss: 0.6216 - accuracy: 0.63 - ETA: 5s - loss: 0.6212 - accuracy: 0.63 - ETA: 5s - loss: 0.6212 - accuracy: 0.63 - ETA: 4s - loss: 0.6207 - accuracy: 0.63 - ETA: 4s - loss: 0.6216 - accuracy: 0.63 - ETA: 4s - loss: 0.6216 - accuracy: 0.63 - ETA: 4s - loss: 0.6216 - accuracy: 0.63 - ETA: 4s - loss: 0.6215 - accuracy: 0.63 - ETA: 4s - loss: 0.6213 - accuracy: 0.63 - ETA: 4s - loss: 0.6212 - accuracy: 0.63 - ETA: 4s - loss: 0.6212 - accuracy: 0.63 - ETA: 3s - loss: 0.6211 - accuracy: 0.63 - ETA: 3s - loss: 0.6211 - accuracy: 0.63 - ETA: 3s - loss: 0.6211 - accuracy: 0.63 - ETA: 3s - loss: 0.6212 - accuracy: 0.63 - ETA: 3s - loss: 0.6213 - accuracy: 0.63 - ETA: 3s - loss: 0.6206 - accuracy: 0.63 - ETA: 3s - loss: 0.6209 - accuracy: 0.63 - ETA: 3s - loss: 0.6206 - accuracy: 0.63 - ETA: 2s - loss: 0.6206 - accuracy: 0.63 - ETA: 2s - loss: 0.6207 - accuracy: 0.63 - ETA: 2s - loss: 0.6207 - accuracy: 0.63 - ETA: 2s - loss: 0.6209 - accuracy: 0.63 - ETA: 2s - loss: 0.6211 - accuracy: 0.63 - ETA: 2s - loss: 0.6216 - accuracy: 0.63 - ETA: 2s - loss: 0.6212 - accuracy: 0.63 - ETA: 2s - loss: 0.6210 - accuracy: 0.63 - ETA: 1s - loss: 0.6210 - accuracy: 0.63 - ETA: 1s - loss: 0.6211 - accuracy: 0.63 - ETA: 1s - loss: 0.6214 - accuracy: 0.63 - ETA: 1s - loss: 0.6212 - accuracy: 0.63 - ETA: 1s - loss: 0.6210 - accuracy: 0.63 - ETA: 1s - loss: 0.6212 - accuracy: 0.63 - ETA: 1s - loss: 0.6211 - accuracy: 0.63 - ETA: 1s - loss: 0.6209 - accuracy: 0.63 - ETA: 0s - loss: 0.6211 - accuracy: 0.63 - ETA: 0s - loss: 0.6208 - accuracy: 0.63 - ETA: 0s - loss: 0.6207 - accuracy: 0.63 - ETA: 0s - loss: 0.6207 - accuracy: 0.63 - ETA: 0s - loss: 0.6210 - accuracy: 0.63 - ETA: 0s - loss: 0.6211 - accuracy: 0.63 - ETA: 0s - loss: 0.6212 - accuracy: 0.63 - ETA: 0s - loss: 0.6213 - accuracy: 0.63 - 9s 234us/step - loss: 0.6212 - accuracy: 0.6378\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.62028\n",
      "Epoch 42/50\n",
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6016 - accuracy: 0.67 - ETA: 8s - loss: 0.6015 - accuracy: 0.65 - ETA: 8s - loss: 0.6036 - accuracy: 0.65 - ETA: 8s - loss: 0.6074 - accuracy: 0.65 - ETA: 8s - loss: 0.6130 - accuracy: 0.64 - ETA: 8s - loss: 0.6122 - accuracy: 0.64 - ETA: 7s - loss: 0.6142 - accuracy: 0.63 - ETA: 7s - loss: 0.6156 - accuracy: 0.63 - ETA: 7s - loss: 0.6157 - accuracy: 0.63 - ETA: 7s - loss: 0.6166 - accuracy: 0.63 - ETA: 7s - loss: 0.6170 - accuracy: 0.63 - ETA: 7s - loss: 0.6168 - accuracy: 0.63 - ETA: 7s - loss: 0.6154 - accuracy: 0.63 - ETA: 7s - loss: 0.6157 - accuracy: 0.63 - ETA: 7s - loss: 0.6175 - accuracy: 0.64 - ETA: 6s - loss: 0.6181 - accuracy: 0.63 - ETA: 6s - loss: 0.6163 - accuracy: 0.64 - ETA: 6s - loss: 0.6164 - accuracy: 0.63 - ETA: 6s - loss: 0.6166 - accuracy: 0.63 - ETA: 6s - loss: 0.6151 - accuracy: 0.64 - ETA: 6s - loss: 0.6143 - accuracy: 0.64 - ETA: 6s - loss: 0.6131 - accuracy: 0.64 - ETA: 6s - loss: 0.6135 - accuracy: 0.64 - ETA: 6s - loss: 0.6129 - accuracy: 0.64 - ETA: 5s - loss: 0.6129 - accuracy: 0.64 - ETA: 5s - loss: 0.6134 - accuracy: 0.64 - ETA: 5s - loss: 0.6121 - accuracy: 0.64 - ETA: 5s - loss: 0.6117 - accuracy: 0.64 - ETA: 5s - loss: 0.6126 - accuracy: 0.64 - ETA: 5s - loss: 0.6130 - accuracy: 0.64 - ETA: 5s - loss: 0.6131 - accuracy: 0.64 - ETA: 5s - loss: 0.6129 - accuracy: 0.64 - ETA: 5s - loss: 0.6137 - accuracy: 0.64 - ETA: 4s - loss: 0.6131 - accuracy: 0.64 - ETA: 4s - loss: 0.6131 - accuracy: 0.64 - ETA: 4s - loss: 0.6125 - accuracy: 0.64 - ETA: 4s - loss: 0.6129 - accuracy: 0.64 - ETA: 4s - loss: 0.6131 - accuracy: 0.64 - ETA: 4s - loss: 0.6125 - accuracy: 0.64 - ETA: 4s - loss: 0.6135 - accuracy: 0.64 - ETA: 4s - loss: 0.6130 - accuracy: 0.64 - ETA: 4s - loss: 0.6135 - accuracy: 0.64 - ETA: 3s - loss: 0.6133 - accuracy: 0.64 - ETA: 3s - loss: 0.6135 - accuracy: 0.64 - ETA: 3s - loss: 0.6137 - accuracy: 0.64 - ETA: 3s - loss: 0.6135 - accuracy: 0.64 - ETA: 3s - loss: 0.6131 - accuracy: 0.64 - ETA: 3s - loss: 0.6130 - accuracy: 0.64 - ETA: 3s - loss: 0.6142 - accuracy: 0.64 - ETA: 3s - loss: 0.6147 - accuracy: 0.64 - ETA: 3s - loss: 0.6153 - accuracy: 0.63 - ETA: 2s - loss: 0.6151 - accuracy: 0.64 - ETA: 2s - loss: 0.6150 - accuracy: 0.64 - ETA: 2s - loss: 0.6151 - accuracy: 0.64 - ETA: 2s - loss: 0.6152 - accuracy: 0.64 - ETA: 2s - loss: 0.6155 - accuracy: 0.63 - ETA: 2s - loss: 0.6158 - accuracy: 0.63 - ETA: 2s - loss: 0.6156 - accuracy: 0.64 - ETA: 2s - loss: 0.6154 - accuracy: 0.64 - ETA: 2s - loss: 0.6156 - accuracy: 0.64 - ETA: 1s - loss: 0.6157 - accuracy: 0.64 - ETA: 1s - loss: 0.6157 - accuracy: 0.64 - ETA: 1s - loss: 0.6154 - accuracy: 0.64 - ETA: 1s - loss: 0.6155 - accuracy: 0.64 - ETA: 1s - loss: 0.6154 - accuracy: 0.64 - ETA: 1s - loss: 0.6154 - accuracy: 0.64 - ETA: 1s - loss: 0.6154 - accuracy: 0.64 - ETA: 1s - loss: 0.6155 - accuracy: 0.64 - ETA: 1s - loss: 0.6153 - accuracy: 0.64 - ETA: 0s - loss: 0.6156 - accuracy: 0.64 - ETA: 0s - loss: 0.6159 - accuracy: 0.64 - ETA: 0s - loss: 0.6156 - accuracy: 0.64 - ETA: 0s - loss: 0.6156 - accuracy: 0.64 - ETA: 0s - loss: 0.6159 - accuracy: 0.64 - ETA: 0s - loss: 0.6159 - accuracy: 0.64 - ETA: 0s - loss: 0.6158 - accuracy: 0.64 - ETA: 0s - loss: 0.6156 - accuracy: 0.64 - ETA: 0s - loss: 0.6160 - accuracy: 0.64 - 9s 215us/step - loss: 0.6158 - accuracy: 0.6422\n",
      "\n",
      "Epoch 00042: loss improved from 0.62028 to 0.61581, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-42-0.6158.hdf5\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 8s - loss: 0.5980 - accuracy: 0.66 - ETA: 8s - loss: 0.6074 - accuracy: 0.66 - ETA: 8s - loss: 0.6095 - accuracy: 0.65 - ETA: 8s - loss: 0.6103 - accuracy: 0.64 - ETA: 8s - loss: 0.6088 - accuracy: 0.64 - ETA: 8s - loss: 0.6075 - accuracy: 0.65 - ETA: 8s - loss: 0.6072 - accuracy: 0.65 - ETA: 7s - loss: 0.6084 - accuracy: 0.65 - ETA: 7s - loss: 0.6099 - accuracy: 0.65 - ETA: 7s - loss: 0.6124 - accuracy: 0.64 - ETA: 7s - loss: 0.6136 - accuracy: 0.64 - ETA: 7s - loss: 0.6126 - accuracy: 0.64 - ETA: 7s - loss: 0.6123 - accuracy: 0.64 - ETA: 7s - loss: 0.6113 - accuracy: 0.65 - ETA: 7s - loss: 0.6099 - accuracy: 0.65 - ETA: 6s - loss: 0.6095 - accuracy: 0.65 - ETA: 6s - loss: 0.6107 - accuracy: 0.65 - ETA: 6s - loss: 0.6106 - accuracy: 0.65 - ETA: 6s - loss: 0.6104 - accuracy: 0.65 - ETA: 6s - loss: 0.6097 - accuracy: 0.65 - ETA: 6s - loss: 0.6094 - accuracy: 0.65 - ETA: 6s - loss: 0.6093 - accuracy: 0.65 - ETA: 6s - loss: 0.6093 - accuracy: 0.65 - ETA: 6s - loss: 0.6091 - accuracy: 0.65 - ETA: 5s - loss: 0.6095 - accuracy: 0.65 - ETA: 5s - loss: 0.6100 - accuracy: 0.65 - ETA: 5s - loss: 0.6091 - accuracy: 0.65 - ETA: 5s - loss: 0.6083 - accuracy: 0.65 - ETA: 5s - loss: 0.6080 - accuracy: 0.65 - ETA: 5s - loss: 0.6078 - accuracy: 0.65 - ETA: 5s - loss: 0.6069 - accuracy: 0.65 - ETA: 5s - loss: 0.6069 - accuracy: 0.65 - ETA: 5s - loss: 0.6070 - accuracy: 0.65 - ETA: 4s - loss: 0.6080 - accuracy: 0.65 - ETA: 4s - loss: 0.6087 - accuracy: 0.65 - ETA: 4s - loss: 0.6089 - accuracy: 0.65 - ETA: 4s - loss: 0.6107 - accuracy: 0.65 - ETA: 4s - loss: 0.6103 - accuracy: 0.65 - ETA: 4s - loss: 0.6102 - accuracy: 0.65 - ETA: 4s - loss: 0.6104 - accuracy: 0.65 - ETA: 4s - loss: 0.6105 - accuracy: 0.65 - ETA: 4s - loss: 0.6110 - accuracy: 0.65 - ETA: 3s - loss: 0.6112 - accuracy: 0.65 - ETA: 3s - loss: 0.6114 - accuracy: 0.65 - ETA: 3s - loss: 0.6115 - accuracy: 0.65 - ETA: 3s - loss: 0.6122 - accuracy: 0.65 - ETA: 3s - loss: 0.6120 - accuracy: 0.65 - ETA: 3s - loss: 0.6118 - accuracy: 0.65 - ETA: 3s - loss: 0.6117 - accuracy: 0.65 - ETA: 3s - loss: 0.6117 - accuracy: 0.65 - ETA: 3s - loss: 0.6116 - accuracy: 0.65 - ETA: 2s - loss: 0.6116 - accuracy: 0.65 - ETA: 2s - loss: 0.6121 - accuracy: 0.65 - ETA: 2s - loss: 0.6116 - accuracy: 0.65 - ETA: 2s - loss: 0.6120 - accuracy: 0.65 - ETA: 2s - loss: 0.6120 - accuracy: 0.65 - ETA: 2s - loss: 0.6123 - accuracy: 0.65 - ETA: 2s - loss: 0.6126 - accuracy: 0.65 - ETA: 2s - loss: 0.6128 - accuracy: 0.64 - ETA: 2s - loss: 0.6126 - accuracy: 0.65 - ETA: 1s - loss: 0.6124 - accuracy: 0.65 - ETA: 1s - loss: 0.6124 - accuracy: 0.65 - ETA: 1s - loss: 0.6123 - accuracy: 0.65 - ETA: 1s - loss: 0.6123 - accuracy: 0.65 - ETA: 1s - loss: 0.6124 - accuracy: 0.65 - ETA: 1s - loss: 0.6127 - accuracy: 0.65 - ETA: 1s - loss: 0.6126 - accuracy: 0.65 - ETA: 1s - loss: 0.6128 - accuracy: 0.64 - ETA: 1s - loss: 0.6126 - accuracy: 0.64 - ETA: 0s - loss: 0.6124 - accuracy: 0.65 - ETA: 0s - loss: 0.6126 - accuracy: 0.65 - ETA: 0s - loss: 0.6124 - accuracy: 0.65 - ETA: 0s - loss: 0.6128 - accuracy: 0.65 - ETA: 0s - loss: 0.6128 - accuracy: 0.65 - ETA: 0s - loss: 0.6127 - accuracy: 0.65 - ETA: 0s - loss: 0.6125 - accuracy: 0.65 - ETA: 0s - loss: 0.6128 - accuracy: 0.64 - ETA: 0s - loss: 0.6130 - accuracy: 0.64 - 9s 213us/step - loss: 0.6130 - accuracy: 0.6491\n",
      "\n",
      "Epoch 00043: loss improved from 0.61581 to 0.61305, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-43-0.6130.hdf5\n",
      "Epoch 44/50\n",
      "40268/40268 [==============================] - ETA: 7s - loss: 0.6044 - accuracy: 0.67 - ETA: 8s - loss: 0.6071 - accuracy: 0.65 - ETA: 8s - loss: 0.6191 - accuracy: 0.64 - ETA: 8s - loss: 0.6178 - accuracy: 0.63 - ETA: 7s - loss: 0.6170 - accuracy: 0.64 - ETA: 7s - loss: 0.6116 - accuracy: 0.64 - ETA: 7s - loss: 0.6122 - accuracy: 0.64 - ETA: 7s - loss: 0.6133 - accuracy: 0.64 - ETA: 7s - loss: 0.6123 - accuracy: 0.64 - ETA: 7s - loss: 0.6141 - accuracy: 0.63 - ETA: 7s - loss: 0.6128 - accuracy: 0.63 - ETA: 7s - loss: 0.6115 - accuracy: 0.64 - ETA: 7s - loss: 0.6118 - accuracy: 0.64 - ETA: 7s - loss: 0.6108 - accuracy: 0.64 - ETA: 7s - loss: 0.6117 - accuracy: 0.64 - ETA: 6s - loss: 0.6098 - accuracy: 0.64 - ETA: 6s - loss: 0.6091 - accuracy: 0.64 - ETA: 6s - loss: 0.6101 - accuracy: 0.64 - ETA: 6s - loss: 0.6097 - accuracy: 0.64 - ETA: 6s - loss: 0.6091 - accuracy: 0.64 - ETA: 6s - loss: 0.6099 - accuracy: 0.64 - ETA: 6s - loss: 0.6093 - accuracy: 0.64 - ETA: 6s - loss: 0.6082 - accuracy: 0.64 - ETA: 6s - loss: 0.6086 - accuracy: 0.64 - ETA: 6s - loss: 0.6089 - accuracy: 0.64 - ETA: 5s - loss: 0.6087 - accuracy: 0.64 - ETA: 5s - loss: 0.6077 - accuracy: 0.64 - ETA: 5s - loss: 0.6071 - accuracy: 0.64 - ETA: 5s - loss: 0.6075 - accuracy: 0.64 - ETA: 5s - loss: 0.6079 - accuracy: 0.64 - ETA: 5s - loss: 0.6079 - accuracy: 0.64 - ETA: 5s - loss: 0.6086 - accuracy: 0.64 - ETA: 5s - loss: 0.6090 - accuracy: 0.64 - ETA: 5s - loss: 0.6087 - accuracy: 0.65 - ETA: 5s - loss: 0.6082 - accuracy: 0.65 - ETA: 4s - loss: 0.6079 - accuracy: 0.65 - ETA: 4s - loss: 0.6083 - accuracy: 0.65 - ETA: 4s - loss: 0.6082 - accuracy: 0.65 - ETA: 4s - loss: 0.6079 - accuracy: 0.65 - ETA: 4s - loss: 0.6068 - accuracy: 0.65 - ETA: 4s - loss: 0.6069 - accuracy: 0.65 - ETA: 4s - loss: 0.6067 - accuracy: 0.65 - ETA: 4s - loss: 0.6067 - accuracy: 0.65 - ETA: 3s - loss: 0.6071 - accuracy: 0.65 - ETA: 3s - loss: 0.6071 - accuracy: 0.65 - ETA: 3s - loss: 0.6067 - accuracy: 0.65 - ETA: 3s - loss: 0.6066 - accuracy: 0.65 - ETA: 3s - loss: 0.6060 - accuracy: 0.65 - ETA: 3s - loss: 0.6064 - accuracy: 0.65 - ETA: 3s - loss: 0.6064 - accuracy: 0.65 - ETA: 3s - loss: 0.6060 - accuracy: 0.65 - ETA: 3s - loss: 0.6058 - accuracy: 0.65 - ETA: 2s - loss: 0.6060 - accuracy: 0.65 - ETA: 2s - loss: 0.6065 - accuracy: 0.65 - ETA: 2s - loss: 0.6065 - accuracy: 0.65 - ETA: 2s - loss: 0.6069 - accuracy: 0.65 - ETA: 2s - loss: 0.6064 - accuracy: 0.65 - ETA: 2s - loss: 0.6063 - accuracy: 0.65 - ETA: 2s - loss: 0.6070 - accuracy: 0.65 - ETA: 2s - loss: 0.6074 - accuracy: 0.65 - ETA: 2s - loss: 0.6078 - accuracy: 0.65 - ETA: 1s - loss: 0.6076 - accuracy: 0.65 - ETA: 1s - loss: 0.6081 - accuracy: 0.65 - ETA: 1s - loss: 0.6083 - accuracy: 0.65 - ETA: 1s - loss: 0.6084 - accuracy: 0.65 - ETA: 1s - loss: 0.6085 - accuracy: 0.65 - ETA: 1s - loss: 0.6085 - accuracy: 0.65 - ETA: 1s - loss: 0.6086 - accuracy: 0.65 - ETA: 1s - loss: 0.6085 - accuracy: 0.65 - ETA: 1s - loss: 0.6089 - accuracy: 0.65 - ETA: 0s - loss: 0.6096 - accuracy: 0.64 - ETA: 0s - loss: 0.6095 - accuracy: 0.64 - ETA: 0s - loss: 0.6094 - accuracy: 0.64 - ETA: 0s - loss: 0.6096 - accuracy: 0.64 - ETA: 0s - loss: 0.6094 - accuracy: 0.64 - ETA: 0s - loss: 0.6096 - accuracy: 0.64 - ETA: 0s - loss: 0.6095 - accuracy: 0.64 - ETA: 0s - loss: 0.6097 - accuracy: 0.64 - 10s 242us/step - loss: 0.6096 - accuracy: 0.6492\n",
      "\n",
      "Epoch 00044: loss improved from 0.61305 to 0.60963, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-44-0.6096.hdf5\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 9s - loss: 0.5979 - accuracy: 0.67 - ETA: 9s - loss: 0.5976 - accuracy: 0.67 - ETA: 9s - loss: 0.6014 - accuracy: 0.67 - ETA: 9s - loss: 0.6056 - accuracy: 0.66 - ETA: 9s - loss: 0.6046 - accuracy: 0.66 - ETA: 9s - loss: 0.6040 - accuracy: 0.66 - ETA: 9s - loss: 0.6024 - accuracy: 0.66 - ETA: 9s - loss: 0.6004 - accuracy: 0.66 - ETA: 9s - loss: 0.6039 - accuracy: 0.66 - ETA: 9s - loss: 0.6039 - accuracy: 0.66 - ETA: 9s - loss: 0.6038 - accuracy: 0.66 - ETA: 9s - loss: 0.6028 - accuracy: 0.66 - ETA: 8s - loss: 0.6012 - accuracy: 0.66 - ETA: 8s - loss: 0.6028 - accuracy: 0.66 - ETA: 8s - loss: 0.6042 - accuracy: 0.66 - ETA: 8s - loss: 0.6019 - accuracy: 0.66 - ETA: 8s - loss: 0.6015 - accuracy: 0.66 - ETA: 8s - loss: 0.6015 - accuracy: 0.66 - ETA: 8s - loss: 0.6022 - accuracy: 0.66 - ETA: 8s - loss: 0.6041 - accuracy: 0.66 - ETA: 7s - loss: 0.6033 - accuracy: 0.66 - ETA: 7s - loss: 0.6023 - accuracy: 0.66 - ETA: 7s - loss: 0.6017 - accuracy: 0.66 - ETA: 7s - loss: 0.6014 - accuracy: 0.66 - ETA: 7s - loss: 0.6015 - accuracy: 0.66 - ETA: 7s - loss: 0.6023 - accuracy: 0.66 - ETA: 7s - loss: 0.6011 - accuracy: 0.66 - ETA: 6s - loss: 0.6015 - accuracy: 0.66 - ETA: 6s - loss: 0.6018 - accuracy: 0.66 - ETA: 6s - loss: 0.6015 - accuracy: 0.66 - ETA: 6s - loss: 0.6026 - accuracy: 0.65 - ETA: 6s - loss: 0.6036 - accuracy: 0.65 - ETA: 6s - loss: 0.6042 - accuracy: 0.65 - ETA: 6s - loss: 0.6048 - accuracy: 0.65 - ETA: 6s - loss: 0.6047 - accuracy: 0.65 - ETA: 5s - loss: 0.6055 - accuracy: 0.65 - ETA: 5s - loss: 0.6055 - accuracy: 0.65 - ETA: 5s - loss: 0.6057 - accuracy: 0.65 - ETA: 5s - loss: 0.6060 - accuracy: 0.65 - ETA: 5s - loss: 0.6062 - accuracy: 0.65 - ETA: 5s - loss: 0.6065 - accuracy: 0.65 - ETA: 5s - loss: 0.6062 - accuracy: 0.65 - ETA: 4s - loss: 0.6060 - accuracy: 0.65 - ETA: 4s - loss: 0.6055 - accuracy: 0.65 - ETA: 4s - loss: 0.6057 - accuracy: 0.65 - ETA: 4s - loss: 0.6062 - accuracy: 0.65 - ETA: 4s - loss: 0.6066 - accuracy: 0.65 - ETA: 4s - loss: 0.6063 - accuracy: 0.65 - ETA: 4s - loss: 0.6068 - accuracy: 0.65 - ETA: 3s - loss: 0.6063 - accuracy: 0.65 - ETA: 3s - loss: 0.6063 - accuracy: 0.65 - ETA: 3s - loss: 0.6063 - accuracy: 0.65 - ETA: 3s - loss: 0.6063 - accuracy: 0.65 - ETA: 3s - loss: 0.6060 - accuracy: 0.65 - ETA: 3s - loss: 0.6062 - accuracy: 0.65 - ETA: 3s - loss: 0.6062 - accuracy: 0.65 - ETA: 3s - loss: 0.6067 - accuracy: 0.65 - ETA: 2s - loss: 0.6063 - accuracy: 0.65 - ETA: 2s - loss: 0.6062 - accuracy: 0.65 - ETA: 2s - loss: 0.6058 - accuracy: 0.65 - ETA: 2s - loss: 0.6062 - accuracy: 0.65 - ETA: 2s - loss: 0.6063 - accuracy: 0.65 - ETA: 2s - loss: 0.6064 - accuracy: 0.65 - ETA: 2s - loss: 0.6061 - accuracy: 0.65 - ETA: 1s - loss: 0.6062 - accuracy: 0.65 - ETA: 1s - loss: 0.6059 - accuracy: 0.65 - ETA: 1s - loss: 0.6065 - accuracy: 0.65 - ETA: 1s - loss: 0.6065 - accuracy: 0.65 - ETA: 1s - loss: 0.6070 - accuracy: 0.65 - ETA: 1s - loss: 0.6070 - accuracy: 0.65 - ETA: 1s - loss: 0.6067 - accuracy: 0.65 - ETA: 0s - loss: 0.6063 - accuracy: 0.65 - ETA: 0s - loss: 0.6064 - accuracy: 0.65 - ETA: 0s - loss: 0.6063 - accuracy: 0.65 - ETA: 0s - loss: 0.6060 - accuracy: 0.65 - ETA: 0s - loss: 0.6059 - accuracy: 0.65 - ETA: 0s - loss: 0.6061 - accuracy: 0.65 - ETA: 0s - loss: 0.6060 - accuracy: 0.65 - 11s 271us/step - loss: 0.6058 - accuracy: 0.6542\n",
      "\n",
      "Epoch 00045: loss improved from 0.60963 to 0.60580, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-45-0.6058.hdf5\n",
      "Epoch 46/50\n",
      "40268/40268 [==============================] - ETA: 9s - loss: 0.6166 - accuracy: 0.61 - ETA: 10s - loss: 0.6048 - accuracy: 0.639 - ETA: 10s - loss: 0.6058 - accuracy: 0.640 - ETA: 10s - loss: 0.6058 - accuracy: 0.637 - ETA: 10s - loss: 0.6023 - accuracy: 0.646 - ETA: 10s - loss: 0.5977 - accuracy: 0.653 - ETA: 9s - loss: 0.5944 - accuracy: 0.658 - ETA: 9s - loss: 0.5939 - accuracy: 0.66 - ETA: 9s - loss: 0.5937 - accuracy: 0.66 - ETA: 9s - loss: 0.5941 - accuracy: 0.66 - ETA: 9s - loss: 0.5956 - accuracy: 0.66 - ETA: 9s - loss: 0.5969 - accuracy: 0.65 - ETA: 9s - loss: 0.5952 - accuracy: 0.66 - ETA: 9s - loss: 0.5945 - accuracy: 0.66 - ETA: 9s - loss: 0.5949 - accuracy: 0.66 - ETA: 8s - loss: 0.5944 - accuracy: 0.66 - ETA: 8s - loss: 0.5933 - accuracy: 0.66 - ETA: 8s - loss: 0.5932 - accuracy: 0.66 - ETA: 8s - loss: 0.5920 - accuracy: 0.66 - ETA: 8s - loss: 0.5918 - accuracy: 0.66 - ETA: 8s - loss: 0.5925 - accuracy: 0.66 - ETA: 8s - loss: 0.5933 - accuracy: 0.66 - ETA: 8s - loss: 0.5942 - accuracy: 0.66 - ETA: 7s - loss: 0.5954 - accuracy: 0.66 - ETA: 7s - loss: 0.5955 - accuracy: 0.66 - ETA: 7s - loss: 0.5951 - accuracy: 0.66 - ETA: 7s - loss: 0.5949 - accuracy: 0.66 - ETA: 7s - loss: 0.5953 - accuracy: 0.66 - ETA: 6s - loss: 0.5964 - accuracy: 0.65 - ETA: 6s - loss: 0.5968 - accuracy: 0.65 - ETA: 6s - loss: 0.5968 - accuracy: 0.65 - ETA: 6s - loss: 0.5969 - accuracy: 0.65 - ETA: 6s - loss: 0.5966 - accuracy: 0.65 - ETA: 6s - loss: 0.5973 - accuracy: 0.65 - ETA: 5s - loss: 0.5977 - accuracy: 0.65 - ETA: 5s - loss: 0.5978 - accuracy: 0.65 - ETA: 5s - loss: 0.5975 - accuracy: 0.65 - ETA: 5s - loss: 0.5975 - accuracy: 0.65 - ETA: 5s - loss: 0.5975 - accuracy: 0.65 - ETA: 5s - loss: 0.5975 - accuracy: 0.65 - ETA: 4s - loss: 0.5982 - accuracy: 0.65 - ETA: 4s - loss: 0.5984 - accuracy: 0.65 - ETA: 4s - loss: 0.5986 - accuracy: 0.65 - ETA: 4s - loss: 0.5982 - accuracy: 0.65 - ETA: 4s - loss: 0.5981 - accuracy: 0.65 - ETA: 4s - loss: 0.5987 - accuracy: 0.65 - ETA: 4s - loss: 0.5987 - accuracy: 0.65 - ETA: 3s - loss: 0.5985 - accuracy: 0.65 - ETA: 3s - loss: 0.5980 - accuracy: 0.65 - ETA: 3s - loss: 0.5983 - accuracy: 0.65 - ETA: 3s - loss: 0.5985 - accuracy: 0.65 - ETA: 3s - loss: 0.5984 - accuracy: 0.65 - ETA: 3s - loss: 0.5980 - accuracy: 0.65 - ETA: 3s - loss: 0.5979 - accuracy: 0.65 - ETA: 2s - loss: 0.5982 - accuracy: 0.65 - ETA: 2s - loss: 0.5983 - accuracy: 0.65 - ETA: 2s - loss: 0.5987 - accuracy: 0.65 - ETA: 2s - loss: 0.5990 - accuracy: 0.65 - ETA: 2s - loss: 0.5993 - accuracy: 0.65 - ETA: 2s - loss: 0.5995 - accuracy: 0.65 - ETA: 2s - loss: 0.5996 - accuracy: 0.65 - ETA: 2s - loss: 0.5999 - accuracy: 0.65 - ETA: 1s - loss: 0.6001 - accuracy: 0.65 - ETA: 1s - loss: 0.6005 - accuracy: 0.65 - ETA: 1s - loss: 0.6007 - accuracy: 0.65 - ETA: 1s - loss: 0.6007 - accuracy: 0.65 - ETA: 1s - loss: 0.6012 - accuracy: 0.65 - ETA: 1s - loss: 0.6006 - accuracy: 0.65 - ETA: 1s - loss: 0.6008 - accuracy: 0.65 - ETA: 1s - loss: 0.6006 - accuracy: 0.65 - ETA: 0s - loss: 0.6010 - accuracy: 0.65 - ETA: 0s - loss: 0.6010 - accuracy: 0.65 - ETA: 0s - loss: 0.6011 - accuracy: 0.65 - ETA: 0s - loss: 0.6014 - accuracy: 0.65 - ETA: 0s - loss: 0.6014 - accuracy: 0.65 - ETA: 0s - loss: 0.6016 - accuracy: 0.65 - ETA: 0s - loss: 0.6018 - accuracy: 0.65 - ETA: 0s - loss: 0.6019 - accuracy: 0.65 - 10s 238us/step - loss: 0.6019 - accuracy: 0.6538\n",
      "\n",
      "Epoch 00046: loss improved from 0.60580 to 0.60194, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-46-0.6019.hdf5\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 8s - loss: 0.5940 - accuracy: 0.66 - ETA: 8s - loss: 0.5970 - accuracy: 0.66 - ETA: 8s - loss: 0.5982 - accuracy: 0.66 - ETA: 8s - loss: 0.6007 - accuracy: 0.66 - ETA: 8s - loss: 0.5994 - accuracy: 0.66 - ETA: 8s - loss: 0.6019 - accuracy: 0.65 - ETA: 8s - loss: 0.6002 - accuracy: 0.65 - ETA: 8s - loss: 0.5994 - accuracy: 0.65 - ETA: 8s - loss: 0.5991 - accuracy: 0.65 - ETA: 7s - loss: 0.5960 - accuracy: 0.65 - ETA: 7s - loss: 0.5939 - accuracy: 0.66 - ETA: 7s - loss: 0.5942 - accuracy: 0.66 - ETA: 7s - loss: 0.5944 - accuracy: 0.66 - ETA: 7s - loss: 0.5937 - accuracy: 0.66 - ETA: 7s - loss: 0.5953 - accuracy: 0.66 - ETA: 7s - loss: 0.5960 - accuracy: 0.65 - ETA: 7s - loss: 0.5978 - accuracy: 0.65 - ETA: 7s - loss: 0.5985 - accuracy: 0.65 - ETA: 7s - loss: 0.5978 - accuracy: 0.65 - ETA: 6s - loss: 0.5977 - accuracy: 0.66 - ETA: 6s - loss: 0.5978 - accuracy: 0.65 - ETA: 6s - loss: 0.5986 - accuracy: 0.65 - ETA: 6s - loss: 0.5983 - accuracy: 0.65 - ETA: 6s - loss: 0.5980 - accuracy: 0.65 - ETA: 6s - loss: 0.5984 - accuracy: 0.65 - ETA: 6s - loss: 0.5990 - accuracy: 0.65 - ETA: 6s - loss: 0.5988 - accuracy: 0.65 - ETA: 6s - loss: 0.5991 - accuracy: 0.65 - ETA: 5s - loss: 0.5995 - accuracy: 0.65 - ETA: 5s - loss: 0.5994 - accuracy: 0.65 - ETA: 5s - loss: 0.6004 - accuracy: 0.65 - ETA: 5s - loss: 0.6008 - accuracy: 0.65 - ETA: 5s - loss: 0.6003 - accuracy: 0.65 - ETA: 5s - loss: 0.6006 - accuracy: 0.65 - ETA: 5s - loss: 0.6008 - accuracy: 0.65 - ETA: 5s - loss: 0.6006 - accuracy: 0.65 - ETA: 5s - loss: 0.6012 - accuracy: 0.65 - ETA: 4s - loss: 0.6009 - accuracy: 0.65 - ETA: 4s - loss: 0.5999 - accuracy: 0.65 - ETA: 4s - loss: 0.5999 - accuracy: 0.65 - ETA: 4s - loss: 0.5999 - accuracy: 0.65 - ETA: 4s - loss: 0.5997 - accuracy: 0.65 - ETA: 4s - loss: 0.6001 - accuracy: 0.65 - ETA: 4s - loss: 0.5997 - accuracy: 0.65 - ETA: 4s - loss: 0.6004 - accuracy: 0.65 - ETA: 3s - loss: 0.6006 - accuracy: 0.65 - ETA: 3s - loss: 0.6013 - accuracy: 0.65 - ETA: 3s - loss: 0.6010 - accuracy: 0.65 - ETA: 3s - loss: 0.6012 - accuracy: 0.65 - ETA: 3s - loss: 0.6006 - accuracy: 0.65 - ETA: 3s - loss: 0.6003 - accuracy: 0.65 - ETA: 3s - loss: 0.6007 - accuracy: 0.65 - ETA: 3s - loss: 0.6008 - accuracy: 0.65 - ETA: 3s - loss: 0.6004 - accuracy: 0.65 - ETA: 2s - loss: 0.6008 - accuracy: 0.65 - ETA: 2s - loss: 0.6005 - accuracy: 0.65 - ETA: 2s - loss: 0.6004 - accuracy: 0.65 - ETA: 2s - loss: 0.6003 - accuracy: 0.65 - ETA: 2s - loss: 0.6003 - accuracy: 0.65 - ETA: 2s - loss: 0.6006 - accuracy: 0.65 - ETA: 2s - loss: 0.6009 - accuracy: 0.65 - ETA: 2s - loss: 0.6010 - accuracy: 0.65 - ETA: 1s - loss: 0.6010 - accuracy: 0.65 - ETA: 1s - loss: 0.6008 - accuracy: 0.65 - ETA: 1s - loss: 0.6010 - accuracy: 0.65 - ETA: 1s - loss: 0.6008 - accuracy: 0.65 - ETA: 1s - loss: 0.6005 - accuracy: 0.65 - ETA: 1s - loss: 0.6004 - accuracy: 0.65 - ETA: 1s - loss: 0.6004 - accuracy: 0.65 - ETA: 1s - loss: 0.6006 - accuracy: 0.65 - ETA: 0s - loss: 0.6010 - accuracy: 0.65 - ETA: 0s - loss: 0.6012 - accuracy: 0.65 - ETA: 0s - loss: 0.6013 - accuracy: 0.65 - ETA: 0s - loss: 0.6014 - accuracy: 0.65 - ETA: 0s - loss: 0.6015 - accuracy: 0.65 - ETA: 0s - loss: 0.6017 - accuracy: 0.65 - ETA: 0s - loss: 0.6017 - accuracy: 0.65 - ETA: 0s - loss: 0.6016 - accuracy: 0.65 - 9s 235us/step - loss: 0.6017 - accuracy: 0.6571\n",
      "\n",
      "Epoch 00047: loss improved from 0.60194 to 0.60172, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-47-0.6017.hdf5\n",
      "Epoch 48/50\n",
      "40268/40268 [==============================] - ETA: 8s - loss: 0.6146 - accuracy: 0.65 - ETA: 8s - loss: 0.6058 - accuracy: 0.65 - ETA: 8s - loss: 0.5974 - accuracy: 0.65 - ETA: 8s - loss: 0.5930 - accuracy: 0.65 - ETA: 8s - loss: 0.5870 - accuracy: 0.66 - ETA: 8s - loss: 0.5863 - accuracy: 0.66 - ETA: 8s - loss: 0.5886 - accuracy: 0.66 - ETA: 8s - loss: 0.5929 - accuracy: 0.66 - ETA: 8s - loss: 0.5916 - accuracy: 0.66 - ETA: 8s - loss: 0.5947 - accuracy: 0.66 - ETA: 8s - loss: 0.5947 - accuracy: 0.65 - ETA: 7s - loss: 0.5956 - accuracy: 0.65 - ETA: 7s - loss: 0.5953 - accuracy: 0.65 - ETA: 7s - loss: 0.5947 - accuracy: 0.65 - ETA: 7s - loss: 0.5918 - accuracy: 0.66 - ETA: 7s - loss: 0.5918 - accuracy: 0.66 - ETA: 7s - loss: 0.5934 - accuracy: 0.65 - ETA: 7s - loss: 0.5935 - accuracy: 0.65 - ETA: 7s - loss: 0.5945 - accuracy: 0.65 - ETA: 6s - loss: 0.5946 - accuracy: 0.65 - ETA: 6s - loss: 0.5950 - accuracy: 0.65 - ETA: 6s - loss: 0.5950 - accuracy: 0.65 - ETA: 6s - loss: 0.5953 - accuracy: 0.65 - ETA: 6s - loss: 0.5965 - accuracy: 0.65 - ETA: 6s - loss: 0.5967 - accuracy: 0.65 - ETA: 6s - loss: 0.5963 - accuracy: 0.65 - ETA: 6s - loss: 0.5956 - accuracy: 0.65 - ETA: 5s - loss: 0.5960 - accuracy: 0.65 - ETA: 5s - loss: 0.5960 - accuracy: 0.65 - ETA: 5s - loss: 0.5954 - accuracy: 0.65 - ETA: 5s - loss: 0.5948 - accuracy: 0.65 - ETA: 5s - loss: 0.5957 - accuracy: 0.65 - ETA: 5s - loss: 0.5958 - accuracy: 0.65 - ETA: 5s - loss: 0.5960 - accuracy: 0.65 - ETA: 5s - loss: 0.5957 - accuracy: 0.65 - ETA: 5s - loss: 0.5956 - accuracy: 0.65 - ETA: 4s - loss: 0.5951 - accuracy: 0.65 - ETA: 4s - loss: 0.5952 - accuracy: 0.65 - ETA: 4s - loss: 0.5948 - accuracy: 0.65 - ETA: 4s - loss: 0.5950 - accuracy: 0.66 - ETA: 4s - loss: 0.5953 - accuracy: 0.66 - ETA: 4s - loss: 0.5958 - accuracy: 0.65 - ETA: 4s - loss: 0.5963 - accuracy: 0.65 - ETA: 4s - loss: 0.5968 - accuracy: 0.65 - ETA: 3s - loss: 0.5960 - accuracy: 0.65 - ETA: 3s - loss: 0.5957 - accuracy: 0.65 - ETA: 3s - loss: 0.5957 - accuracy: 0.65 - ETA: 3s - loss: 0.5956 - accuracy: 0.65 - ETA: 3s - loss: 0.5957 - accuracy: 0.65 - ETA: 3s - loss: 0.5955 - accuracy: 0.65 - ETA: 3s - loss: 0.5961 - accuracy: 0.65 - ETA: 3s - loss: 0.5964 - accuracy: 0.65 - ETA: 3s - loss: 0.5965 - accuracy: 0.65 - ETA: 2s - loss: 0.5965 - accuracy: 0.65 - ETA: 2s - loss: 0.5968 - accuracy: 0.65 - ETA: 2s - loss: 0.5966 - accuracy: 0.65 - ETA: 2s - loss: 0.5964 - accuracy: 0.65 - ETA: 2s - loss: 0.5964 - accuracy: 0.65 - ETA: 2s - loss: 0.5965 - accuracy: 0.65 - ETA: 2s - loss: 0.5963 - accuracy: 0.65 - ETA: 2s - loss: 0.5962 - accuracy: 0.65 - ETA: 1s - loss: 0.5960 - accuracy: 0.65 - ETA: 1s - loss: 0.5961 - accuracy: 0.65 - ETA: 1s - loss: 0.5960 - accuracy: 0.65 - ETA: 1s - loss: 0.5958 - accuracy: 0.65 - ETA: 1s - loss: 0.5959 - accuracy: 0.65 - ETA: 1s - loss: 0.5958 - accuracy: 0.65 - ETA: 1s - loss: 0.5955 - accuracy: 0.65 - ETA: 1s - loss: 0.5957 - accuracy: 0.65 - ETA: 1s - loss: 0.5957 - accuracy: 0.65 - ETA: 0s - loss: 0.5956 - accuracy: 0.65 - ETA: 0s - loss: 0.5960 - accuracy: 0.65 - ETA: 0s - loss: 0.5959 - accuracy: 0.65 - ETA: 0s - loss: 0.5958 - accuracy: 0.65 - ETA: 0s - loss: 0.5960 - accuracy: 0.65 - ETA: 0s - loss: 0.5959 - accuracy: 0.65 - ETA: 0s - loss: 0.5957 - accuracy: 0.65 - ETA: 0s - loss: 0.5960 - accuracy: 0.65 - 9s 231us/step - loss: 0.5959 - accuracy: 0.6589\n",
      "\n",
      "Epoch 00048: loss improved from 0.60172 to 0.59588, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-48-0.5959.hdf5\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40268/40268 [==============================] - ETA: 8s - loss: 0.5831 - accuracy: 0.69 - ETA: 8s - loss: 0.5774 - accuracy: 0.68 - ETA: 8s - loss: 0.5789 - accuracy: 0.67 - ETA: 8s - loss: 0.5829 - accuracy: 0.67 - ETA: 8s - loss: 0.5808 - accuracy: 0.67 - ETA: 8s - loss: 0.5791 - accuracy: 0.67 - ETA: 8s - loss: 0.5765 - accuracy: 0.67 - ETA: 7s - loss: 0.5750 - accuracy: 0.68 - ETA: 7s - loss: 0.5796 - accuracy: 0.67 - ETA: 7s - loss: 0.5814 - accuracy: 0.67 - ETA: 7s - loss: 0.5805 - accuracy: 0.67 - ETA: 7s - loss: 0.5807 - accuracy: 0.67 - ETA: 7s - loss: 0.5826 - accuracy: 0.67 - ETA: 7s - loss: 0.5842 - accuracy: 0.67 - ETA: 7s - loss: 0.5862 - accuracy: 0.67 - ETA: 7s - loss: 0.5883 - accuracy: 0.66 - ETA: 7s - loss: 0.5881 - accuracy: 0.66 - ETA: 7s - loss: 0.5886 - accuracy: 0.66 - ETA: 6s - loss: 0.5883 - accuracy: 0.66 - ETA: 6s - loss: 0.5887 - accuracy: 0.66 - ETA: 6s - loss: 0.5891 - accuracy: 0.66 - ETA: 6s - loss: 0.5890 - accuracy: 0.66 - ETA: 6s - loss: 0.5885 - accuracy: 0.66 - ETA: 6s - loss: 0.5879 - accuracy: 0.66 - ETA: 6s - loss: 0.5871 - accuracy: 0.66 - ETA: 6s - loss: 0.5878 - accuracy: 0.66 - ETA: 5s - loss: 0.5888 - accuracy: 0.66 - ETA: 5s - loss: 0.5879 - accuracy: 0.66 - ETA: 5s - loss: 0.5873 - accuracy: 0.66 - ETA: 5s - loss: 0.5869 - accuracy: 0.67 - ETA: 5s - loss: 0.5878 - accuracy: 0.67 - ETA: 5s - loss: 0.5883 - accuracy: 0.66 - ETA: 5s - loss: 0.5877 - accuracy: 0.67 - ETA: 5s - loss: 0.5876 - accuracy: 0.67 - ETA: 5s - loss: 0.5876 - accuracy: 0.67 - ETA: 4s - loss: 0.5878 - accuracy: 0.66 - ETA: 4s - loss: 0.5879 - accuracy: 0.66 - ETA: 4s - loss: 0.5876 - accuracy: 0.66 - ETA: 4s - loss: 0.5885 - accuracy: 0.66 - ETA: 4s - loss: 0.5883 - accuracy: 0.66 - ETA: 4s - loss: 0.5883 - accuracy: 0.66 - ETA: 4s - loss: 0.5886 - accuracy: 0.66 - ETA: 4s - loss: 0.5892 - accuracy: 0.66 - ETA: 3s - loss: 0.5893 - accuracy: 0.66 - ETA: 3s - loss: 0.5893 - accuracy: 0.66 - ETA: 3s - loss: 0.5897 - accuracy: 0.66 - ETA: 3s - loss: 0.5902 - accuracy: 0.66 - ETA: 3s - loss: 0.5906 - accuracy: 0.66 - ETA: 3s - loss: 0.5914 - accuracy: 0.66 - ETA: 3s - loss: 0.5916 - accuracy: 0.66 - ETA: 3s - loss: 0.5916 - accuracy: 0.66 - ETA: 3s - loss: 0.5916 - accuracy: 0.66 - ETA: 2s - loss: 0.5920 - accuracy: 0.66 - ETA: 2s - loss: 0.5924 - accuracy: 0.66 - ETA: 2s - loss: 0.5921 - accuracy: 0.66 - ETA: 2s - loss: 0.5922 - accuracy: 0.66 - ETA: 2s - loss: 0.5922 - accuracy: 0.66 - ETA: 2s - loss: 0.5920 - accuracy: 0.66 - ETA: 2s - loss: 0.5919 - accuracy: 0.66 - ETA: 2s - loss: 0.5921 - accuracy: 0.66 - ETA: 1s - loss: 0.5919 - accuracy: 0.66 - ETA: 1s - loss: 0.5921 - accuracy: 0.66 - ETA: 1s - loss: 0.5919 - accuracy: 0.66 - ETA: 1s - loss: 0.5920 - accuracy: 0.66 - ETA: 1s - loss: 0.5923 - accuracy: 0.66 - ETA: 1s - loss: 0.5922 - accuracy: 0.66 - ETA: 1s - loss: 0.5923 - accuracy: 0.66 - ETA: 1s - loss: 0.5925 - accuracy: 0.66 - ETA: 1s - loss: 0.5927 - accuracy: 0.66 - ETA: 0s - loss: 0.5927 - accuracy: 0.66 - ETA: 0s - loss: 0.5924 - accuracy: 0.66 - ETA: 0s - loss: 0.5924 - accuracy: 0.66 - ETA: 0s - loss: 0.5924 - accuracy: 0.66 - ETA: 0s - loss: 0.5926 - accuracy: 0.66 - ETA: 0s - loss: 0.5926 - accuracy: 0.66 - ETA: 0s - loss: 0.5930 - accuracy: 0.66 - ETA: 0s - loss: 0.5930 - accuracy: 0.66 - ETA: 0s - loss: 0.5928 - accuracy: 0.66 - 9s 217us/step - loss: 0.5932 - accuracy: 0.6636\n",
      "\n",
      "Epoch 00049: loss improved from 0.59588 to 0.59319, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-49-0.5932.hdf5\n",
      "Epoch 50/50\n",
      "40268/40268 [==============================] - ETA: 7s - loss: 0.5767 - accuracy: 0.68 - ETA: 8s - loss: 0.5858 - accuracy: 0.67 - ETA: 8s - loss: 0.5778 - accuracy: 0.68 - ETA: 8s - loss: 0.5836 - accuracy: 0.67 - ETA: 7s - loss: 0.5855 - accuracy: 0.67 - ETA: 7s - loss: 0.5820 - accuracy: 0.67 - ETA: 7s - loss: 0.5805 - accuracy: 0.68 - ETA: 7s - loss: 0.5821 - accuracy: 0.68 - ETA: 7s - loss: 0.5825 - accuracy: 0.68 - ETA: 7s - loss: 0.5832 - accuracy: 0.67 - ETA: 7s - loss: 0.5845 - accuracy: 0.67 - ETA: 7s - loss: 0.5862 - accuracy: 0.67 - ETA: 7s - loss: 0.5854 - accuracy: 0.67 - ETA: 6s - loss: 0.5864 - accuracy: 0.67 - ETA: 6s - loss: 0.5861 - accuracy: 0.67 - ETA: 6s - loss: 0.5865 - accuracy: 0.67 - ETA: 6s - loss: 0.5860 - accuracy: 0.67 - ETA: 6s - loss: 0.5848 - accuracy: 0.67 - ETA: 6s - loss: 0.5838 - accuracy: 0.67 - ETA: 6s - loss: 0.5842 - accuracy: 0.67 - ETA: 6s - loss: 0.5857 - accuracy: 0.67 - ETA: 6s - loss: 0.5866 - accuracy: 0.67 - ETA: 6s - loss: 0.5869 - accuracy: 0.67 - ETA: 5s - loss: 0.5880 - accuracy: 0.67 - ETA: 5s - loss: 0.5890 - accuracy: 0.66 - ETA: 5s - loss: 0.5889 - accuracy: 0.66 - ETA: 5s - loss: 0.5887 - accuracy: 0.66 - ETA: 5s - loss: 0.5904 - accuracy: 0.66 - ETA: 5s - loss: 0.5900 - accuracy: 0.66 - ETA: 5s - loss: 0.5893 - accuracy: 0.66 - ETA: 5s - loss: 0.5891 - accuracy: 0.66 - ETA: 5s - loss: 0.5889 - accuracy: 0.66 - ETA: 4s - loss: 0.5887 - accuracy: 0.66 - ETA: 4s - loss: 0.5883 - accuracy: 0.66 - ETA: 4s - loss: 0.5885 - accuracy: 0.66 - ETA: 4s - loss: 0.5880 - accuracy: 0.66 - ETA: 4s - loss: 0.5882 - accuracy: 0.66 - ETA: 4s - loss: 0.5878 - accuracy: 0.66 - ETA: 4s - loss: 0.5874 - accuracy: 0.67 - ETA: 4s - loss: 0.5867 - accuracy: 0.67 - ETA: 4s - loss: 0.5865 - accuracy: 0.67 - ETA: 4s - loss: 0.5859 - accuracy: 0.67 - ETA: 3s - loss: 0.5854 - accuracy: 0.67 - ETA: 3s - loss: 0.5854 - accuracy: 0.67 - ETA: 3s - loss: 0.5862 - accuracy: 0.67 - ETA: 3s - loss: 0.5867 - accuracy: 0.67 - ETA: 3s - loss: 0.5868 - accuracy: 0.67 - ETA: 3s - loss: 0.5870 - accuracy: 0.67 - ETA: 3s - loss: 0.5868 - accuracy: 0.67 - ETA: 3s - loss: 0.5869 - accuracy: 0.67 - ETA: 3s - loss: 0.5864 - accuracy: 0.67 - ETA: 2s - loss: 0.5868 - accuracy: 0.67 - ETA: 2s - loss: 0.5870 - accuracy: 0.67 - ETA: 2s - loss: 0.5872 - accuracy: 0.67 - ETA: 2s - loss: 0.5870 - accuracy: 0.67 - ETA: 2s - loss: 0.5871 - accuracy: 0.67 - ETA: 2s - loss: 0.5869 - accuracy: 0.67 - ETA: 2s - loss: 0.5862 - accuracy: 0.67 - ETA: 2s - loss: 0.5863 - accuracy: 0.67 - ETA: 2s - loss: 0.5868 - accuracy: 0.67 - ETA: 1s - loss: 0.5867 - accuracy: 0.67 - ETA: 1s - loss: 0.5870 - accuracy: 0.67 - ETA: 1s - loss: 0.5870 - accuracy: 0.67 - ETA: 1s - loss: 0.5875 - accuracy: 0.67 - ETA: 1s - loss: 0.5879 - accuracy: 0.66 - ETA: 1s - loss: 0.5882 - accuracy: 0.66 - ETA: 1s - loss: 0.5882 - accuracy: 0.66 - ETA: 1s - loss: 0.5889 - accuracy: 0.66 - ETA: 1s - loss: 0.5888 - accuracy: 0.66 - ETA: 0s - loss: 0.5894 - accuracy: 0.66 - ETA: 0s - loss: 0.5894 - accuracy: 0.66 - ETA: 0s - loss: 0.5898 - accuracy: 0.66 - ETA: 0s - loss: 0.5896 - accuracy: 0.66 - ETA: 0s - loss: 0.5896 - accuracy: 0.66 - ETA: 0s - loss: 0.5898 - accuracy: 0.66 - ETA: 0s - loss: 0.5900 - accuracy: 0.66 - ETA: 0s - loss: 0.5899 - accuracy: 0.66 - ETA: 0s - loss: 0.5901 - accuracy: 0.66 - 9s 222us/step - loss: 0.5904 - accuracy: 0.6662\n",
      "\n",
      "Epoch 00050: loss improved from 0.59319 to 0.59038, saving model to Resultados/Embed_promedio/Checkpoints/word2vec-50-0.5904.hdf5\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_41 (LSTM)               (None, 1, 64)             93440     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_42 (LSTM)               (None, 512)               1181696   \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,275,649\n",
      "Trainable params: 1,275,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "time: 7min 45s\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(reshape_x_train, y_train,\n",
    "          epochs=best_bayes_params['nb_epochs'], \n",
    "          batch_size=best_bayes_params['batch_size'], callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "model.save(folder + '/keras_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1589755595730,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "mdsR4Qngv5Q1",
    "outputId": "433bbcf6-d6eb-44c1-a1bb-afee72ac0ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.497989\n",
      "time: 1.7 s\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(reshape_x_test, y_test, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.save_checkpoint()\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28 ms\n"
     ]
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.save_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Resultados/Embed_promedio/RNN_Model_Base.ipynb'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.02 ms\n"
     ]
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "copyfile('RNN_Model_Base.ipynb', folder + '/RNN_Model_Base.ipynb' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVoOQQrAbpy2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 278 ms\n"
     ]
    }
   ],
   "source": [
    "# # Selecciono el archivo con el que se corre el modelo\n",
    "# data = embeddings_sum_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iGzSZUEzbvLs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 95 ms\n"
     ]
    }
   ],
   "source": [
    "# # Se separa en train y test\n",
    "# x_train = data.drop([data.columns[0],\"Top\",\"Label\", \"Date\"], axis=1)[:num_training]\n",
    "# x_test = data.drop([data.columns[0],\"Top\",'Label', 'Date'], axis=1)[num_training:]\n",
    "# y_train = data[\"Label\"].values[:num_training]\n",
    "# y_test = data[\"Label\"].values[num_training:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 915,
     "status": "ok",
     "timestamp": 1589753651752,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "EdyQX-X3mEde",
    "outputId": "3f319356-30f7-414a-8ad8-c5997b17efcd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 240 ms\n"
     ]
    }
   ],
   "source": [
    "# x_train_array = x_train.to_numpy()\n",
    "# reshape_x_train = x_train_array.reshape(40268, 1, 300)\n",
    "# reshape_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1207,
     "status": "ok",
     "timestamp": 1589753654795,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "TiRmnmDvsagi",
    "outputId": "1fcf3a9b-7bd2-4981-e024-828e7b11aa1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 147 ms\n"
     ]
    }
   ],
   "source": [
    "# x_test_array = x_test.to_numpy()\n",
    "# reshape_x_test = x_test_array.reshape(9450, 1, 300)\n",
    "# reshape_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJZBoIl-nFDg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 103 ms\n"
     ]
    }
   ],
   "source": [
    "# from numpy.testing import assert_allclose\n",
    "# from keras.models import Sequential, load_model\n",
    "# from keras.layers import LSTM, Dropout, Dense\n",
    "# from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIKq7z8tnIWl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 105 ms\n"
     ]
    }
   ],
   "source": [
    "# n_units = 10\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(n_units, input_shape=(1,300), return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(n_units, return_sequences=False))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# #model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# # compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# # define the checkpoint\n",
    "# filepath=\"word2vec-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "# callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3944,
     "status": "ok",
     "timestamp": 1589755592715,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "JsHgNLFnnTLN",
    "outputId": "4c22910d-c7b2-4dff-eb32-15c2574174ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 141 ms\n"
     ]
    }
   ],
   "source": [
    "# # fit the model\n",
    "# model.fit(reshape_x_train, y_train, epochs=50, batch_size=500, callbacks=callbacks_list)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1589755595730,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "mdsR4Qngv5Q1",
    "outputId": "433bbcf6-d6eb-44c1-a1bb-afee72ac0ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 161 ms\n"
     ]
    }
   ],
   "source": [
    "# # evaluate the model\n",
    "# loss, accuracy = model.evaluate(reshape_x_test, y_test, verbose=0)\n",
    "# print('Accuracy: %f' % (accuracy))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNhtKTbzPEwz7PyaEe0FkIO",
   "collapsed_sections": [],
   "name": "RNN - Meli.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
