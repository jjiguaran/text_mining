{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4dLP23xZmpC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Ed\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "# Importar librerias\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import zipfile\n",
    "from datetime import date\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, GlobalMaxPool1D, Conv1D, Flatten,  MaxPooling1D, Activation, GlobalMaxPooling1D, Bidirectional, GRU\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNGRU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10 ms\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exists\n",
      "time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "exp_name = '7_b'\n",
    "folder = 'Resultados/' + exp_name\n",
    "my_file = Path(folder)\n",
    "if os.path.exists(my_file):\n",
    "    print('already exists')\n",
    "else:\n",
    "    os.makedirs(folder)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exists\n",
      "time: 146 ms\n"
     ]
    }
   ],
   "source": [
    "ch_folder = folder + '/Checkpoints'\n",
    "my_file = Path(ch_folder)\n",
    "if os.path.exists(my_file):\n",
    "    print('already exists')\n",
    "else:\n",
    "    os.makedirs(ch_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nzv66BqFbl92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>Top</th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49649</th>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.050684</td>\n",
       "      <td>-0.078711</td>\n",
       "      <td>0.069385</td>\n",
       "      <td>-0.120630</td>\n",
       "      <td>0.095508</td>\n",
       "      <td>0.036621</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.096631</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.134375</td>\n",
       "      <td>-0.150244</td>\n",
       "      <td>-0.100488</td>\n",
       "      <td>0.123291</td>\n",
       "      <td>0.020605</td>\n",
       "      <td>0.104590</td>\n",
       "      <td>0.079565</td>\n",
       "      <td>0.159546</td>\n",
       "      <td>-0.014038</td>\n",
       "      <td>-0.019336</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>-0.091040</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>0.007471</td>\n",
       "      <td>-0.058362</td>\n",
       "      <td>-0.175696</td>\n",
       "      <td>0.052246</td>\n",
       "      <td>-0.047949</td>\n",
       "      <td>0.057214</td>\n",
       "      <td>-0.001563</td>\n",
       "      <td>-0.074683</td>\n",
       "      <td>-0.089453</td>\n",
       "      <td>-0.136575</td>\n",
       "      <td>-0.035522</td>\n",
       "      <td>-0.044775</td>\n",
       "      <td>-0.084277</td>\n",
       "      <td>-0.087115</td>\n",
       "      <td>0.092236</td>\n",
       "      <td>-0.074023</td>\n",
       "      <td>0.171582</td>\n",
       "      <td>0.055505</td>\n",
       "      <td>-0.031738</td>\n",
       "      <td>0.079736</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.062964</td>\n",
       "      <td>-0.156643</td>\n",
       "      <td>0.037891</td>\n",
       "      <td>0.053223</td>\n",
       "      <td>-0.184277</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>-0.042213</td>\n",
       "      <td>0.110443</td>\n",
       "      <td>-0.159143</td>\n",
       "      <td>0.075684</td>\n",
       "      <td>0.050726</td>\n",
       "      <td>-0.124219</td>\n",
       "      <td>-0.053876</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.046753</td>\n",
       "      <td>-0.142627</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.062012</td>\n",
       "      <td>0.155615</td>\n",
       "      <td>-0.119690</td>\n",
       "      <td>0.023047</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>-0.012073</td>\n",
       "      <td>0.052051</td>\n",
       "      <td>-0.038714</td>\n",
       "      <td>0.096625</td>\n",
       "      <td>0.032764</td>\n",
       "      <td>-0.105762</td>\n",
       "      <td>0.075488</td>\n",
       "      <td>-0.013354</td>\n",
       "      <td>-0.159668</td>\n",
       "      <td>-0.022070</td>\n",
       "      <td>-0.127051</td>\n",
       "      <td>-0.002856</td>\n",
       "      <td>0.020410</td>\n",
       "      <td>0.096093</td>\n",
       "      <td>0.051074</td>\n",
       "      <td>-0.160498</td>\n",
       "      <td>-0.044824</td>\n",
       "      <td>0.037259</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>0.038721</td>\n",
       "      <td>-0.170763</td>\n",
       "      <td>0.044312</td>\n",
       "      <td>-0.043982</td>\n",
       "      <td>-0.170801</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>-0.107178</td>\n",
       "      <td>-0.018710</td>\n",
       "      <td>-0.023686</td>\n",
       "      <td>0.083203</td>\n",
       "      <td>-0.066431</td>\n",
       "      <td>0.240039</td>\n",
       "      <td>0.015967</td>\n",
       "      <td>0.080176</td>\n",
       "      <td>0.083057</td>\n",
       "      <td>0.085913</td>\n",
       "      <td>0.160815</td>\n",
       "      <td>-0.024756</td>\n",
       "      <td>0.089258</td>\n",
       "      <td>0.134863</td>\n",
       "      <td>-0.183105</td>\n",
       "      <td>0.093701</td>\n",
       "      <td>-0.032422</td>\n",
       "      <td>-0.030859</td>\n",
       "      <td>-0.171924</td>\n",
       "      <td>-0.070312</td>\n",
       "      <td>-0.000861</td>\n",
       "      <td>0.073975</td>\n",
       "      <td>-0.145459</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>-0.124481</td>\n",
       "      <td>-0.067749</td>\n",
       "      <td>-0.072168</td>\n",
       "      <td>0.152429</td>\n",
       "      <td>0.090430</td>\n",
       "      <td>-0.165698</td>\n",
       "      <td>0.082666</td>\n",
       "      <td>-0.073535</td>\n",
       "      <td>-0.021973</td>\n",
       "      <td>-0.027893</td>\n",
       "      <td>-0.214258</td>\n",
       "      <td>0.093848</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.018594</td>\n",
       "      <td>0.048389</td>\n",
       "      <td>0.057397</td>\n",
       "      <td>0.013354</td>\n",
       "      <td>-0.235205</td>\n",
       "      <td>-0.159955</td>\n",
       "      <td>-0.205176</td>\n",
       "      <td>-0.246289</td>\n",
       "      <td>-0.039508</td>\n",
       "      <td>0.218457</td>\n",
       "      <td>-0.163428</td>\n",
       "      <td>0.123743</td>\n",
       "      <td>0.073145</td>\n",
       "      <td>-0.007524</td>\n",
       "      <td>-0.051318</td>\n",
       "      <td>0.064874</td>\n",
       "      <td>0.069727</td>\n",
       "      <td>-0.036743</td>\n",
       "      <td>-0.072217</td>\n",
       "      <td>-0.016357</td>\n",
       "      <td>-0.172266</td>\n",
       "      <td>-0.006573</td>\n",
       "      <td>0.173486</td>\n",
       "      <td>-0.005371</td>\n",
       "      <td>-0.003857</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>-0.031494</td>\n",
       "      <td>-0.094775</td>\n",
       "      <td>0.090625</td>\n",
       "      <td>-0.196759</td>\n",
       "      <td>-0.032446</td>\n",
       "      <td>-0.116797</td>\n",
       "      <td>0.097949</td>\n",
       "      <td>0.073145</td>\n",
       "      <td>0.187024</td>\n",
       "      <td>-0.023914</td>\n",
       "      <td>-0.021729</td>\n",
       "      <td>-0.093010</td>\n",
       "      <td>0.054492</td>\n",
       "      <td>0.035657</td>\n",
       "      <td>-0.014432</td>\n",
       "      <td>-0.093689</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>-0.125958</td>\n",
       "      <td>-0.115039</td>\n",
       "      <td>-0.030200</td>\n",
       "      <td>-0.080908</td>\n",
       "      <td>0.124854</td>\n",
       "      <td>-0.017725</td>\n",
       "      <td>0.061914</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>-0.130652</td>\n",
       "      <td>-0.037939</td>\n",
       "      <td>0.100732</td>\n",
       "      <td>-0.101514</td>\n",
       "      <td>0.065918</td>\n",
       "      <td>0.064258</td>\n",
       "      <td>-0.105762</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>0.134717</td>\n",
       "      <td>-0.051904</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.099512</td>\n",
       "      <td>0.149072</td>\n",
       "      <td>-0.068091</td>\n",
       "      <td>-0.006396</td>\n",
       "      <td>0.045746</td>\n",
       "      <td>-0.036450</td>\n",
       "      <td>-0.158325</td>\n",
       "      <td>-0.030737</td>\n",
       "      <td>0.049097</td>\n",
       "      <td>0.045508</td>\n",
       "      <td>-0.149609</td>\n",
       "      <td>0.038666</td>\n",
       "      <td>0.093359</td>\n",
       "      <td>0.014551</td>\n",
       "      <td>-0.016589</td>\n",
       "      <td>-0.057178</td>\n",
       "      <td>0.11460</td>\n",
       "      <td>-0.064404</td>\n",
       "      <td>-0.166699</td>\n",
       "      <td>0.026172</td>\n",
       "      <td>-0.048755</td>\n",
       "      <td>-0.047766</td>\n",
       "      <td>-0.108203</td>\n",
       "      <td>-0.067676</td>\n",
       "      <td>0.05293</td>\n",
       "      <td>0.105859</td>\n",
       "      <td>-0.162329</td>\n",
       "      <td>-0.151929</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>-0.007690</td>\n",
       "      <td>0.120850</td>\n",
       "      <td>-0.032813</td>\n",
       "      <td>-0.003711</td>\n",
       "      <td>-0.147778</td>\n",
       "      <td>0.150977</td>\n",
       "      <td>-0.049023</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.169336</td>\n",
       "      <td>0.044727</td>\n",
       "      <td>-0.014014</td>\n",
       "      <td>-0.022339</td>\n",
       "      <td>-0.033347</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>-0.022852</td>\n",
       "      <td>0.067737</td>\n",
       "      <td>0.113086</td>\n",
       "      <td>-0.056299</td>\n",
       "      <td>0.023663</td>\n",
       "      <td>-0.058374</td>\n",
       "      <td>0.073743</td>\n",
       "      <td>-0.199902</td>\n",
       "      <td>0.022217</td>\n",
       "      <td>0.091113</td>\n",
       "      <td>-0.015039</td>\n",
       "      <td>0.064966</td>\n",
       "      <td>-0.006104</td>\n",
       "      <td>-0.209302</td>\n",
       "      <td>0.096289</td>\n",
       "      <td>0.058203</td>\n",
       "      <td>0.109180</td>\n",
       "      <td>-0.001855</td>\n",
       "      <td>-0.074133</td>\n",
       "      <td>-0.156067</td>\n",
       "      <td>-0.010223</td>\n",
       "      <td>0.082349</td>\n",
       "      <td>-0.107092</td>\n",
       "      <td>0.155078</td>\n",
       "      <td>-0.066010</td>\n",
       "      <td>0.070361</td>\n",
       "      <td>-0.042505</td>\n",
       "      <td>0.131006</td>\n",
       "      <td>0.076392</td>\n",
       "      <td>-0.072461</td>\n",
       "      <td>-0.046094</td>\n",
       "      <td>0.154224</td>\n",
       "      <td>-0.020947</td>\n",
       "      <td>-0.030371</td>\n",
       "      <td>0.039795</td>\n",
       "      <td>0.204150</td>\n",
       "      <td>0.089087</td>\n",
       "      <td>-0.191699</td>\n",
       "      <td>-0.013916</td>\n",
       "      <td>-0.139600</td>\n",
       "      <td>-0.072852</td>\n",
       "      <td>-0.053857</td>\n",
       "      <td>-0.142529</td>\n",
       "      <td>0.057910</td>\n",
       "      <td>0.062061</td>\n",
       "      <td>-0.052393</td>\n",
       "      <td>0.167090</td>\n",
       "      <td>0.058887</td>\n",
       "      <td>-0.076538</td>\n",
       "      <td>-0.095724</td>\n",
       "      <td>-0.230847</td>\n",
       "      <td>0.036865</td>\n",
       "      <td>0.106544</td>\n",
       "      <td>0.180566</td>\n",
       "      <td>0.070203</td>\n",
       "      <td>0.108008</td>\n",
       "      <td>-0.031592</td>\n",
       "      <td>-0.192676</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>0.075034</td>\n",
       "      <td>0.023315</td>\n",
       "      <td>-0.095508</td>\n",
       "      <td>0.155450</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>24</td>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1759</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49650</th>\n",
       "      <td>0.073608</td>\n",
       "      <td>0.090820</td>\n",
       "      <td>-0.069580</td>\n",
       "      <td>-0.088684</td>\n",
       "      <td>-0.126465</td>\n",
       "      <td>-0.135132</td>\n",
       "      <td>-0.096680</td>\n",
       "      <td>-0.334961</td>\n",
       "      <td>0.136230</td>\n",
       "      <td>0.150879</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>-0.105713</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.161499</td>\n",
       "      <td>-0.276367</td>\n",
       "      <td>-0.014648</td>\n",
       "      <td>-0.018066</td>\n",
       "      <td>-0.157227</td>\n",
       "      <td>0.057129</td>\n",
       "      <td>-0.074219</td>\n",
       "      <td>0.015472</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.104340</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.035583</td>\n",
       "      <td>-0.005859</td>\n",
       "      <td>0.050232</td>\n",
       "      <td>-0.231201</td>\n",
       "      <td>0.066406</td>\n",
       "      <td>0.112549</td>\n",
       "      <td>0.104164</td>\n",
       "      <td>-0.083252</td>\n",
       "      <td>-0.042847</td>\n",
       "      <td>-0.089844</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>-0.015259</td>\n",
       "      <td>0.102051</td>\n",
       "      <td>-0.054443</td>\n",
       "      <td>0.074585</td>\n",
       "      <td>0.190308</td>\n",
       "      <td>0.149658</td>\n",
       "      <td>0.069946</td>\n",
       "      <td>0.135742</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.017212</td>\n",
       "      <td>-0.115723</td>\n",
       "      <td>0.014465</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.134766</td>\n",
       "      <td>0.052979</td>\n",
       "      <td>0.127441</td>\n",
       "      <td>0.041626</td>\n",
       "      <td>-0.037476</td>\n",
       "      <td>0.186035</td>\n",
       "      <td>-0.058472</td>\n",
       "      <td>0.020264</td>\n",
       "      <td>-0.024414</td>\n",
       "      <td>-0.101318</td>\n",
       "      <td>0.059448</td>\n",
       "      <td>-0.038818</td>\n",
       "      <td>-0.018188</td>\n",
       "      <td>0.194824</td>\n",
       "      <td>-0.150024</td>\n",
       "      <td>0.104996</td>\n",
       "      <td>-0.084717</td>\n",
       "      <td>-0.017090</td>\n",
       "      <td>-0.228516</td>\n",
       "      <td>-0.140137</td>\n",
       "      <td>-0.166992</td>\n",
       "      <td>-0.025635</td>\n",
       "      <td>0.056763</td>\n",
       "      <td>0.053955</td>\n",
       "      <td>-0.024170</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>-0.187988</td>\n",
       "      <td>-0.006149</td>\n",
       "      <td>0.095215</td>\n",
       "      <td>-0.068298</td>\n",
       "      <td>0.083374</td>\n",
       "      <td>-0.022217</td>\n",
       "      <td>0.172363</td>\n",
       "      <td>-0.237793</td>\n",
       "      <td>-0.091675</td>\n",
       "      <td>0.073486</td>\n",
       "      <td>-0.096924</td>\n",
       "      <td>-0.298096</td>\n",
       "      <td>-0.056396</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>-0.009766</td>\n",
       "      <td>-0.056641</td>\n",
       "      <td>0.118530</td>\n",
       "      <td>-0.108398</td>\n",
       "      <td>-0.208496</td>\n",
       "      <td>0.016373</td>\n",
       "      <td>0.094238</td>\n",
       "      <td>0.097534</td>\n",
       "      <td>0.108337</td>\n",
       "      <td>0.149597</td>\n",
       "      <td>0.069336</td>\n",
       "      <td>0.243896</td>\n",
       "      <td>-0.097191</td>\n",
       "      <td>-0.044495</td>\n",
       "      <td>0.030579</td>\n",
       "      <td>-0.127319</td>\n",
       "      <td>0.216476</td>\n",
       "      <td>-0.082153</td>\n",
       "      <td>-0.138916</td>\n",
       "      <td>-0.220703</td>\n",
       "      <td>0.077881</td>\n",
       "      <td>-0.020264</td>\n",
       "      <td>0.236877</td>\n",
       "      <td>-0.114258</td>\n",
       "      <td>-0.154053</td>\n",
       "      <td>0.232910</td>\n",
       "      <td>-0.101074</td>\n",
       "      <td>-0.201172</td>\n",
       "      <td>0.088623</td>\n",
       "      <td>0.144287</td>\n",
       "      <td>-0.002197</td>\n",
       "      <td>0.283691</td>\n",
       "      <td>0.052490</td>\n",
       "      <td>0.333496</td>\n",
       "      <td>-0.053711</td>\n",
       "      <td>0.044067</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>-0.104004</td>\n",
       "      <td>-0.086182</td>\n",
       "      <td>-0.043671</td>\n",
       "      <td>0.077148</td>\n",
       "      <td>0.148682</td>\n",
       "      <td>0.055725</td>\n",
       "      <td>-0.035156</td>\n",
       "      <td>0.074707</td>\n",
       "      <td>-0.068359</td>\n",
       "      <td>-0.011810</td>\n",
       "      <td>0.112152</td>\n",
       "      <td>0.275391</td>\n",
       "      <td>-0.065193</td>\n",
       "      <td>-0.439453</td>\n",
       "      <td>0.074341</td>\n",
       "      <td>-0.019775</td>\n",
       "      <td>-0.073242</td>\n",
       "      <td>-0.083008</td>\n",
       "      <td>0.150391</td>\n",
       "      <td>-0.065430</td>\n",
       "      <td>0.124695</td>\n",
       "      <td>-0.078613</td>\n",
       "      <td>0.101807</td>\n",
       "      <td>-0.030762</td>\n",
       "      <td>-0.225098</td>\n",
       "      <td>0.467041</td>\n",
       "      <td>-0.142578</td>\n",
       "      <td>0.070618</td>\n",
       "      <td>0.184814</td>\n",
       "      <td>-0.049103</td>\n",
       "      <td>-0.184082</td>\n",
       "      <td>0.024933</td>\n",
       "      <td>0.085571</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>-0.153687</td>\n",
       "      <td>-0.020996</td>\n",
       "      <td>0.092285</td>\n",
       "      <td>0.117310</td>\n",
       "      <td>-0.215942</td>\n",
       "      <td>-0.115143</td>\n",
       "      <td>0.187378</td>\n",
       "      <td>0.262695</td>\n",
       "      <td>-0.063721</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.202637</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.166504</td>\n",
       "      <td>-0.168945</td>\n",
       "      <td>-0.224609</td>\n",
       "      <td>-0.033386</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.225098</td>\n",
       "      <td>-0.079712</td>\n",
       "      <td>-0.113525</td>\n",
       "      <td>0.084961</td>\n",
       "      <td>-0.257324</td>\n",
       "      <td>-0.015869</td>\n",
       "      <td>-0.133789</td>\n",
       "      <td>-0.320312</td>\n",
       "      <td>0.165771</td>\n",
       "      <td>-0.292480</td>\n",
       "      <td>-0.020752</td>\n",
       "      <td>0.072754</td>\n",
       "      <td>-0.084839</td>\n",
       "      <td>0.069092</td>\n",
       "      <td>0.035198</td>\n",
       "      <td>0.018799</td>\n",
       "      <td>0.104736</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>-0.112061</td>\n",
       "      <td>0.046021</td>\n",
       "      <td>-0.188477</td>\n",
       "      <td>0.086792</td>\n",
       "      <td>-0.155884</td>\n",
       "      <td>0.007324</td>\n",
       "      <td>0.155029</td>\n",
       "      <td>0.203003</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>0.068481</td>\n",
       "      <td>0.030701</td>\n",
       "      <td>0.070190</td>\n",
       "      <td>-0.297363</td>\n",
       "      <td>0.20166</td>\n",
       "      <td>-0.021973</td>\n",
       "      <td>-0.176086</td>\n",
       "      <td>-0.018555</td>\n",
       "      <td>0.100830</td>\n",
       "      <td>0.077271</td>\n",
       "      <td>-0.143433</td>\n",
       "      <td>0.030304</td>\n",
       "      <td>-0.09021</td>\n",
       "      <td>-0.142334</td>\n",
       "      <td>-0.226318</td>\n",
       "      <td>-0.059570</td>\n",
       "      <td>0.246582</td>\n",
       "      <td>-0.049927</td>\n",
       "      <td>0.216553</td>\n",
       "      <td>-0.128418</td>\n",
       "      <td>-0.072021</td>\n",
       "      <td>-0.058594</td>\n",
       "      <td>-0.065308</td>\n",
       "      <td>-0.057007</td>\n",
       "      <td>0.020020</td>\n",
       "      <td>0.082642</td>\n",
       "      <td>-0.013641</td>\n",
       "      <td>-0.182129</td>\n",
       "      <td>0.018066</td>\n",
       "      <td>0.152588</td>\n",
       "      <td>-0.097046</td>\n",
       "      <td>-0.043701</td>\n",
       "      <td>0.066650</td>\n",
       "      <td>-0.152222</td>\n",
       "      <td>0.190308</td>\n",
       "      <td>-0.142578</td>\n",
       "      <td>-0.068115</td>\n",
       "      <td>0.157715</td>\n",
       "      <td>-0.093140</td>\n",
       "      <td>-0.064453</td>\n",
       "      <td>-0.188721</td>\n",
       "      <td>0.280273</td>\n",
       "      <td>0.023621</td>\n",
       "      <td>-0.118164</td>\n",
       "      <td>-0.089844</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.078857</td>\n",
       "      <td>-0.029785</td>\n",
       "      <td>-0.040039</td>\n",
       "      <td>0.061401</td>\n",
       "      <td>0.183838</td>\n",
       "      <td>0.067871</td>\n",
       "      <td>0.260254</td>\n",
       "      <td>-0.113647</td>\n",
       "      <td>0.161095</td>\n",
       "      <td>-0.115967</td>\n",
       "      <td>0.018799</td>\n",
       "      <td>-0.083252</td>\n",
       "      <td>-0.061646</td>\n",
       "      <td>0.234863</td>\n",
       "      <td>-0.187012</td>\n",
       "      <td>0.211304</td>\n",
       "      <td>-0.074341</td>\n",
       "      <td>-0.036133</td>\n",
       "      <td>-0.095703</td>\n",
       "      <td>-0.222900</td>\n",
       "      <td>-0.005318</td>\n",
       "      <td>0.234863</td>\n",
       "      <td>-0.114136</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.228271</td>\n",
       "      <td>0.125244</td>\n",
       "      <td>-0.066895</td>\n",
       "      <td>0.083984</td>\n",
       "      <td>-0.018311</td>\n",
       "      <td>-0.027344</td>\n",
       "      <td>-0.074341</td>\n",
       "      <td>-0.140503</td>\n",
       "      <td>-0.073059</td>\n",
       "      <td>0.069946</td>\n",
       "      <td>-0.080322</td>\n",
       "      <td>-0.133789</td>\n",
       "      <td>-0.123291</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.012451</td>\n",
       "      <td>0.136688</td>\n",
       "      <td>-0.030518</td>\n",
       "      <td>-0.094360</td>\n",
       "      <td>-0.106689</td>\n",
       "      <td>-0.097900</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>-0.075684</td>\n",
       "      <td>-0.137268</td>\n",
       "      <td>-0.020630</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>25</td>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5175</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.2274</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6         7         8         9        10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32        33        34        35        36        37        38        39        40        41        42        43        44        45        46        47        48        49        50        51        52        53        54        55        56        57        58        59        60        61        62        63        64        65        66        67        68        69        70        71        72        73        74        75        76        77        78        79        80        81        82        83        84        85        86        87        88        89        90        91        92        93        94        95        96        97        98  \\\n",
       "49649  0.000830  0.050684 -0.078711  0.069385 -0.120630  0.095508  0.036621  0.002893  0.096631  0.027344  0.134375 -0.150244 -0.100488  0.123291  0.020605  0.104590  0.079565  0.159546 -0.014038 -0.019336  0.005188 -0.091040  0.018677  0.007471 -0.058362 -0.175696  0.052246 -0.047949  0.057214 -0.001563 -0.074683 -0.089453 -0.136575 -0.035522 -0.044775 -0.084277 -0.087115  0.092236 -0.074023  0.171582  0.055505 -0.031738  0.079736  0.000439  0.062964 -0.156643  0.037891  0.053223 -0.184277  0.015015 -0.042213  0.110443 -0.159143  0.075684  0.050726 -0.124219 -0.053876  0.066498  0.046753 -0.142627  0.001953  0.062012  0.155615 -0.119690  0.023047  0.107422 -0.012073  0.052051 -0.038714  0.096625  0.032764 -0.105762  0.075488 -0.013354 -0.159668 -0.022070 -0.127051 -0.002856  0.020410  0.096093  0.051074 -0.160498 -0.044824  0.037259  0.032520  0.038721 -0.170763  0.044312 -0.043982 -0.170801  0.001929 -0.107178 -0.018710 -0.023686  0.083203 -0.066431  0.240039  0.015967  0.080176   \n",
       "49650  0.073608  0.090820 -0.069580 -0.088684 -0.126465 -0.135132 -0.096680 -0.334961  0.136230  0.150879  0.071289 -0.105713  0.033203  0.161499 -0.276367 -0.014648 -0.018066 -0.157227  0.057129 -0.074219  0.015472  0.008789  0.104340  0.011719  0.035583 -0.005859  0.050232 -0.231201  0.066406  0.112549  0.104164 -0.083252 -0.042847 -0.089844 -0.002022 -0.015259  0.102051 -0.054443  0.074585  0.190308  0.149658  0.069946  0.135742  0.164062  0.017212 -0.115723  0.014465  0.089844  0.134766  0.052979  0.127441  0.041626 -0.037476  0.186035 -0.058472  0.020264 -0.024414 -0.101318  0.059448 -0.038818 -0.018188  0.194824 -0.150024  0.104996 -0.084717 -0.017090 -0.228516 -0.140137 -0.166992 -0.025635  0.056763  0.053955 -0.024170  0.106445 -0.187988 -0.006149  0.095215 -0.068298  0.083374 -0.022217  0.172363 -0.237793 -0.091675  0.073486 -0.096924 -0.298096 -0.056396  0.033203 -0.009766 -0.056641  0.118530 -0.108398 -0.208496  0.016373  0.094238  0.097534  0.108337  0.149597  0.069336   \n",
       "\n",
       "             99       100       101       102       103       104       105       106       107       108       109       110       111       112       113       114       115       116       117       118       119       120       121       122       123       124       125       126       127       128       129       130       131       132       133       134       135       136       137       138       139       140       141       142       143       144       145       146       147       148       149       150       151       152       153       154       155       156       157       158       159       160       161       162       163       164       165       166       167       168       169       170       171       172       173       174       175       176       177       178       179       180       181       182       183       184       185       186       187       188       189       190       191       192       193       194       195       196       197  \\\n",
       "49649  0.083057  0.085913  0.160815 -0.024756  0.089258  0.134863 -0.183105  0.093701 -0.032422 -0.030859 -0.171924 -0.070312 -0.000861  0.073975 -0.145459  0.006323 -0.124481 -0.067749 -0.072168  0.152429  0.090430 -0.165698  0.082666 -0.073535 -0.021973 -0.027893 -0.214258  0.093848  0.023438  0.018594  0.048389  0.057397  0.013354 -0.235205 -0.159955 -0.205176 -0.246289 -0.039508  0.218457 -0.163428  0.123743  0.073145 -0.007524 -0.051318  0.064874  0.069727 -0.036743 -0.072217 -0.016357 -0.172266 -0.006573  0.173486 -0.005371 -0.003857  0.003418 -0.031494 -0.094775  0.090625 -0.196759 -0.032446 -0.116797  0.097949  0.073145  0.187024 -0.023914 -0.021729 -0.093010  0.054492  0.035657 -0.014432 -0.093689  0.002148 -0.012500 -0.125958 -0.115039 -0.030200 -0.080908  0.124854 -0.017725  0.061914  0.010327 -0.130652 -0.037939  0.100732 -0.101514  0.065918  0.064258 -0.105762  0.006689  0.008521  0.134717 -0.051904  0.046875  0.099512  0.149072 -0.068091 -0.006396  0.045746 -0.036450   \n",
       "49650  0.243896 -0.097191 -0.044495  0.030579 -0.127319  0.216476 -0.082153 -0.138916 -0.220703  0.077881 -0.020264  0.236877 -0.114258 -0.154053  0.232910 -0.101074 -0.201172  0.088623  0.144287 -0.002197  0.283691  0.052490  0.333496 -0.053711  0.044067  0.132812 -0.104004 -0.086182 -0.043671  0.077148  0.148682  0.055725 -0.035156  0.074707 -0.068359 -0.011810  0.112152  0.275391 -0.065193 -0.439453  0.074341 -0.019775 -0.073242 -0.083008  0.150391 -0.065430  0.124695 -0.078613  0.101807 -0.030762 -0.225098  0.467041 -0.142578  0.070618  0.184814 -0.049103 -0.184082  0.024933  0.085571  0.273438 -0.153687 -0.020996  0.092285  0.117310 -0.215942 -0.115143  0.187378  0.262695 -0.063721  0.234375  0.202637  0.008789  0.166504 -0.168945 -0.224609 -0.033386  0.132812  0.225098 -0.079712 -0.113525  0.084961 -0.257324 -0.015869 -0.133789 -0.320312  0.165771 -0.292480 -0.020752  0.072754 -0.084839  0.069092  0.035198  0.018799  0.104736  0.017578 -0.112061  0.046021 -0.188477  0.086792   \n",
       "\n",
       "            198       199       200       201       202       203       204       205       206       207      208       209       210       211       212       213       214       215      216       217       218       219       220       221       222       223       224       225       226       227       228       229       230       231       232       233       234       235       236       237       238       239       240       241       242       243       244       245       246       247       248       249       250       251       252       253       254       255       256       257       258       259       260       261       262       263       264       265       266       267       268       269       270       271       272       273       274       275       276       277       278       279       280       281       282       283       284       285       286       287       288       289       290       291       292       293       294       295       296  \\\n",
       "49649 -0.158325 -0.030737  0.049097  0.045508 -0.149609  0.038666  0.093359  0.014551 -0.016589 -0.057178  0.11460 -0.064404 -0.166699  0.026172 -0.048755 -0.047766 -0.108203 -0.067676  0.05293  0.105859 -0.162329 -0.151929  0.009521 -0.007690  0.120850 -0.032813 -0.003711 -0.147778  0.150977 -0.049023 -0.017871  0.169336  0.044727 -0.014014 -0.022339 -0.033347  0.001709 -0.017822 -0.022852  0.067737  0.113086 -0.056299  0.023663 -0.058374  0.073743 -0.199902  0.022217  0.091113 -0.015039  0.064966 -0.006104 -0.209302  0.096289  0.058203  0.109180 -0.001855 -0.074133 -0.156067 -0.010223  0.082349 -0.107092  0.155078 -0.066010  0.070361 -0.042505  0.131006  0.076392 -0.072461 -0.046094  0.154224 -0.020947 -0.030371  0.039795  0.204150  0.089087 -0.191699 -0.013916 -0.139600 -0.072852 -0.053857 -0.142529  0.057910  0.062061 -0.052393  0.167090  0.058887 -0.076538 -0.095724 -0.230847  0.036865  0.106544  0.180566  0.070203  0.108008 -0.031592 -0.192676 -0.093750  0.075034  0.023315   \n",
       "49650 -0.155884  0.007324  0.155029  0.203003  0.062073 -0.023438  0.068481  0.030701  0.070190 -0.297363  0.20166 -0.021973 -0.176086 -0.018555  0.100830  0.077271 -0.143433  0.030304 -0.09021 -0.142334 -0.226318 -0.059570  0.246582 -0.049927  0.216553 -0.128418 -0.072021 -0.058594 -0.065308 -0.057007  0.020020  0.082642 -0.013641 -0.182129  0.018066  0.152588 -0.097046 -0.043701  0.066650 -0.152222  0.190308 -0.142578 -0.068115  0.157715 -0.093140 -0.064453 -0.188721  0.280273  0.023621 -0.118164 -0.089844  0.000305  0.078857 -0.029785 -0.040039  0.061401  0.183838  0.067871  0.260254 -0.113647  0.161095 -0.115967  0.018799 -0.083252 -0.061646  0.234863 -0.187012  0.211304 -0.074341 -0.036133 -0.095703 -0.222900 -0.005318  0.234863 -0.114136 -0.187500  0.228271  0.125244 -0.066895  0.083984 -0.018311 -0.027344 -0.074341 -0.140503 -0.073059  0.069946 -0.080322 -0.133789 -0.123291  0.000488  0.012451  0.136688 -0.030518 -0.094360 -0.106689 -0.097900  0.036133 -0.075684 -0.137268   \n",
       "\n",
       "            297       298       299  Top       Date  Label  topic_0  topic_1  topic_2  topic_3  topic_4  topic_5  topic_6  topic_7  topic_8  topic_9  sentiment  \n",
       "49649 -0.095508  0.155450  0.075000   24 2008-08-08      0   0.0295   0.0222   0.0178   0.0149   0.0128   0.0113     0.01   0.1759    0.698      0.0       -0.1  \n",
       "49650 -0.020630  0.015869  0.000488   25 2008-08-08      0   0.5175   0.0141   0.0113   0.0000   0.1980   0.2274     0.00   0.0000    0.000      0.0        0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "#Importar los datasets\n",
    "url_embeddings_average_individual = zipfile.ZipFile('../Data/average_bigram_topics_sentiment.zip')\n",
    "\n",
    "embeddings_average_individual = pd.read_csv(url_embeddings_average_individual.open('average_bigram_topics_sentiment.csv'), index_col = 0)\n",
    "\n",
    "embeddings_average_individual['Date'] =  pd.to_datetime(embeddings_average_individual['Date'], format='%Y-%m-%d')\n",
    "\n",
    "embeddings_average_individual.reset_index(inplace=True)\n",
    "embeddings_average_individual.fillna(0, inplace=True)\n",
    "embeddings_average_individual.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAXOJcEcbmed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 170 ms\n"
     ]
    }
   ],
   "source": [
    "# Selecciono la fecha para la cual hago el corte de train y test\n",
    "training_end = pd.to_datetime(\"2013-12-31\")\n",
    "num_training = len(embeddings_average_individual[(embeddings_average_individual[\"Date\"]) <= training_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5418076004775169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>Top</th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9443</th>\n",
       "      <td>-0.063354</td>\n",
       "      <td>0.015055</td>\n",
       "      <td>-0.127116</td>\n",
       "      <td>0.055664</td>\n",
       "      <td>-0.07666</td>\n",
       "      <td>-0.111328</td>\n",
       "      <td>-0.004476</td>\n",
       "      <td>-0.130859</td>\n",
       "      <td>0.148763</td>\n",
       "      <td>0.015381</td>\n",
       "      <td>0.095835</td>\n",
       "      <td>-0.082113</td>\n",
       "      <td>0.023112</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>-0.063232</td>\n",
       "      <td>0.176595</td>\n",
       "      <td>0.047791</td>\n",
       "      <td>0.068827</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>0.039714</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>-0.130697</td>\n",
       "      <td>-0.138672</td>\n",
       "      <td>0.013018</td>\n",
       "      <td>0.010295</td>\n",
       "      <td>-0.103597</td>\n",
       "      <td>0.046224</td>\n",
       "      <td>0.167643</td>\n",
       "      <td>0.028768</td>\n",
       "      <td>-0.177083</td>\n",
       "      <td>0.079997</td>\n",
       "      <td>-0.026204</td>\n",
       "      <td>-0.10555</td>\n",
       "      <td>-0.044434</td>\n",
       "      <td>0.032288</td>\n",
       "      <td>-0.023071</td>\n",
       "      <td>0.133301</td>\n",
       "      <td>0.076497</td>\n",
       "      <td>0.03304</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>-0.049886</td>\n",
       "      <td>0.048991</td>\n",
       "      <td>-0.166972</td>\n",
       "      <td>-0.024577</td>\n",
       "      <td>-0.147461</td>\n",
       "      <td>0.059896</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.14091</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>-0.012817</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.062581</td>\n",
       "      <td>-0.09082</td>\n",
       "      <td>0.042013</td>\n",
       "      <td>-0.231608</td>\n",
       "      <td>0.029012</td>\n",
       "      <td>-0.036865</td>\n",
       "      <td>0.06665</td>\n",
       "      <td>0.036418</td>\n",
       "      <td>0.096842</td>\n",
       "      <td>-0.008626</td>\n",
       "      <td>-0.129781</td>\n",
       "      <td>-0.075521</td>\n",
       "      <td>-0.066447</td>\n",
       "      <td>-0.120361</td>\n",
       "      <td>-0.009572</td>\n",
       "      <td>0.056966</td>\n",
       "      <td>0.158529</td>\n",
       "      <td>0.16154</td>\n",
       "      <td>-0.03658</td>\n",
       "      <td>-0.037516</td>\n",
       "      <td>-0.003642</td>\n",
       "      <td>-0.131917</td>\n",
       "      <td>-0.201009</td>\n",
       "      <td>-0.108358</td>\n",
       "      <td>-0.025553</td>\n",
       "      <td>0.015381</td>\n",
       "      <td>-0.040436</td>\n",
       "      <td>0.02002</td>\n",
       "      <td>-0.031291</td>\n",
       "      <td>-0.091309</td>\n",
       "      <td>0.06901</td>\n",
       "      <td>-0.016602</td>\n",
       "      <td>0.061971</td>\n",
       "      <td>-0.024089</td>\n",
       "      <td>-0.119954</td>\n",
       "      <td>0.102397</td>\n",
       "      <td>-0.027995</td>\n",
       "      <td>0.075684</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.162069</td>\n",
       "      <td>-0.056152</td>\n",
       "      <td>-0.052409</td>\n",
       "      <td>-0.097493</td>\n",
       "      <td>0.134684</td>\n",
       "      <td>0.032633</td>\n",
       "      <td>-0.05717</td>\n",
       "      <td>0.018066</td>\n",
       "      <td>0.025065</td>\n",
       "      <td>-0.104533</td>\n",
       "      <td>0.061686</td>\n",
       "      <td>0.041504</td>\n",
       "      <td>-0.013387</td>\n",
       "      <td>-0.01062</td>\n",
       "      <td>0.011882</td>\n",
       "      <td>0.077637</td>\n",
       "      <td>0.152445</td>\n",
       "      <td>-0.071828</td>\n",
       "      <td>-0.009847</td>\n",
       "      <td>0.015299</td>\n",
       "      <td>-0.055908</td>\n",
       "      <td>0.00061</td>\n",
       "      <td>-0.220062</td>\n",
       "      <td>-0.024801</td>\n",
       "      <td>0.030268</td>\n",
       "      <td>0.121989</td>\n",
       "      <td>0.059082</td>\n",
       "      <td>0.096293</td>\n",
       "      <td>-0.104167</td>\n",
       "      <td>-0.1014</td>\n",
       "      <td>-0.065104</td>\n",
       "      <td>0.127686</td>\n",
       "      <td>-0.031738</td>\n",
       "      <td>-0.002238</td>\n",
       "      <td>-0.182292</td>\n",
       "      <td>-0.149495</td>\n",
       "      <td>0.057251</td>\n",
       "      <td>0.097656</td>\n",
       "      <td>0.085836</td>\n",
       "      <td>-0.180339</td>\n",
       "      <td>-0.055257</td>\n",
       "      <td>0.009542</td>\n",
       "      <td>0.064941</td>\n",
       "      <td>-0.265706</td>\n",
       "      <td>0.073486</td>\n",
       "      <td>-0.054606</td>\n",
       "      <td>-0.061198</td>\n",
       "      <td>0.127223</td>\n",
       "      <td>0.051229</td>\n",
       "      <td>-0.170736</td>\n",
       "      <td>-0.05245</td>\n",
       "      <td>0.066813</td>\n",
       "      <td>0.055216</td>\n",
       "      <td>0.15918</td>\n",
       "      <td>-0.208008</td>\n",
       "      <td>-0.182129</td>\n",
       "      <td>-0.025879</td>\n",
       "      <td>-0.073324</td>\n",
       "      <td>-0.01237</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>-0.051432</td>\n",
       "      <td>0.126363</td>\n",
       "      <td>-0.091227</td>\n",
       "      <td>-0.164185</td>\n",
       "      <td>-0.067464</td>\n",
       "      <td>-0.015137</td>\n",
       "      <td>-0.085531</td>\n",
       "      <td>0.055094</td>\n",
       "      <td>-0.141439</td>\n",
       "      <td>0.014974</td>\n",
       "      <td>-0.056966</td>\n",
       "      <td>-0.028809</td>\n",
       "      <td>-0.027262</td>\n",
       "      <td>-0.048706</td>\n",
       "      <td>0.064209</td>\n",
       "      <td>-0.163574</td>\n",
       "      <td>-0.007894</td>\n",
       "      <td>-0.114258</td>\n",
       "      <td>-0.158203</td>\n",
       "      <td>-0.058512</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>-0.056844</td>\n",
       "      <td>-0.053385</td>\n",
       "      <td>0.063354</td>\n",
       "      <td>0.063477</td>\n",
       "      <td>0.014608</td>\n",
       "      <td>-0.142253</td>\n",
       "      <td>0.080078</td>\n",
       "      <td>-0.045736</td>\n",
       "      <td>-0.042033</td>\n",
       "      <td>0.046987</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>-0.062826</td>\n",
       "      <td>-0.066081</td>\n",
       "      <td>-0.04777</td>\n",
       "      <td>0.038656</td>\n",
       "      <td>0.033529</td>\n",
       "      <td>0.038778</td>\n",
       "      <td>0.082642</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.036214</td>\n",
       "      <td>-0.152832</td>\n",
       "      <td>0.25472</td>\n",
       "      <td>-0.013672</td>\n",
       "      <td>-0.063721</td>\n",
       "      <td>-0.125651</td>\n",
       "      <td>-0.277344</td>\n",
       "      <td>-0.002991</td>\n",
       "      <td>0.078242</td>\n",
       "      <td>-0.183431</td>\n",
       "      <td>-0.183838</td>\n",
       "      <td>0.157064</td>\n",
       "      <td>0.077474</td>\n",
       "      <td>-0.017049</td>\n",
       "      <td>0.025187</td>\n",
       "      <td>-0.011759</td>\n",
       "      <td>-0.11084</td>\n",
       "      <td>-0.094686</td>\n",
       "      <td>0.106974</td>\n",
       "      <td>-0.17806</td>\n",
       "      <td>0.056348</td>\n",
       "      <td>-0.158773</td>\n",
       "      <td>0.05306</td>\n",
       "      <td>0.239258</td>\n",
       "      <td>0.140951</td>\n",
       "      <td>-0.034424</td>\n",
       "      <td>-0.002797</td>\n",
       "      <td>-0.057048</td>\n",
       "      <td>-0.156576</td>\n",
       "      <td>-0.014974</td>\n",
       "      <td>0.191121</td>\n",
       "      <td>0.015574</td>\n",
       "      <td>-0.012594</td>\n",
       "      <td>-0.008545</td>\n",
       "      <td>-0.000814</td>\n",
       "      <td>-0.024333</td>\n",
       "      <td>0.123698</td>\n",
       "      <td>0.172526</td>\n",
       "      <td>-0.055766</td>\n",
       "      <td>-0.105957</td>\n",
       "      <td>-0.061605</td>\n",
       "      <td>0.05485</td>\n",
       "      <td>0.08846</td>\n",
       "      <td>0.043294</td>\n",
       "      <td>0.020447</td>\n",
       "      <td>0.105347</td>\n",
       "      <td>-0.008301</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>-0.017853</td>\n",
       "      <td>-0.113118</td>\n",
       "      <td>-0.303304</td>\n",
       "      <td>-0.09789</td>\n",
       "      <td>0.066203</td>\n",
       "      <td>0.056315</td>\n",
       "      <td>-0.090515</td>\n",
       "      <td>-0.113118</td>\n",
       "      <td>0.047811</td>\n",
       "      <td>-0.075928</td>\n",
       "      <td>-0.015381</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>-0.019368</td>\n",
       "      <td>-0.086304</td>\n",
       "      <td>-0.051595</td>\n",
       "      <td>0.061526</td>\n",
       "      <td>0.036438</td>\n",
       "      <td>-0.060476</td>\n",
       "      <td>0.118571</td>\n",
       "      <td>0.104329</td>\n",
       "      <td>-0.006226</td>\n",
       "      <td>0.249349</td>\n",
       "      <td>0.008057</td>\n",
       "      <td>0.076986</td>\n",
       "      <td>0.111287</td>\n",
       "      <td>-0.207357</td>\n",
       "      <td>-0.124064</td>\n",
       "      <td>-0.05837</td>\n",
       "      <td>0.099202</td>\n",
       "      <td>0.141357</td>\n",
       "      <td>0.039876</td>\n",
       "      <td>0.09493</td>\n",
       "      <td>-0.094238</td>\n",
       "      <td>0.105469</td>\n",
       "      <td>-0.138835</td>\n",
       "      <td>-0.245687</td>\n",
       "      <td>-0.046631</td>\n",
       "      <td>0.069092</td>\n",
       "      <td>0.081706</td>\n",
       "      <td>0.022705</td>\n",
       "      <td>-0.067546</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.088623</td>\n",
       "      <td>0.109782</td>\n",
       "      <td>-0.175354</td>\n",
       "      <td>0.104126</td>\n",
       "      <td>-0.074707</td>\n",
       "      <td>0.083984</td>\n",
       "      <td>0.067464</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>-0.053955</td>\n",
       "      <td>0.056478</td>\n",
       "      <td>0.055176</td>\n",
       "      <td>-0.096842</td>\n",
       "      <td>-0.020833</td>\n",
       "      <td>0.071859</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>-0.068522</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9113</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3        4         5         6         7         8         9        10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32       33        34        35        36        37        38       39        40        41        42        43        44        45        46        47       48      49        50        51        52       53        54        55        56        57       58        59        60        61        62        63        64        65        66        67        68       69       70        71        72        73        74        75        76        77        78       79        80        81       82        83        84        85        86        87        88        89        90        91        92        93        94        95        96        97       98        99  \\\n",
       "9443 -0.063354  0.015055 -0.127116  0.055664 -0.07666 -0.111328 -0.004476 -0.130859  0.148763  0.015381  0.095835 -0.082113  0.023112  0.041992 -0.063232  0.176595  0.047791  0.068827  0.000814  0.072917  0.039714  0.004801 -0.130697 -0.138672  0.013018  0.010295 -0.103597  0.046224  0.167643  0.028768 -0.177083  0.079997 -0.026204 -0.10555 -0.044434  0.032288 -0.023071  0.133301  0.076497  0.03304  0.009018 -0.049886  0.048991 -0.166972 -0.024577 -0.147461  0.059896  0.010742  0.14091  0.0271 -0.012817  0.015625  0.062581 -0.09082  0.042013 -0.231608  0.029012 -0.036865  0.06665  0.036418  0.096842 -0.008626 -0.129781 -0.075521 -0.066447 -0.120361 -0.009572  0.056966  0.158529  0.16154 -0.03658 -0.037516 -0.003642 -0.131917 -0.201009 -0.108358 -0.025553  0.015381 -0.040436  0.02002 -0.031291 -0.091309  0.06901 -0.016602  0.061971 -0.024089 -0.119954  0.102397 -0.027995  0.075684  0.003418 -0.054688 -0.162069 -0.056152 -0.052409 -0.097493  0.134684  0.032633 -0.05717  0.018066   \n",
       "\n",
       "           100       101       102       103       104      105       106       107       108       109       110       111       112      113       114       115       116       117       118       119       120     121       122       123       124       125       126       127       128       129       130       131       132       133       134       135       136       137       138       139       140       141      142       143       144      145       146       147       148       149      150       151       152       153       154       155       156       157       158       159       160       161       162       163       164       165       166       167       168       169       170       171       172       173       174       175       176       177       178       179       180       181       182       183       184       185      186       187       188       189       190       191       192       193       194      195       196       197       198       199  \\\n",
       "9443  0.025065 -0.104533  0.061686  0.041504 -0.013387 -0.01062  0.011882  0.077637  0.152445 -0.071828 -0.009847  0.015299 -0.055908  0.00061 -0.220062 -0.024801  0.030268  0.121989  0.059082  0.096293 -0.104167 -0.1014 -0.065104  0.127686 -0.031738 -0.002238 -0.182292 -0.149495  0.057251  0.097656  0.085836 -0.180339 -0.055257  0.009542  0.064941 -0.265706  0.073486 -0.054606 -0.061198  0.127223  0.051229 -0.170736 -0.05245  0.066813  0.055216  0.15918 -0.208008 -0.182129 -0.025879 -0.073324 -0.01237  0.035156 -0.051432  0.126363 -0.091227 -0.164185 -0.067464 -0.015137 -0.085531  0.055094 -0.141439  0.014974 -0.056966 -0.028809 -0.027262 -0.048706  0.064209 -0.163574 -0.007894 -0.114258 -0.158203 -0.058512  0.029785 -0.056844 -0.053385  0.063354  0.063477  0.014608 -0.142253  0.080078 -0.045736 -0.042033  0.046987 -0.000651 -0.062826 -0.066081 -0.04777  0.038656  0.033529  0.038778  0.082642 -0.078125  0.050781  0.036214 -0.152832  0.25472 -0.013672 -0.063721 -0.125651 -0.277344   \n",
       "\n",
       "           200       201       202       203       204       205       206       207       208      209       210       211      212       213       214      215       216       217       218       219       220       221       222       223       224       225       226       227       228       229       230       231       232       233      234      235       236       237       238       239     240       241       242       243      244       245       246       247       248       249       250       251       252       253       254       255       256       257       258       259       260       261       262       263       264       265       266       267       268      269       270       271       272      273       274       275       276       277       278       279       280       281       282       283       284       285       286       287       288       289       290       291       292       293       294       295       296       297       298       299  \\\n",
       "9443 -0.002991  0.078242 -0.183431 -0.183838  0.157064  0.077474 -0.017049  0.025187 -0.011759 -0.11084 -0.094686  0.106974 -0.17806  0.056348 -0.158773  0.05306  0.239258  0.140951 -0.034424 -0.002797 -0.057048 -0.156576 -0.014974  0.191121  0.015574 -0.012594 -0.008545 -0.000814 -0.024333  0.123698  0.172526 -0.055766 -0.105957 -0.061605  0.05485  0.08846  0.043294  0.020447  0.105347 -0.008301 -0.0118 -0.017853 -0.113118 -0.303304 -0.09789  0.066203  0.056315 -0.090515 -0.113118  0.047811 -0.075928 -0.015381  0.018717  0.018717 -0.019368 -0.086304 -0.051595  0.061526  0.036438 -0.060476  0.118571  0.104329 -0.006226  0.249349  0.008057  0.076986  0.111287 -0.207357 -0.124064 -0.05837  0.099202  0.141357  0.039876  0.09493 -0.094238  0.105469 -0.138835 -0.245687 -0.046631  0.069092  0.081706  0.022705 -0.067546  0.114583  0.088623  0.109782 -0.175354  0.104126 -0.074707  0.083984  0.067464  0.001546 -0.053955  0.056478  0.055176 -0.096842 -0.020833  0.071859  0.132812 -0.068522   \n",
       "\n",
       "      Top       Date  Label  topic_0  topic_1  topic_2  topic_3  topic_4  topic_5  topic_6  topic_7  topic_8  topic_9  sentiment  \n",
       "9443    1 2014-12-31      0   0.9113   0.0174   0.0139   0.0116      0.0      0.0      0.0      0.0      0.0      0.0        0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 828 ms\n"
     ]
    }
   ],
   "source": [
    "# Selecciono el archivo con el que se corre el modelo\n",
    "data = embeddings_average_individual[embeddings_average_individual['Date']<='2014-12-31']\n",
    "print(data['Label'].mean())\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6294, 1, 311)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 211 ms\n"
     ]
    }
   ],
   "source": [
    "training = data[:num_training]\n",
    "testing = data[num_training:]\n",
    "\n",
    "# Se separa en train y test\n",
    "x_train = data.drop([\"Top\",\"Label\", \"Date\"], axis=1)[:num_training]\n",
    "x_test = data.drop([\"Top\",'Label', 'Date'], axis=1)[num_training:]\n",
    "y_train = data[\"Label\"].values[:num_training]\n",
    "y_test = data[\"Label\"].values[num_training:]\n",
    "\n",
    "\n",
    "x_train_array = x_train.to_numpy()\n",
    "reshape_x_train = x_train_array.reshape(len(x_train), 1, x_train.shape[1])\n",
    "reshape_x_train.shape\n",
    "\n",
    "x_test_array = x_test.to_numpy()\n",
    "reshape_x_test = x_test_array.reshape(len(x_test), 1, x_train.shape[1])\n",
    "reshape_x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir espacio de busqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 510 ms\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'units1': hp.choice('units1', [8, 16, 32, 64, 128, 256, 512]),\n",
    "    'units2': hp.choice('units2', [8, 16, 32, 64, 128, 256, 512]),\n",
    "                 \n",
    "    'dropout1': hp.choice('dropout1', [0.1,0.2,0.3, 0.4]),\n",
    "    \n",
    "    'batch_size' : hp.choice('batch_size', [16,64,128,256]),\n",
    "    \n",
    "    'nb_epochs' : hp.choice('nb_epochs', [50]),\n",
    "\n",
    "    'optimizer':  hp.choice('optimizer', [ 'adam','adadelta']),   \n",
    "    'activation': hp.choice('activation', [ 'relu','softmax']), \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir busqueda bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9 ms\n"
     ]
    }
   ],
   "source": [
    "#Objective function that hyperopt will minimize\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def objective(params):\n",
    "    \n",
    "#     import ml_metrics\n",
    "\n",
    "    \n",
    "    start = timer()\n",
    "    print ('Params testing: ', params)\n",
    "    print ('\\n ')\n",
    "  \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(128, 1, activation='relu'))\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(Dense(params['units1'], activation = params['activation']))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer=params['optimizer'], loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "    logdir = \"Resultados\\\\\" + exp_name +\"\\\\logs\\\\model\"\n",
    "\n",
    "    tensor_board = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1, profile_batch = 100000000)\n",
    "\n",
    "    \n",
    "    #includes the call back object\n",
    "    model.fit(reshape_x_train, y_train, epochs=params['nb_epochs'], batch_size=params['batch_size'],\n",
    "                verbose = 0, validation_data=(reshape_x_test, y_test),callbacks=[tensor_board])\n",
    "     \n",
    "    #predict the test set \n",
    "    ypred = model.predict_proba(reshape_x_test)\n",
    "    testing_cp = testing.copy()\n",
    "    testing_cp['Prob'] = ypred\n",
    "    testing_cp['Prob_dia'] = testing_cp['Prob'].groupby(testing_cp['Date']).transform('mean')\n",
    "    testing_cp['Prediction'] = 0\n",
    "    testing_cp.loc[testing_cp['Prob_dia']>0.5, 'Prediction'] = 1\n",
    "    testing_cp.drop_duplicates(subset=['Date','Prediction','Label'], inplace=True)\n",
    "    \n",
    "    acc = accuracy_score(testing_cp.Label, testing_cp.Prediction)\n",
    "    \n",
    "    run_time = timer() - start\n",
    "    \n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([-acc, params, run_time])\n",
    "    of_connection.close()\n",
    "    \n",
    "    \n",
    "    print('Test accuracy:', acc)\n",
    " \n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'train_time': run_time,}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almacenar resultados de cada iteración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 999 µs\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import tpe\n",
    "\n",
    "tpe_algorithm = tpe.suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 405 ms\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "from hyperopt import Trials\n",
    "\n",
    "bayes_trials = Trials()\n",
    "\n",
    "# File to save first results\n",
    "out_file = folder + '/gbm_results.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write the headers to the file\n",
    "writer.writerow(['loss', 'params', 'time'])\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lanzar optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params testing:                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 64, 'dropout1': 0.2, 'nb_epochs': 50, 'optimizer': 'adam', 'units1': 256, 'units2': 32}\n",
      "  0%|                                                                            | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "# Run optimization\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = 2, trials = bayes_trials,\n",
    "            verbose = 1, rstate= np.random.RandomState(50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportar bayesiana, por si quisiera retomar donde queda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(bayes_trials, open(folder + '/trials.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer mejores parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the trials with lowest loss (highest AUC) first\n",
    "bayes_trials_results  = sorted(bayes_trials.results, key = lambda x: x['loss'])\n",
    "bayes_trials_results [:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(folder + '/gbm_results.csv')\n",
    "\n",
    "# Sort with best scores on top and reset index for slicing\n",
    "results.sort_values('loss', ascending = True, inplace = True)\n",
    "results.reset_index(inplace = True, drop = True)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Convert from a string to a dictionary\n",
    "ast.literal_eval(results.loc[0, 'params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract the ideal number of estimators and hyperparameters\n",
    "best_bayes_params = ast.literal_eval(results.loc[0, 'params']).copy()\n",
    "best_bayes_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir datasets de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciono la fecha para la cual hago el corte de train y test\n",
    "training_end = pd.to_datetime(\"2014-12-31\")\n",
    "num_training = len(embeddings_average_individual[(embeddings_average_individual[\"Date\"]) <= training_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciono el archivo con el que se corre el modelo\n",
    "data = embeddings_average_individual\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = data[:num_training]\n",
    "testing = data[num_training:]\n",
    "\n",
    "# Se separa en train y test\n",
    "x_train = data.drop([\"Top\",\"Label\", \"Date\"], axis=1)[:num_training]\n",
    "x_test = data.drop([\"Top\",'Label', 'Date'], axis=1)[num_training:]\n",
    "y_train = data[\"Label\"].values[:num_training]\n",
    "y_test = data[\"Label\"].values[num_training:]\n",
    "\n",
    "\n",
    "x_train_array = x_train.to_numpy()\n",
    "reshape_x_train = x_train_array.reshape(len(x_train), 1, x_train.shape[1])\n",
    "reshape_x_train.shape\n",
    "\n",
    "x_test_array = x_test.to_numpy()\n",
    "reshape_x_test = x_test_array.reshape(len(x_test), 1, x_train.shape[1])\n",
    "reshape_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIKq7z8tnIWl"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(best_bayes_params['units1'], activation=best_bayes_params['activation']))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',         metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# define the checkpoint\n",
    "filepath= ch_folder + \"/word2vec-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logdir = \"Resultados\\\\\" + exp_name +\"\\\\logs\\\\model\"\n",
    "\n",
    "\n",
    "tensor_board = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1, profile_batch = 100000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3944,
     "status": "ok",
     "timestamp": 1589755592715,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "JsHgNLFnnTLN",
    "outputId": "4c22910d-c7b2-4dff-eb32-15c2574174ff",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model.fit(reshape_x_train, y_train,\n",
    "          epochs=best_bayes_params['nb_epochs'], \n",
    "          batch_size=best_bayes_params['batch_size'], callbacks=[tensor_board])\n",
    "\n",
    "\n",
    "model.save(folder + '/keras_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(reshape_x_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(reshape_x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1589755595730,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "mdsR4Qngv5Q1",
    "outputId": "433bbcf6-d6eb-44c1-a1bb-afee72ac0ffb"
   },
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "ypred = model.predict_proba(reshape_x_test)\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_cp = testing.copy()\n",
    "testing_cp['Prob'] = ypred\n",
    "testing_cp['Prob_dia'] = testing_cp['Prob'].groupby(testing_cp['Date']).transform('mean')\n",
    "testing_cp['Prediction'] = 0\n",
    "testing_cp.loc[testing_cp['Prob_dia']> 0.5, 'Prediction'] = 1\n",
    "testing_cp.drop_duplicates(subset=['Date','Prediction','Label'], inplace=True)\n",
    "testing_cp.head(1)\n",
    "\n",
    "print('Numero de días en testing: ', testing['Date'].nunique())\n",
    "print('Numero de registros en testing: ', testing_cp['Date'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_cp['Label'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(testing_cp['Label'].value_counts(),\n",
    "        testing_cp['Prediction'].value_counts() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(testing_cp.Label, testing_cp.Prediction, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creates a confusion matrix\n",
    "cm = confusion_matrix(testing_cp.Label, testing_cp.Prediction) \n",
    "\n",
    "# Transform to df for easier plotting\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['Sube','Baja'], \n",
    "                     columns = ['Sube','Baja'])\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(cm_df, annot=True, cmap=\"Greens\", fmt='g')\n",
    "plt.title('Neuronal Network \\nAccuracy:{0:.3f}'.format(accuracy_score(testing_cp.Label, testing_cp.Prediction)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.save_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "copyfile('RNN_Model_Base_GPU_m2.ipynb', folder + '/RNN_Model_Base.ipynb' )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNhtKTbzPEwz7PyaEe0FkIO",
   "collapsed_sections": [],
   "name": "RNN - Meli.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
