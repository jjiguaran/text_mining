{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4dLP23xZmpC"
   },
   "outputs": [],
   "source": [
    "# Importar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import date\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nzv66BqFbl92"
   },
   "outputs": [],
   "source": [
    "#Importar los datasets\n",
    "#url_embeddings_average = 'https://raw.githubusercontent.com/jjiguaran/text_mining/master/Data/embeddings_average.csv'\n",
    "#url_embeddings_sum = 'https://raw.githubusercontent.com/jjiguaran/text_mining/master/Data/embeddings_sum.csv'\n",
    "\n",
    "url_embeddings_average = 'C:/Users/dalessam/Downloads/text_mining/Data/embeddings_average.csv'\n",
    "url_embeddings_sum = 'C:/Users/dalessam/Downloads/text_mining/Data/embeddings_sum.csv'\n",
    "\n",
    "embeddings_average = pd.read_csv(url_embeddings_average)\n",
    "embeddings_sum = pd.read_csv(url_embeddings_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAXOJcEcbmed"
   },
   "outputs": [],
   "source": [
    "# Selecciono la fecha para la cual hago el corte de train y test\n",
    "training_end = pd.to_datetime(\"2014-12-31\")\n",
    "num_training = len(embeddings_average[pd.to_datetime(embeddings_average[\"Date\"]) <= training_end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings Promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVoOQQrAbpy2"
   },
   "outputs": [],
   "source": [
    "# Selecciono el archivo con el que se corre el modelo\n",
    "data = embeddings_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iGzSZUEzbvLs"
   },
   "outputs": [],
   "source": [
    "# Se separa en train y test\n",
    "x_train = data.drop([data.columns[0],\"Label\", \"Date\"], axis=1)[:num_training]\n",
    "x_test = data.drop([data.columns[0],'Label', 'Date'], axis=1)[num_training:]\n",
    "y_train = data[\"Label\"].values[:num_training]\n",
    "y_test = data[\"Label\"].values[num_training:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vlllQBuXsjDh"
   },
   "source": [
    "Se cambia el shape de train y test para el input:\n",
    "https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 915,
     "status": "ok",
     "timestamp": 1589753651752,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "EdyQX-X3mEde",
    "outputId": "3f319356-30f7-414a-8ad8-c5997b17efcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1611, 1, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_array = x_train.to_numpy()\n",
    "reshape_x_train = x_train_array.reshape(1611, 1, 300)\n",
    "reshape_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1207,
     "status": "ok",
     "timestamp": 1589753654795,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "TiRmnmDvsagi",
    "outputId": "1fcf3a9b-7bd2-4981-e024-828e7b11aa1b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 1, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_array = x_test.to_numpy()\n",
    "reshape_x_test = x_test_array.reshape(378, 1, 300)\n",
    "reshape_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJZBoIl-nFDg"
   },
   "outputs": [],
   "source": [
    "from numpy.testing import assert_allclose\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIKq7z8tnIWl"
   },
   "outputs": [],
   "source": [
    "n_units = 10\n",
    "\n",
    "# AGREGAR SEED\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_units, input_shape=(1,300), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(n_units, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# define the checkpoint\n",
    "filepath=\"word2vec-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3944,
     "status": "ok",
     "timestamp": 1589755592715,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "JsHgNLFnnTLN",
    "outputId": "4c22910d-c7b2-4dff-eb32-15c2574174ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dalessam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "1611/1611 [==============================] - 1s 580us/step - loss: 0.6931 - accuracy: 0.5084\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.69306, saving model to word2vec-01-0.6931.hdf5\n",
      "Epoch 2/50\n",
      "1611/1611 [==============================] - 0s 19us/step - loss: 0.6927 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00002: loss improved from 0.69306 to 0.69267, saving model to word2vec-02-0.6927.hdf5\n",
      "Epoch 3/50\n",
      "1611/1611 [==============================] - 0s 16us/step - loss: 0.6923 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00003: loss improved from 0.69267 to 0.69228, saving model to word2vec-03-0.6923.hdf5\n",
      "Epoch 4/50\n",
      "1611/1611 [==============================] - 0s 17us/step - loss: 0.6919 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00004: loss improved from 0.69228 to 0.69195, saving model to word2vec-04-0.6919.hdf5\n",
      "Epoch 5/50\n",
      "1611/1611 [==============================] - 0s 18us/step - loss: 0.6917 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00005: loss improved from 0.69195 to 0.69167, saving model to word2vec-05-0.6917.hdf5\n",
      "Epoch 6/50\n",
      "1611/1611 [==============================] - 0s 18us/step - loss: 0.6913 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00006: loss improved from 0.69167 to 0.69131, saving model to word2vec-06-0.6913.hdf5\n",
      "Epoch 7/50\n",
      "1611/1611 [==============================] - 0s 17us/step - loss: 0.6911 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00007: loss improved from 0.69131 to 0.69106, saving model to word2vec-07-0.6911.hdf5\n",
      "Epoch 8/50\n",
      "1611/1611 [==============================] - 0s 19us/step - loss: 0.6909 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00008: loss improved from 0.69106 to 0.69087, saving model to word2vec-08-0.6909.hdf5\n",
      "Epoch 9/50\n",
      "1611/1611 [==============================] - 0s 20us/step - loss: 0.6907 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00009: loss improved from 0.69087 to 0.69066, saving model to word2vec-09-0.6907.hdf5\n",
      "Epoch 10/50\n",
      "1611/1611 [==============================] - 0s 18us/step - loss: 0.6903 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00010: loss improved from 0.69066 to 0.69028, saving model to word2vec-10-0.6903.hdf5\n",
      "Epoch 11/50\n",
      "1611/1611 [==============================] - 0s 20us/step - loss: 0.6903 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.69028\n",
      "Epoch 12/50\n",
      "1611/1611 [==============================] - 0s 25us/step - loss: 0.6900 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00012: loss improved from 0.69028 to 0.68998, saving model to word2vec-12-0.6900.hdf5\n",
      "Epoch 13/50\n",
      "1611/1611 [==============================] - 0s 29us/step - loss: 0.6902 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.68998\n",
      "Epoch 14/50\n",
      "1611/1611 [==============================] - 0s 33us/step - loss: 0.6898 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00014: loss improved from 0.68998 to 0.68980, saving model to word2vec-14-0.6898.hdf5\n",
      "Epoch 15/50\n",
      "1611/1611 [==============================] - 0s 51us/step - loss: 0.6895 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00015: loss improved from 0.68980 to 0.68954, saving model to word2vec-15-0.6895.hdf5\n",
      "Epoch 16/50\n",
      "1611/1611 [==============================] - 0s 25us/step - loss: 0.6897 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.68954\n",
      "Epoch 17/50\n",
      "1611/1611 [==============================] - 0s 26us/step - loss: 0.6895 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00017: loss improved from 0.68954 to 0.68953, saving model to word2vec-17-0.6895.hdf5\n",
      "Epoch 18/50\n",
      "1611/1611 [==============================] - 0s 22us/step - loss: 0.6902 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.68953\n",
      "Epoch 19/50\n",
      "1611/1611 [==============================] - 0s 24us/step - loss: 0.6897 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.68953\n",
      "Epoch 20/50\n",
      "1611/1611 [==============================] - 0s 31us/step - loss: 0.6902 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.68953\n",
      "Epoch 21/50\n",
      "1611/1611 [==============================] - 0s 41us/step - loss: 0.6891 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00021: loss improved from 0.68953 to 0.68912, saving model to word2vec-21-0.6891.hdf5\n",
      "Epoch 22/50\n",
      "1611/1611 [==============================] - 0s 24us/step - loss: 0.6894 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.68912\n",
      "Epoch 23/50\n",
      "1611/1611 [==============================] - 0s 24us/step - loss: 0.6894 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.68912\n",
      "Epoch 24/50\n",
      "1611/1611 [==============================] - 0s 22us/step - loss: 0.6900 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.68912\n",
      "Epoch 25/50\n",
      "1611/1611 [==============================] - 0s 21us/step - loss: 0.6897 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.68912\n",
      "Epoch 26/50\n",
      "1611/1611 [==============================] - 0s 22us/step - loss: 0.6894 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.68912\n",
      "Epoch 27/50\n",
      "1611/1611 [==============================] - 0s 25us/step - loss: 0.6898 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.68912\n",
      "Epoch 28/50\n",
      "1611/1611 [==============================] - 0s 27us/step - loss: 0.6897 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.68912\n",
      "Epoch 29/50\n",
      "1611/1611 [==============================] - 0s 27us/step - loss: 0.6898 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.68912\n",
      "Epoch 30/50\n",
      "1611/1611 [==============================] - 0s 34us/step - loss: 0.6894 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.68912\n",
      "Epoch 31/50\n",
      "1611/1611 [==============================] - 0s 30us/step - loss: 0.6895 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.68912\n",
      "Epoch 32/50\n",
      "1611/1611 [==============================] - 0s 22us/step - loss: 0.6894 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.68912\n",
      "Epoch 33/50\n",
      "1611/1611 [==============================] - 0s 21us/step - loss: 0.6892 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.68912\n",
      "Epoch 34/50\n",
      "1611/1611 [==============================] - 0s 22us/step - loss: 0.6892 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.68912\n",
      "Epoch 35/50\n",
      "1611/1611 [==============================] - 0s 22us/step - loss: 0.6895 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.68912\n",
      "Epoch 36/50\n",
      "1611/1611 [==============================] - 0s 20us/step - loss: 0.6894 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.68912\n",
      "Epoch 37/50\n",
      "1611/1611 [==============================] - 0s 19us/step - loss: 0.6894 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.68912\n",
      "Epoch 38/50\n",
      "1611/1611 [==============================] - 0s 19us/step - loss: 0.6897 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.68912\n",
      "Epoch 39/50\n",
      "1611/1611 [==============================] - 0s 19us/step - loss: 0.6896 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.68912\n",
      "Epoch 40/50\n",
      "1611/1611 [==============================] - 0s 19us/step - loss: 0.6892 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.68912\n",
      "Epoch 41/50\n",
      "1611/1611 [==============================] - 0s 22us/step - loss: 0.6896 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.68912\n",
      "Epoch 42/50\n",
      "1611/1611 [==============================] - 0s 19us/step - loss: 0.6895 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.68912\n",
      "Epoch 43/50\n",
      "1611/1611 [==============================] - 0s 22us/step - loss: 0.6896 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.68912\n",
      "Epoch 44/50\n",
      "1611/1611 [==============================] - 0s 24us/step - loss: 0.6897 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.68912\n",
      "Epoch 45/50\n",
      "1611/1611 [==============================] - 0s 21us/step - loss: 0.6893 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.68912\n",
      "Epoch 46/50\n",
      "1611/1611 [==============================] - 0s 19us/step - loss: 0.6895 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.68912\n",
      "Epoch 47/50\n",
      "1611/1611 [==============================] - 0s 19us/step - loss: 0.6894 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.68912\n",
      "Epoch 48/50\n",
      "1611/1611 [==============================] - 0s 20us/step - loss: 0.6894 - accuracy: 0.5419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00048: loss did not improve from 0.68912\n",
      "Epoch 49/50\n",
      "1611/1611 [==============================] - 0s 20us/step - loss: 0.6894 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.68912\n",
      "Epoch 50/50\n",
      "1611/1611 [==============================] - 0s 19us/step - loss: 0.6894 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.68912\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 1, 10)             12440     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 10)                840       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 13,291\n",
      "Trainable params: 13,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(reshape_x_train, y_train, epochs=50, batch_size=500, callbacks=callbacks_list)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1589755595730,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "mdsR4Qngv5Q1",
    "outputId": "433bbcf6-d6eb-44c1-a1bb-afee72ac0ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.507937\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(reshape_x_test, y_test, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings Suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciono el archivo con el que se corre el modelo\n",
    "data = embeddings_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se separa en train y test\n",
    "x_train = data.drop([data.columns[0],\"Label\", \"Date\"], axis=1)[:num_training]\n",
    "x_test = data.drop([data.columns[0],'Label', 'Date'], axis=1)[num_training:]\n",
    "y_train = data[\"Label\"].values[:num_training]\n",
    "y_test = data[\"Label\"].values[num_training:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ALaEKIEq0sfK"
   },
   "outputs": [],
   "source": [
    "n_units = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_units, input_shape=(1,300), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(n_units, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#binary_crossentropy\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "# define the checkpoint\n",
    "filepath=\"word2vec-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1611, 1, 300)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_array = x_train.to_numpy()\n",
    "reshape_x_train = x_train_array.reshape(1611, 1, 300)\n",
    "reshape_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 1, 300)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_array = x_test.to_numpy()\n",
    "reshape_x_test = x_test_array.reshape(378, 1, 300)\n",
    "reshape_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.testing import assert_allclose\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5822,
     "status": "ok",
     "timestamp": 1589755948633,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "pSy9hWYW0WRr",
    "outputId": "e54870b1-b669-4be5-8a1c-9ff676611184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1611/1611 [==============================] - 1s 516us/step - loss: 0.2487 - accuracy: 0.5400\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.24871, saving model to word2vec-01-0.2487.hdf5\n",
      "Epoch 2/50\n",
      "1611/1611 [==============================] - 0s 34us/step - loss: 0.2490 - accuracy: 0.5425\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.24871\n",
      "Epoch 3/50\n",
      "1611/1611 [==============================] - 0s 36us/step - loss: 0.2489 - accuracy: 0.5400\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.24871\n",
      "Epoch 4/50\n",
      "1611/1611 [==============================] - 0s 37us/step - loss: 0.2483 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00004: loss improved from 0.24871 to 0.24830, saving model to word2vec-04-0.2483.hdf5\n",
      "Epoch 5/50\n",
      "1611/1611 [==============================] - 0s 40us/step - loss: 0.2478 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00005: loss improved from 0.24830 to 0.24780, saving model to word2vec-05-0.2478.hdf5\n",
      "Epoch 6/50\n",
      "1611/1611 [==============================] - 0s 39us/step - loss: 0.2482 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.24780\n",
      "Epoch 7/50\n",
      "1611/1611 [==============================] - 0s 42us/step - loss: 0.2486 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.24780\n",
      "Epoch 8/50\n",
      "1611/1611 [==============================] - 0s 49us/step - loss: 0.2482 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.24780\n",
      "Epoch 9/50\n",
      "1611/1611 [==============================] - 0s 48us/step - loss: 0.2485 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.24780\n",
      "Epoch 10/50\n",
      "1611/1611 [==============================] - 0s 43us/step - loss: 0.2484 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.24780\n",
      "Epoch 11/50\n",
      "1611/1611 [==============================] - 0s 44us/step - loss: 0.2482 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.24780\n",
      "Epoch 12/50\n",
      "1611/1611 [==============================] - 0s 40us/step - loss: 0.2486 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.24780\n",
      "Epoch 13/50\n",
      "1611/1611 [==============================] - 0s 41us/step - loss: 0.2482 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.24780\n",
      "Epoch 14/50\n",
      "1611/1611 [==============================] - 0s 42us/step - loss: 0.2482 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.24780\n",
      "Epoch 15/50\n",
      "1611/1611 [==============================] - 0s 51us/step - loss: 0.2483 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.24780\n",
      "Epoch 16/50\n",
      "1611/1611 [==============================] - 0s 42us/step - loss: 0.2485 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.24780\n",
      "Epoch 17/50\n",
      "1611/1611 [==============================] - 0s 41us/step - loss: 0.2481 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.24780\n",
      "Epoch 18/50\n",
      "1611/1611 [==============================] - 0s 40us/step - loss: 0.2480 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.24780\n",
      "Epoch 19/50\n",
      "1611/1611 [==============================] - 0s 42us/step - loss: 0.2484 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.24780\n",
      "Epoch 20/50\n",
      "1611/1611 [==============================] - 0s 38us/step - loss: 0.2485 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.24780\n",
      "Epoch 21/50\n",
      "1611/1611 [==============================] - 0s 38us/step - loss: 0.2485 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.24780\n",
      "Epoch 22/50\n",
      "1611/1611 [==============================] - 0s 47us/step - loss: 0.2483 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.24780\n",
      "Epoch 23/50\n",
      "1611/1611 [==============================] - 0s 53us/step - loss: 0.2485 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.24780\n",
      "Epoch 24/50\n",
      "1611/1611 [==============================] - 0s 56us/step - loss: 0.2484 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.24780\n",
      "Epoch 25/50\n",
      "1611/1611 [==============================] - 0s 55us/step - loss: 0.2483 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.24780\n",
      "Epoch 26/50\n",
      "1611/1611 [==============================] - 0s 54us/step - loss: 0.2483 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.24780\n",
      "Epoch 27/50\n",
      "1611/1611 [==============================] - 0s 50us/step - loss: 0.2481 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.24780\n",
      "Epoch 28/50\n",
      "1611/1611 [==============================] - 0s 55us/step - loss: 0.2482 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.24780\n",
      "Epoch 29/50\n",
      "1611/1611 [==============================] - 0s 52us/step - loss: 0.2485 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.24780\n",
      "Epoch 30/50\n",
      "1611/1611 [==============================] - 0s 50us/step - loss: 0.2484 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.24780\n",
      "Epoch 31/50\n",
      "1611/1611 [==============================] - 0s 45us/step - loss: 0.2483 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.24780\n",
      "Epoch 32/50\n",
      "1611/1611 [==============================] - 0s 42us/step - loss: 0.2483 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.24780\n",
      "Epoch 33/50\n",
      "1611/1611 [==============================] - 0s 43us/step - loss: 0.2481 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.24780\n",
      "Epoch 34/50\n",
      "1611/1611 [==============================] - 0s 43us/step - loss: 0.2483 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.24780\n",
      "Epoch 35/50\n",
      "1611/1611 [==============================] - 0s 40us/step - loss: 0.2484 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.24780\n",
      "Epoch 36/50\n",
      "1611/1611 [==============================] - 0s 43us/step - loss: 0.2482 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.24780\n",
      "Epoch 37/50\n",
      "1611/1611 [==============================] - 0s 43us/step - loss: 0.2481 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.24780\n",
      "Epoch 38/50\n",
      "1611/1611 [==============================] - 0s 38us/step - loss: 0.2483 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.24780\n",
      "Epoch 39/50\n",
      "1611/1611 [==============================] - 0s 40us/step - loss: 0.2483 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.24780\n",
      "Epoch 40/50\n",
      "1611/1611 [==============================] - 0s 39us/step - loss: 0.2481 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.24780\n",
      "Epoch 41/50\n",
      "1611/1611 [==============================] - 0s 41us/step - loss: 0.2482 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.24780\n",
      "Epoch 42/50\n",
      "1611/1611 [==============================] - 0s 40us/step - loss: 0.2480 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.24780\n",
      "Epoch 43/50\n",
      "1611/1611 [==============================] - 0s 42us/step - loss: 0.2483 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.24780\n",
      "Epoch 44/50\n",
      "1611/1611 [==============================] - 0s 39us/step - loss: 0.2482 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.24780\n",
      "Epoch 45/50\n",
      "1611/1611 [==============================] - 0s 40us/step - loss: 0.2482 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.24780\n",
      "Epoch 46/50\n",
      "1611/1611 [==============================] - 0s 38us/step - loss: 0.2484 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.24780\n",
      "Epoch 47/50\n",
      "1611/1611 [==============================] - 0s 42us/step - loss: 0.2483 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.24780\n",
      "Epoch 48/50\n",
      "1611/1611 [==============================] - 0s 41us/step - loss: 0.2483 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.24780\n",
      "Epoch 49/50\n",
      "1611/1611 [==============================] - 0s 40us/step - loss: 0.2485 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.24780\n",
      "Epoch 50/50\n",
      "1611/1611 [==============================] - 0s 42us/step - loss: 0.2484 - accuracy: 0.5419\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.24780\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 1, 5)              6120      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1, 5)              0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 5)                 220       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 6,346\n",
      "Trainable params: 6,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(reshape_x_train, y_train, epochs=50, batch_size=100, callbacks=callbacks_list)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2326,
     "status": "ok",
     "timestamp": 1589755952899,
     "user": {
      "displayName": "Melina D'Alessandro",
      "photoUrl": "https://lh4.googleusercontent.com/-AU_sxBOTu8w/AAAAAAAAAAI/AAAAAAAAAR8/nO0zS5J_9Wo/s64/photo.jpg",
      "userId": "09190509655785270416"
     },
     "user_tz": 180
    },
    "id": "xAzxxIGm0i5J",
    "outputId": "94cae81f-6aff-42c9-bcff-7ed2e760b7b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.793654\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(reshape_x_test, y_test, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNhtKTbzPEwz7PyaEe0FkIO",
   "collapsed_sections": [],
   "name": "RNN - Meli.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
